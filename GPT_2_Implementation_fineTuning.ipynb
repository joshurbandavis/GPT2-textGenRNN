{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzxl1vYX-1kk"
      },
      "source": [
        "This notebook is intended to either train GPT2 from scratch using open-source implementations or to fine-tune a pre-existing model trained on GPT2 architecture.\n",
        "\n",
        "Most recent version of this notebook was developed `by Josh Urban Davis (http://www.joshurbandavis.com, @joshurbandavis)`\n",
        "\n",
        "Setup:\n",
        "\n",
        "1) Make sure GPU is enabled, go to edit->notebook settings->Hardware Accelerator GPU\n",
        "\n",
        "2) Make a copy to your google drive, click on copy to drive in panel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW0abT07ZkhZ"
      },
      "source": [
        "Note: Colab will reset after 12 hours make sure to save your model checkpoints to google drive around 10-11 hours mark or before, then go to runtime->reset all runtimes. Now copy your train model back into colab and start training again from the previous checkpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLXW02eIYpcB"
      },
      "source": [
        "Most recent version of this notebook was developed by Josh Urban Davis (http://www.joshurbandavis.com, @joshurbandavis)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICYu3w9hIJkC",
        "outputId": "4b581f31-49d3-47b5-bffb-235efbd6ff0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/nshepperd/gpt-2.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 310, done.\u001b[K\n",
            "remote: Total 310 (delta 0), reused 0 (delta 0), pack-reused 310\u001b[K\n",
            "Receiving objects: 100% (310/310), 4.40 MiB | 3.97 MiB/s, done.\n",
            "Resolving deltas: 100% (168/168), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eEIs3ApZUVO",
        "outputId": "77322ed1-5b9c-4022-b407-6df7584a48f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtn1qZPgZLb0"
      },
      "source": [
        "Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "434oOx0bZH6J",
        "outputId": "9bf1cad8-f10e-4005-b9f2-f02df2c3351f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        }
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20kB 27.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 30kB 33.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 40kB 36.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 51kB 39.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 61kB 43.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71kB 39.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 28.6MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Collecting tqdm==4.31.1 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 25.0MB/s \n",
            "\u001b[?25hCollecting toposort==1.5 (from -r requirements.txt (line 5))\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=a0b50bba31d1b569c568a4b137cb502555c11cffd226746130dd303fa7e58a57\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533194 sha256=422776e6d00591ff0689f786679715d87ab6127eb9c1ddefe352599166416b81\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "Installing collected packages: fire, regex, tqdm, toposort\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed fire-0.2.1 regex-2017.4.5 toposort-1.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvUQhgK3PQ4L"
      },
      "source": [
        "Mount drive to access google drive for saving and accessing checkpoints later. Have to log in to your google account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNpf6R4ahYSN",
        "outputId": "805d46ca-1483-49d6-a67d-ce8604d79430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1hrgeKFYsuE"
      },
      "source": [
        "Download the model data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A498TySgHYyF",
        "outputId": "c507fb5f-4bd8-4315-d5b1-7910df4e36a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!python3 download_model.py 117M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 717kit/s]                                                      \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 56.1Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 957kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:07, 62.2Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 4.29Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 40.2Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 51.5Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UDpEGjfO8Q2",
        "outputId": "c4b36abb-cdcf-40b7-9465-8b0d7fbffa62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!python3 download_model.py 345M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 767kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 63.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 778kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:23, 60.7Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 6.96Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 67.4Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 59.7Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq-YwRnNOBYO"
      },
      "source": [
        "encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oJPQtdLbbeK"
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KzSbAvePgsI"
      },
      "source": [
        "Fetch checkpoints if you have them saved in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA2Wk7yIPmS6"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/checkpoint/ /content/gpt-2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p--9zwqQRTc"
      },
      "source": [
        "\n",
        "Let's get our train on! In this case the file is A Tale of Two Cities (Charles Dickens) from Project Gutenberg. To change the dataset GPT-2 models will fine-tune on, change this URL to another .txt file, and change corresponding part of the next cell. Note that you can use small datasets if you want but you will have to be sure not to run the fine-tuning for too long or you will overfit badly. Roughly, expect interesting results within minutes to hours in the 1-10s of megabyte ballpark, and below this you may want to stop the run early as fine-tuning can be very fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOCvrs-DHvxa",
        "outputId": "61c190b2-4db6-4cab-986c-bd8251235dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget https://www.gutenberg.org/files/98/98-0.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-19 19:36:36--  https://www.gutenberg.org/files/98/98-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 804335 (785K) [text/plain]\n",
            "Saving to: ‘98-0.txt’\n",
            "\n",
            "98-0.txt            100%[===================>] 785.48K  1.66MB/s    in 0.5s    \n",
            "\n",
            "2019-08-19 19:36:36 (1.66 MB/s) - ‘98-0.txt’ saved [804335/804335]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPfJ5b3CQXqr"
      },
      "source": [
        "\n",
        "Start training, add --model_name '345M' to use 345 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEn_ihcGI00T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "656f4775-4647-4ad8-9208-3497b63c4838"
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset /content/obituary_text_corpus_GPT2_8.txt --model_name '345M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 03:39:00.654868 140429746399104 deprecation_wrapper.py:119] From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0904 03:39:00.669187 140429746399104 deprecation_wrapper.py:119] From /content/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0904 03:39:00.751445 140429746399104 deprecation_wrapper.py:119] From ./train.py:88: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0904 03:39:00.751766 140429746399104 deprecation_wrapper.py:119] From ./train.py:91: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-09-04 03:39:00.769537: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-09-04 03:39:00.771371: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f65100 executing computations on platform Host. Devices:\n",
            "2019-09-04 03:39:00.771415: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-04 03:39:00.795970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-04 03:39:01.030433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 03:39:01.031143: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f652c0 executing computations on platform CUDA. Devices:\n",
            "2019-09-04 03:39:01.031177: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-09-04 03:39:01.031544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 03:39:01.032063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-04 03:39:01.038467: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-04 03:39:01.193695: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-04 03:39:01.263008: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-04 03:39:01.282624: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-04 03:39:01.455947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-04 03:39:01.561175: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-04 03:39:01.908514: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-04 03:39:01.908791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 03:39:01.909526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 03:39:01.910043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-04 03:39:01.912805: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-04 03:39:01.914116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-04 03:39:01.914145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-04 03:39:01.914156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-04 03:39:01.919484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 03:39:01.920142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 03:39:01.920677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0904 03:39:01.921774 140429746399104 deprecation_wrapper.py:119] From ./train.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0904 03:39:12.095399 140429746399104 deprecation.py:323] From /content/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0904 03:39:12.107628 140429746399104 deprecation.py:323] From /content/gpt-2/src/sample.py:16: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0904 03:39:12.109062 140429746399104 deprecation.py:323] From /content/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "W0904 03:39:12.118053 140429746399104 deprecation_wrapper.py:119] From ./train.py:121: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0904 03:39:25.246921 140429746399104 deprecation_wrapper.py:119] From ./train.py:144: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0904 03:39:25.249494 140429746399104 deprecation_wrapper.py:119] From ./train.py:147: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W0904 03:39:25.250224 140429746399104 deprecation_wrapper.py:119] From ./train.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W0904 03:39:25.250798 140429746399104 deprecation_wrapper.py:119] From ./train.py:152: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2019-09-04 03:39:26.650314: W tensorflow/core/framework/allocator.cc:107] Allocation of 16777216 exceeds 10% of system memory.\n",
            "2019-09-04 03:39:26.657587: W tensorflow/core/framework/allocator.cc:107] Allocation of 16777216 exceeds 10% of system memory.\n",
            "2019-09-04 03:39:26.663132: W tensorflow/core/framework/allocator.cc:107] Allocation of 16777216 exceeds 10% of system memory.\n",
            "2019-09-04 03:39:26.667031: W tensorflow/core/framework/allocator.cc:107] Allocation of 16777216 exceeds 10% of system memory.\n",
            "2019-09-04 03:39:26.678436: W tensorflow/core/framework/allocator.cc:107] Allocation of 16777216 exceeds 10% of system memory.\n",
            "Loading checkpoint models/345M/model.ckpt\n",
            "W0904 03:39:40.062791 140429746399104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Loading dataset...\n",
            "100% 1/1 [00:16<00:00, 16.52s/it]\n",
            "dataset has 3578805 tokens\n",
            "Training...\n",
            "2019-09-04 03:40:15.675808: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "2019-09-04 03:40:16.340480: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "[3701 | 12.22] loss=3.21 avg=3.21\n",
            "[3702 | 13.69] loss=3.18 avg=3.19\n",
            "[3703 | 15.16] loss=3.38 avg=3.26\n",
            "[3704 | 16.65] loss=3.06 avg=3.21\n",
            "[3705 | 18.13] loss=3.02 avg=3.17\n",
            "[3706 | 19.61] loss=3.15 avg=3.16\n",
            "[3707 | 21.10] loss=2.97 avg=3.13\n",
            "[3708 | 22.59] loss=3.23 avg=3.15\n",
            "[3709 | 24.09] loss=3.28 avg=3.16\n",
            "[3710 | 25.59] loss=3.05 avg=3.15\n",
            "[3711 | 27.09] loss=2.96 avg=3.13\n",
            "[3712 | 28.60] loss=3.27 avg=3.14\n",
            "[3713 | 30.10] loss=2.77 avg=3.11\n",
            "[3714 | 31.60] loss=3.39 avg=3.13\n",
            "[3715 | 33.11] loss=2.99 avg=3.12\n",
            "[3716 | 34.62] loss=3.63 avg=3.16\n",
            "[3717 | 36.13] loss=3.02 avg=3.15\n",
            "[3718 | 37.64] loss=3.25 avg=3.16\n",
            "[3719 | 39.15] loss=3.23 avg=3.16\n",
            "[3720 | 40.67] loss=3.29 avg=3.17\n",
            "[3721 | 42.19] loss=3.35 avg=3.18\n",
            "[3722 | 43.71] loss=3.68 avg=3.20\n",
            "[3723 | 45.24] loss=3.00 avg=3.19\n",
            "[3724 | 46.77] loss=3.17 avg=3.19\n",
            "[3725 | 48.30] loss=2.96 avg=3.18\n",
            "[3726 | 49.83] loss=3.44 avg=3.19\n",
            "[3727 | 51.37] loss=2.67 avg=3.17\n",
            "[3728 | 52.91] loss=3.29 avg=3.18\n",
            "[3729 | 54.45] loss=3.20 avg=3.18\n",
            "[3730 | 56.00] loss=2.92 avg=3.17\n",
            "[3731 | 57.55] loss=3.06 avg=3.16\n",
            "[3732 | 59.10] loss=3.06 avg=3.16\n",
            "[3733 | 60.66] loss=3.08 avg=3.16\n",
            "[3734 | 62.22] loss=2.64 avg=3.14\n",
            "[3735 | 63.79] loss=2.87 avg=3.13\n",
            "[3736 | 65.37] loss=2.95 avg=3.12\n",
            "[3737 | 66.94] loss=3.15 avg=3.12\n",
            "[3738 | 68.53] loss=2.78 avg=3.11\n",
            "[3739 | 70.12] loss=3.09 avg=3.11\n",
            "[3740 | 71.70] loss=2.96 avg=3.11\n",
            "[3741 | 73.28] loss=2.92 avg=3.10\n",
            "[3742 | 74.86] loss=3.43 avg=3.11\n",
            "[3743 | 76.44] loss=2.77 avg=3.10\n",
            "[3744 | 78.03] loss=3.48 avg=3.11\n",
            "[3745 | 79.62] loss=2.65 avg=3.10\n",
            "[3746 | 81.22] loss=3.89 avg=3.12\n",
            "[3747 | 82.83] loss=3.03 avg=3.12\n",
            "[3748 | 84.43] loss=3.05 avg=3.12\n",
            "[3749 | 86.04] loss=3.59 avg=3.13\n",
            "[3750 | 87.66] loss=2.80 avg=3.12\n",
            "[3751 | 89.28] loss=2.98 avg=3.12\n",
            "[3752 | 90.91] loss=2.81 avg=3.11\n",
            "[3753 | 92.55] loss=2.78 avg=3.10\n",
            "[3754 | 94.19] loss=2.95 avg=3.10\n",
            "[3755 | 95.84] loss=3.21 avg=3.10\n",
            "[3756 | 97.51] loss=3.00 avg=3.10\n",
            "[3757 | 99.17] loss=3.33 avg=3.10\n",
            "[3758 | 100.83] loss=2.48 avg=3.09\n",
            "[3759 | 102.51] loss=2.72 avg=3.08\n",
            "[3760 | 104.19] loss=2.73 avg=3.07\n",
            "[3761 | 105.90] loss=2.31 avg=3.06\n",
            "[3762 | 107.61] loss=3.17 avg=3.06\n",
            "[3763 | 109.31] loss=3.05 avg=3.06\n",
            "[3764 | 111.01] loss=3.05 avg=3.06\n",
            "[3765 | 112.74] loss=2.74 avg=3.05\n",
            "[3766 | 114.46] loss=2.83 avg=3.05\n",
            "[3767 | 116.18] loss=3.29 avg=3.05\n",
            "[3768 | 117.91] loss=3.07 avg=3.05\n",
            "[3769 | 119.64] loss=3.23 avg=3.06\n",
            "[3770 | 121.36] loss=3.01 avg=3.06\n",
            "[3771 | 123.08] loss=3.19 avg=3.06\n",
            "[3772 | 124.78] loss=2.95 avg=3.06\n",
            "[3773 | 126.48] loss=2.97 avg=3.05\n",
            "[3774 | 128.18] loss=3.29 avg=3.06\n",
            "[3775 | 129.84] loss=3.06 avg=3.06\n",
            "[3776 | 131.50] loss=2.79 avg=3.05\n",
            "[3777 | 133.15] loss=3.29 avg=3.06\n",
            "[3778 | 134.80] loss=2.77 avg=3.05\n",
            "[3779 | 136.45] loss=3.11 avg=3.05\n",
            "[3780 | 138.09] loss=2.84 avg=3.05\n",
            "[3781 | 139.73] loss=2.74 avg=3.05\n",
            "[3782 | 141.36] loss=2.90 avg=3.04\n",
            "[3783 | 143.00] loss=3.10 avg=3.04\n",
            "[3784 | 144.63] loss=3.06 avg=3.04\n",
            "[3785 | 146.27] loss=2.77 avg=3.04\n",
            "[3786 | 147.92] loss=2.98 avg=3.04\n",
            "[3787 | 149.55] loss=2.77 avg=3.03\n",
            "[3788 | 151.18] loss=2.87 avg=3.03\n",
            "[3789 | 152.81] loss=3.43 avg=3.04\n",
            "[3790 | 154.45] loss=2.63 avg=3.03\n",
            "[3791 | 156.08] loss=3.03 avg=3.03\n",
            "[3792 | 157.72] loss=2.92 avg=3.03\n",
            "[3793 | 159.38] loss=3.40 avg=3.03\n",
            "[3794 | 161.02] loss=2.84 avg=3.03\n",
            "[3795 | 162.68] loss=2.76 avg=3.03\n",
            "[3796 | 164.34] loss=3.31 avg=3.03\n",
            "[3797 | 166.00] loss=2.70 avg=3.03\n",
            "[3798 | 167.67] loss=3.01 avg=3.03\n",
            "[3799 | 169.33] loss=3.34 avg=3.03\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " and of course his team – a man who was on his way to being the most coveted player in all of professional sports. But he was not of the typical athlete in that he did not train by himself and never did. As a child for many years there were two things which were most important to him – his father had a great deal of money to invest in him and being able to give him a healthy dose of life; and his mother and brother.\n",
            "Posted by Paul at 13:02\n",
            "The very first player to be paid in the AFL, I would like to think – but I do not have any concrete evidence – was Jack Hurn. (1942-43) The boy looked to be just the same as he had been when he was nine. He was a hardy boy, strong, brave, and a real winner. The AFL had introduced him to the game before it was known that he was a boy; and as there was only one boy going to a big event and a couple of mates from the clubs, he did not get much publicity from the teams. Not long afterwards he was the biggest boy in the room and received more awards than anyone else that night. There was a good deal of publicity in the local press at the time and, for some reason, a group of Australian sporting figures who were there in a party, decided to go down and help the boy out. They took the boy to the front stand of the local team in Sydney and, with him, were able to photograph him, and I am not sure that there was anyone there in full professional mode.\n",
            "Posted by Paul at 19:59\n",
            "The great Peter Shilton had an interesting nickname – a name that was to become an apt one among the many aunts and uncles of the football community at Adelaide Oval. On the night of his 80th birthday, he was invited to celebrate by giving away a $10,000 sum to the church through the Bishop of Adelaide. He did not know how to put his hand to the cash; but he was determined and was quite sure that when the bell rang, the bells at the cathedral's front door went into eagle tings. He gave away more than he had been lucky enough to get in his career, and the church was greatly glad to receive the amount and was pleased with its performance.\n",
            "Posted by Paul at 25:44\n",
            "I know it is a big question, but why was David Fyfe given a life sentence for his involvement in the murder of Mary Stokes, one of Melbourne's most respected women? The question is being widely asked now, but no explanation for this case is offered. The most probable answer is that Fyfe's association with the murderer was so bad that, with a few exceptions, Fyfe never knew her personally. Fyfe would have known her by name from all the time we saw her as a daughter of his, but that was not a very long time ago, at least at his home. Perhaps he was not able to see her on that occasion, seeing as he had been away from Victoria, but I think he never really saw her, and if his association with her should be the reason, it was one which had an enormous influence on him. The reason why it took four years for a verdict was that Fyfe, after visiting a hospital to receive medical advice, was told that if he wished to remain as a solicitor he could not, but there were no legal questions he could answer and no one ever got to the bottom of the matter so far as I know. For that he paid two years' imprisonment in a local court, and also a fine. It was just the most unusual of cases. But although Mary never saw Fyfe again after he left her at an early age, the Fyfe family would come back to Victoria. They were then well aware of the truth of the matter, and there were few in Victoria who felt at all a little sorry for the murderer, although Mary thought it was very difficult to get a man to forgive. It would have been impossible to get the man to come straight out of the back of her truck and apologise again once he had been given the chance. It would have taken so long but I know that she would have felt sorry for him. It is too late now for her to make that apology; and I must say that I do believe that he was probably never going to forgive her. I may be a different person in many respects to what I was then, and have my own views and opinions, but I still have a good sense of humour about me – and I still have plenty of it. I did go on holiday to New Zealand with my cousin after I got the guilty verdicts, but I left my hotel room and the hotel, in spite of all the police presence, to go into the lounge and smoke a pipe, and I left the hotel and did a few miles of walking.\n",
            "Posted by Paul at 08:18\n",
            "When you are out of the hospital\n",
            "\n",
            "[3800 | 196.21] loss=2.54 avg=3.02\n",
            "[3801 | 197.91] loss=2.67 avg=3.02\n",
            "[3802 | 199.61] loss=3.14 avg=3.02\n",
            "[3803 | 201.31] loss=2.57 avg=3.01\n",
            "[3804 | 202.99] loss=3.24 avg=3.02\n",
            "[3805 | 204.68] loss=2.80 avg=3.01\n",
            "[3806 | 206.34] loss=3.13 avg=3.01\n",
            "[3807 | 208.02] loss=3.01 avg=3.01\n",
            "[3808 | 209.68] loss=3.00 avg=3.01\n",
            "[3809 | 211.34] loss=3.23 avg=3.02\n",
            "[3810 | 213.01] loss=2.94 avg=3.02\n",
            "[3811 | 214.67] loss=2.82 avg=3.01\n",
            "[3812 | 216.33] loss=2.79 avg=3.01\n",
            "[3813 | 217.99] loss=2.90 avg=3.01\n",
            "[3814 | 219.65] loss=2.82 avg=3.01\n",
            "[3815 | 221.31] loss=2.71 avg=3.00\n",
            "[3816 | 222.97] loss=3.40 avg=3.01\n",
            "[3817 | 224.63] loss=2.70 avg=3.00\n",
            "[3818 | 226.29] loss=2.80 avg=3.00\n",
            "[3819 | 227.95] loss=3.04 avg=3.00\n",
            "[3820 | 229.61] loss=2.85 avg=3.00\n",
            "[3821 | 231.27] loss=2.96 avg=3.00\n",
            "[3822 | 232.93] loss=3.12 avg=3.00\n",
            "[3823 | 234.61] loss=2.79 avg=3.00\n",
            "[3824 | 236.27] loss=2.61 avg=2.99\n",
            "[3825 | 237.95] loss=2.68 avg=2.99\n",
            "[3826 | 239.64] loss=2.90 avg=2.99\n",
            "[3827 | 241.32] loss=2.73 avg=2.98\n",
            "[3828 | 243.00] loss=2.75 avg=2.98\n",
            "[3829 | 244.69] loss=2.67 avg=2.97\n",
            "[3830 | 246.38] loss=3.00 avg=2.98\n",
            "[3831 | 248.08] loss=2.47 avg=2.97\n",
            "[3832 | 249.78] loss=3.13 avg=2.97\n",
            "[3833 | 251.46] loss=3.17 avg=2.97\n",
            "[3834 | 253.17] loss=3.52 avg=2.98\n",
            "[3835 | 254.87] loss=2.97 avg=2.98\n",
            "[3836 | 256.58] loss=2.76 avg=2.98\n",
            "[3837 | 258.28] loss=3.18 avg=2.98\n",
            "[3838 | 259.98] loss=2.71 avg=2.98\n",
            "[3839 | 261.68] loss=2.92 avg=2.98\n",
            "[3840 | 263.39] loss=3.07 avg=2.98\n",
            "[3841 | 265.08] loss=3.24 avg=2.98\n",
            "[3842 | 266.79] loss=3.42 avg=2.99\n",
            "[3843 | 268.50] loss=3.77 avg=3.00\n",
            "[3844 | 270.19] loss=3.07 avg=3.00\n",
            "[3845 | 271.90] loss=2.76 avg=2.99\n",
            "[3846 | 273.59] loss=2.99 avg=2.99\n",
            "[3847 | 275.29] loss=2.82 avg=2.99\n",
            "[3848 | 277.00] loss=3.21 avg=2.99\n",
            "[3849 | 278.70] loss=2.72 avg=2.99\n",
            "[3850 | 280.40] loss=3.06 avg=2.99\n",
            "[3851 | 282.09] loss=3.64 avg=3.00\n",
            "[3852 | 283.78] loss=3.24 avg=3.00\n",
            "[3853 | 285.47] loss=3.09 avg=3.00\n",
            "[3854 | 287.16] loss=2.95 avg=3.00\n",
            "[3855 | 288.84] loss=2.85 avg=3.00\n",
            "[3856 | 290.53] loss=2.62 avg=3.00\n",
            "[3857 | 292.21] loss=3.18 avg=3.00\n",
            "[3858 | 293.89] loss=2.81 avg=3.00\n",
            "[3859 | 295.58] loss=3.29 avg=3.00\n",
            "[3860 | 297.26] loss=2.78 avg=3.00\n",
            "[3861 | 298.94] loss=3.13 avg=3.00\n",
            "[3862 | 300.63] loss=3.06 avg=3.00\n",
            "[3863 | 302.32] loss=3.10 avg=3.00\n",
            "[3864 | 304.00] loss=2.53 avg=3.00\n",
            "[3865 | 305.69] loss=2.79 avg=2.99\n",
            "[3866 | 307.38] loss=3.11 avg=2.99\n",
            "[3867 | 309.05] loss=2.87 avg=2.99\n",
            "[3868 | 310.75] loss=2.76 avg=2.99\n",
            "[3869 | 312.45] loss=2.74 avg=2.99\n",
            "[3870 | 314.15] loss=2.58 avg=2.98\n",
            "[3871 | 315.84] loss=2.78 avg=2.98\n",
            "[3872 | 317.54] loss=2.98 avg=2.98\n",
            "[3873 | 319.23] loss=3.01 avg=2.98\n",
            "[3874 | 320.92] loss=2.78 avg=2.98\n",
            "[3875 | 322.62] loss=2.69 avg=2.97\n",
            "[3876 | 324.32] loss=3.09 avg=2.98\n",
            "[3877 | 326.02] loss=2.70 avg=2.97\n",
            "[3878 | 327.72] loss=2.78 avg=2.97\n",
            "[3879 | 329.43] loss=3.14 avg=2.97\n",
            "[3880 | 331.12] loss=2.71 avg=2.97\n",
            "[3881 | 332.83] loss=2.59 avg=2.96\n",
            "[3882 | 334.53] loss=2.92 avg=2.96\n",
            "[3883 | 336.23] loss=2.97 avg=2.96\n",
            "[3884 | 337.93] loss=2.95 avg=2.96\n",
            "[3885 | 339.63] loss=2.91 avg=2.96\n",
            "[3886 | 341.33] loss=2.97 avg=2.96\n",
            "[3887 | 343.04] loss=3.16 avg=2.97\n",
            "[3888 | 344.74] loss=3.65 avg=2.97\n",
            "[3889 | 346.44] loss=3.14 avg=2.98\n",
            "[3890 | 348.14] loss=2.69 avg=2.97\n",
            "[3891 | 349.85] loss=2.72 avg=2.97\n",
            "[3892 | 351.55] loss=2.70 avg=2.97\n",
            "[3893 | 353.25] loss=3.15 avg=2.97\n",
            "[3894 | 354.95] loss=3.12 avg=2.97\n",
            "[3895 | 356.65] loss=2.70 avg=2.97\n",
            "[3896 | 358.36] loss=3.05 avg=2.97\n",
            "[3897 | 360.06] loss=3.37 avg=2.97\n",
            "[3898 | 361.75] loss=3.26 avg=2.98\n",
            "[3899 | 363.46] loss=2.83 avg=2.97\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " of the first wave-born women in Ireland in the late nineteenth century, one of the original and perhaps the most popular of the early nurse-maid-maids.\n",
            "\n",
            "On Saturday (16th January) we were informed about a special event that was taking place in Dublin's Church of St. John the Bap. The event was a memorial show, a very special treat for the ladies' section to a special occasion which they had a special part in, and as such, we were not really well satisfied about it. We do, however, know from a number of sources that in its original incarnation this was a very popular and popular thing (to use a man's term), but one which in practice did very little but cause a very bad impression of the lady.\n",
            "\n",
            "One woman in particular, after some very serious talk with the lady, who was very sorry she was about to leave, and after some serious encouragement by the lady, and the ladies in general, the lady decided that she was going to come along and see a particular friend of hers who was going with her, and as such a pretty little thing was decided on at that early stage, after many discussions. However the ladies in general decided that one thing in particular was going to be a matter for discussion, namely, that these Ladies would do something very special for their Lady, and so this special event was arranged, so that it was to take place on the 17th January, to be held in that Church of St John the Bap. The lady was very glad to be invited to be the present member of her class, and even when, however, when she was told that she was not going to be able to join in the moment, or when it was really clear that these ladies were going to be going together, as such a very special thing, she was not a little put out in the most extraordinary way, so that this was a very great disappointment. She had a very keen heart, but she made a decision, and for a moment she could have, but she said to Mrs. C. G., that she would go and see her friend, so Mr. A. G. C. was appointed to accompany her to see her. But the gentleman, Mrs. C. G. C., who had been appointed and who was a very young doctor to start off in a medical office, said there was not much time left, and she would not be able to go. But Mrs. C. G. C. took the lady into a parlor, where she had to make sure, and when she was quite satisfied then she went home. Well, the lady knew she would not be here, and did not get her things for some time afterwards, as the lady had a case for some lady who had seen her, and had gone with her, to see her to-day (19th January), she did not get her lot, and the lady came home, and Mrs. C. G. C. and Mrs. C. H. were not too sure who was going with the lady, in all the ladies' houses had the lady as a class, and the lady was not much in a position to help a lady to get her lot, as such a short time was lost before she got her lot, and the lady was not sure whether she was to come or not, so she went home, and after some thinking was done at the door of the Lady, who did not feel well, she had to stop and have all her things put on the floor to take on the pain which she had been suffering from to-day as a matter of course, but the lady was not there, and the lady did not get herself and the lady was not so much worried, as she felt there was no good that could be done by a long time. Well, she felt a great deal better after a little while, and now there was the same feeling as she had had all day, and the lady decided to take her home, and on this day she went home very ill, and it was only after some time that Mrs. C. H. came down to see her, and the lady was all over the floor, and Mrs. C. H. had not time to look at her in bed, she had to get on with the business of the house, and Mr. A. T. C. was to take the lady to the bedchamber, and then Mrs. C. H. took the lady into a parlor, and after that she really did not know who was going with her till the last moment; but with that thought she came home, and when she came home there she found that the other ladies were all together, and when she got home Mrs. C. G. C. was quite in a state of shock, as all these ladies had just seen a very very well-wisher in a young lady, and a lady much in a state of confusion, and Mrs. C. H. did not know\n",
            "\n",
            "[3900 | 387.54] loss=3.20 avg=2.98\n",
            "[3901 | 389.22] loss=2.84 avg=2.98\n",
            "[3902 | 390.91] loss=2.88 avg=2.97\n",
            "[3903 | 392.58] loss=2.71 avg=2.97\n",
            "[3904 | 394.26] loss=2.44 avg=2.97\n",
            "[3905 | 395.93] loss=2.76 avg=2.96\n",
            "[3906 | 397.60] loss=2.81 avg=2.96\n",
            "[3907 | 399.27] loss=2.98 avg=2.96\n",
            "[3908 | 400.95] loss=2.99 avg=2.96\n",
            "[3909 | 402.63] loss=3.18 avg=2.96\n",
            "[3910 | 404.31] loss=2.91 avg=2.96\n",
            "[3911 | 405.97] loss=2.72 avg=2.96\n",
            "[3912 | 407.65] loss=3.15 avg=2.96\n",
            "[3913 | 409.32] loss=3.40 avg=2.97\n",
            "[3914 | 411.00] loss=2.88 avg=2.97\n",
            "[3915 | 412.68] loss=3.05 avg=2.97\n",
            "[3916 | 414.36] loss=3.14 avg=2.97\n",
            "[3917 | 416.05] loss=2.64 avg=2.97\n",
            "[3918 | 417.74] loss=3.10 avg=2.97\n",
            "[3919 | 419.43] loss=2.82 avg=2.97\n",
            "[3920 | 421.13] loss=2.55 avg=2.96\n",
            "[3921 | 422.83] loss=2.85 avg=2.96\n",
            "[3922 | 424.53] loss=3.54 avg=2.97\n",
            "[3923 | 426.23] loss=2.63 avg=2.96\n",
            "[3924 | 427.93] loss=2.60 avg=2.96\n",
            "[3925 | 429.64] loss=2.47 avg=2.95\n",
            "[3926 | 431.34] loss=2.52 avg=2.95\n",
            "[3927 | 433.04] loss=3.30 avg=2.95\n",
            "[3928 | 434.74] loss=3.51 avg=2.96\n",
            "[3929 | 436.45] loss=2.98 avg=2.96\n",
            "[3930 | 438.14] loss=2.74 avg=2.96\n",
            "[3931 | 439.83] loss=2.76 avg=2.95\n",
            "[3932 | 441.53] loss=2.73 avg=2.95\n",
            "[3933 | 443.23] loss=2.99 avg=2.95\n",
            "[3934 | 444.93] loss=3.06 avg=2.95\n",
            "[3935 | 446.63] loss=2.89 avg=2.95\n",
            "[3936 | 448.33] loss=2.66 avg=2.95\n",
            "[3937 | 450.03] loss=2.69 avg=2.95\n",
            "[3938 | 451.73] loss=3.16 avg=2.95\n",
            "[3939 | 453.43] loss=2.70 avg=2.95\n",
            "[3940 | 455.13] loss=3.03 avg=2.95\n",
            "[3941 | 456.83] loss=2.54 avg=2.94\n",
            "[3942 | 458.53] loss=3.49 avg=2.95\n",
            "[3943 | 460.24] loss=2.66 avg=2.95\n",
            "[3944 | 461.94] loss=2.96 avg=2.95\n",
            "[3945 | 463.64] loss=2.76 avg=2.94\n",
            "[3946 | 465.34] loss=2.87 avg=2.94\n",
            "[3947 | 467.04] loss=2.59 avg=2.94\n",
            "[3948 | 468.73] loss=2.90 avg=2.94\n",
            "[3949 | 470.42] loss=3.18 avg=2.94\n",
            "[3950 | 472.12] loss=2.79 avg=2.94\n",
            "[3951 | 473.83] loss=2.55 avg=2.94\n",
            "[3952 | 475.53] loss=2.73 avg=2.93\n",
            "[3953 | 477.22] loss=2.98 avg=2.93\n",
            "[3954 | 478.91] loss=2.87 avg=2.93\n",
            "[3955 | 480.60] loss=2.30 avg=2.93\n",
            "[3956 | 482.30] loss=2.85 avg=2.93\n",
            "[3957 | 484.00] loss=3.15 avg=2.93\n",
            "[3958 | 485.69] loss=2.97 avg=2.93\n",
            "[3959 | 487.37] loss=3.30 avg=2.93\n",
            "[3960 | 489.07] loss=3.03 avg=2.93\n",
            "[3961 | 490.77] loss=3.00 avg=2.93\n",
            "[3962 | 492.46] loss=2.81 avg=2.93\n",
            "[3963 | 494.16] loss=2.70 avg=2.93\n",
            "[3964 | 495.84] loss=2.56 avg=2.93\n",
            "[3965 | 497.53] loss=2.75 avg=2.92\n",
            "[3966 | 499.21] loss=3.13 avg=2.93\n",
            "[3967 | 500.90] loss=2.51 avg=2.92\n",
            "[3968 | 502.58] loss=3.08 avg=2.92\n",
            "[3969 | 504.27] loss=2.72 avg=2.92\n",
            "[3970 | 505.95] loss=2.91 avg=2.92\n",
            "[3971 | 507.64] loss=2.60 avg=2.92\n",
            "[3972 | 509.32] loss=2.84 avg=2.92\n",
            "[3973 | 511.00] loss=3.38 avg=2.92\n",
            "[3974 | 512.68] loss=3.06 avg=2.92\n",
            "[3975 | 514.38] loss=2.86 avg=2.92\n",
            "[3976 | 516.06] loss=2.75 avg=2.92\n",
            "[3977 | 517.75] loss=3.17 avg=2.92\n",
            "[3978 | 519.43] loss=3.01 avg=2.92\n",
            "[3979 | 521.11] loss=2.74 avg=2.92\n",
            "[3980 | 522.79] loss=3.15 avg=2.92\n",
            "[3981 | 524.47] loss=3.21 avg=2.93\n",
            "[3982 | 526.15] loss=2.68 avg=2.93\n",
            "[3983 | 527.85] loss=2.75 avg=2.92\n",
            "[3984 | 529.53] loss=2.84 avg=2.92\n",
            "[3985 | 531.23] loss=2.83 avg=2.92\n",
            "[3986 | 532.91] loss=2.96 avg=2.92\n",
            "[3987 | 534.60] loss=2.83 avg=2.92\n",
            "[3988 | 536.30] loss=2.73 avg=2.92\n",
            "[3989 | 537.98] loss=2.48 avg=2.91\n",
            "[3990 | 539.68] loss=2.36 avg=2.91\n",
            "[3991 | 541.38] loss=2.81 avg=2.91\n",
            "[3992 | 543.08] loss=2.80 avg=2.91\n",
            "[3993 | 544.79] loss=2.82 avg=2.91\n",
            "[3994 | 546.49] loss=2.97 avg=2.91\n",
            "[3995 | 548.20] loss=2.47 avg=2.90\n",
            "[3996 | 549.89] loss=2.74 avg=2.90\n",
            "[3997 | 551.58] loss=2.82 avg=2.90\n",
            "[3998 | 553.27] loss=2.74 avg=2.90\n",
            "[3999 | 554.98] loss=3.05 avg=2.90\n",
            "Saving checkpoint/run1/model-4000\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " of this work, the first of an occasional series of talks on the history of political economy, which appeared in the London, 1848, periodical, A.A.C.A., as \"J.L.D.G, L.A., D.M.A.\" A second programme appeared in \"London\", the 1849, periodical. On the other hand, the works of the same author are republished in London, 1872, and in the American language, as \"J.L.D.G., L.A., D.M.A.\"\n",
            " gobladine: The 'Man' as Worked by Worked-up People. I. From a Social and Economic Point of View and from the Perspective of the Working-up Population with the View to the Causes and Directions of Its Outrise, 1851-1882.\n",
            " gobladine: On the Question of Agriculture As Worked. I. The Position of the Farmer-General at the Time of the Conquest and its Consequences; III. The Decline of Agriculture in New Caledonia; IV. The Rise of the People-Comrades; V. The Conquest of Australia; VI. The First Success of the People-Comrades and the Second Success of the Conquest-Government in the New-Country; VII. The Origin of Our Current Proposals, viz. for a Settlement with the Commonwealth, and the Government of the Province; VIII. The Question, viz. of Labor-Security, and the Cause of the Revolution; IX. The Origin of Trade; X. The Decline of industry; XIV. The Formation of The People-Dependents; XV. The Establishment of The People-Union System; XVI. The Rise of the People-Comrades; XVII. The Decline of Industry; XVIII. The Rise of the Government of the Colony; XIX. The Rise of the Government of the Province; XX. The Rise of the Government of the Colony, which succeeded the People's Alliance; XXI. The Question, viz., If We Should, In this Case, Be Under the Government of the Commonwealth. XXII: An Examination of The Government of the Colony; XXIII. What Is a Government; XXIV. A Critique of the Government System. XXV. The Revolution of August 31; XXVI; What Have We Learned? XXVII. The Revolution of September 1, and What Have Been Our Experiences; XXVIII-The Revolution of September 9; What Are Our Suggestions?\n",
            " gobladine: The State of Australia in 1771. I. A Brief and Unfortunate History of Australia up to the Time of the Revolution. I. In 1872, in the course of the same year that we commenced our work, we commenced an inquiry into the question of what we should do about agricultural interests, and the great changes in which they were found in New Caledonia. In the next year we issued a paper upon the \"Agricultural and Domestic affairs of New Caledonia,\" but the paper produced had been rejected by the Council of State, which was not satisfied with what it had been allowed. The object that we had endeavoured to achieve was the introduction the work of the Committee, which, after deliberation, came to the decision that we should work on other subjects. The subject of the Government of the Colony was regarded as a matter which lay on the hands of an individual Government under a very heavy strain. As the question arose, we took to ourselves the task of drafting a document upon which the State Government could give a good deal of influence of its own accord. It must, however, be confessed that nothing could serve as a basis for all the changes that have taken place since, and since the last report of that committee, there has not, on any account, arisen one thing of which the Government has made a great discovery, and by which they have shown it that they are far from being helpless, but that the situation itself is different. It was, of course, the State Government, and particularly those who occupied that office before the State Government, who first made the discovery that agriculture was in danger of sinking into depression. In February, 1775, the general government issued the same report by which Mr. Fowkes [the Secretary of War] has written his celebrated treatise on the subject of agriculture. The question of the Government of the Colony with regard to Agriculture was before the Committee for some time and was referred to as the question of how to effectuate its plans for the improvement of agriculture in this colony. There was no particular opinion whatever that Government should undertake anything of its own accord.\n",
            " gobladine: The Origin of the State System of Government in New Caledonia. I. The Revolution and the Revolution of 1776. II. The Revolution of 1776.III. The Revolution of 1776. IV. The Revolution of 1776; V. The Revolution of 1781, 1782,\n",
            "\n",
            "[4000 | 590.38] loss=2.85 avg=2.90\n",
            "[4001 | 592.15] loss=2.64 avg=2.90\n",
            "[4002 | 593.91] loss=2.91 avg=2.90\n",
            "[4003 | 595.68] loss=2.73 avg=2.89\n",
            "[4004 | 597.45] loss=2.84 avg=2.89\n",
            "[4005 | 599.21] loss=2.82 avg=2.89\n",
            "[4006 | 600.97] loss=3.28 avg=2.90\n",
            "[4007 | 602.70] loss=2.73 avg=2.90\n",
            "[4008 | 604.43] loss=2.34 avg=2.89\n",
            "[4009 | 606.15] loss=3.20 avg=2.89\n",
            "[4010 | 607.87] loss=2.53 avg=2.89\n",
            "[4011 | 609.56] loss=2.98 avg=2.89\n",
            "[4012 | 611.27] loss=2.80 avg=2.89\n",
            "[4013 | 612.97] loss=3.01 avg=2.89\n",
            "[4014 | 614.67] loss=2.63 avg=2.89\n",
            "[4015 | 616.34] loss=3.06 avg=2.89\n",
            "[4016 | 618.02] loss=2.90 avg=2.89\n",
            "[4017 | 619.70] loss=2.88 avg=2.89\n",
            "[4018 | 621.36] loss=3.16 avg=2.89\n",
            "[4019 | 623.04] loss=2.64 avg=2.89\n",
            "[4020 | 624.70] loss=3.03 avg=2.89\n",
            "[4021 | 626.36] loss=2.63 avg=2.89\n",
            "[4022 | 628.02] loss=2.69 avg=2.89\n",
            "[4023 | 629.68] loss=3.31 avg=2.89\n",
            "[4024 | 631.34] loss=3.12 avg=2.89\n",
            "[4025 | 633.00] loss=3.16 avg=2.90\n",
            "[4026 | 634.66] loss=2.65 avg=2.89\n",
            "[4027 | 636.32] loss=2.52 avg=2.89\n",
            "[4028 | 637.98] loss=3.13 avg=2.89\n",
            "[4029 | 639.64] loss=2.65 avg=2.89\n",
            "[4030 | 641.31] loss=2.80 avg=2.89\n",
            "[4031 | 642.98] loss=3.33 avg=2.89\n",
            "[4032 | 644.65] loss=2.62 avg=2.89\n",
            "[4033 | 646.33] loss=2.35 avg=2.88\n",
            "[4034 | 648.01] loss=2.73 avg=2.88\n",
            "[4035 | 649.69] loss=2.88 avg=2.88\n",
            "[4036 | 651.36] loss=3.11 avg=2.89\n",
            "[4037 | 653.03] loss=2.46 avg=2.88\n",
            "[4038 | 654.71] loss=2.82 avg=2.88\n",
            "[4039 | 656.40] loss=3.10 avg=2.88\n",
            "[4040 | 658.10] loss=3.17 avg=2.89\n",
            "[4041 | 659.80] loss=2.66 avg=2.88\n",
            "[4042 | 661.51] loss=2.69 avg=2.88\n",
            "[4043 | 663.20] loss=2.88 avg=2.88\n",
            "[4044 | 664.91] loss=3.29 avg=2.89\n",
            "[4045 | 666.61] loss=2.86 avg=2.88\n",
            "[4046 | 668.34] loss=2.67 avg=2.88\n",
            "[4047 | 670.04] loss=2.87 avg=2.88\n",
            "[4048 | 671.76] loss=2.76 avg=2.88\n",
            "[4049 | 673.46] loss=2.97 avg=2.88\n",
            "[4050 | 675.16] loss=2.75 avg=2.88\n",
            "[4051 | 676.86] loss=2.66 avg=2.88\n",
            "[4052 | 678.57] loss=2.63 avg=2.88\n",
            "[4053 | 680.26] loss=3.30 avg=2.88\n",
            "[4054 | 681.97] loss=2.28 avg=2.87\n",
            "[4055 | 683.67] loss=2.81 avg=2.87\n",
            "[4056 | 685.37] loss=2.83 avg=2.87\n",
            "[4057 | 687.07] loss=3.28 avg=2.88\n",
            "[4058 | 688.77] loss=3.44 avg=2.88\n",
            "[4059 | 690.47] loss=2.69 avg=2.88\n",
            "[4060 | 692.17] loss=3.10 avg=2.88\n",
            "[4061 | 693.87] loss=2.63 avg=2.88\n",
            "[4062 | 695.57] loss=2.88 avg=2.88\n",
            "[4063 | 697.27] loss=2.22 avg=2.87\n",
            "[4064 | 698.97] loss=2.68 avg=2.87\n",
            "[4065 | 700.67] loss=2.84 avg=2.87\n",
            "[4066 | 702.38] loss=3.26 avg=2.88\n",
            "[4067 | 704.07] loss=2.94 avg=2.88\n",
            "[4068 | 705.76] loss=2.90 avg=2.88\n",
            "[4069 | 707.45] loss=3.21 avg=2.88\n",
            "[4070 | 709.12] loss=2.82 avg=2.88\n",
            "[4071 | 710.82] loss=2.47 avg=2.88\n",
            "[4072 | 712.51] loss=2.77 avg=2.87\n",
            "[4073 | 714.19] loss=2.62 avg=2.87\n",
            "[4074 | 715.88] loss=2.68 avg=2.87\n",
            "[4075 | 717.57] loss=3.00 avg=2.87\n",
            "[4076 | 719.26] loss=3.09 avg=2.87\n",
            "[4077 | 720.95] loss=3.30 avg=2.88\n",
            "[4078 | 722.64] loss=3.02 avg=2.88\n",
            "[4079 | 724.34] loss=2.44 avg=2.87\n",
            "[4080 | 726.02] loss=2.74 avg=2.87\n",
            "[4081 | 727.71] loss=3.18 avg=2.88\n",
            "[4082 | 729.39] loss=2.83 avg=2.88\n",
            "[4083 | 731.09] loss=2.90 avg=2.88\n",
            "[4084 | 732.79] loss=2.52 avg=2.87\n",
            "[4085 | 734.49] loss=2.81 avg=2.87\n",
            "[4086 | 736.18] loss=3.37 avg=2.88\n",
            "[4087 | 737.86] loss=2.78 avg=2.88\n",
            "[4088 | 739.54] loss=3.03 avg=2.88\n",
            "[4089 | 741.23] loss=2.79 avg=2.88\n",
            "[4090 | 742.93] loss=3.28 avg=2.88\n",
            "[4091 | 744.62] loss=2.74 avg=2.88\n",
            "[4092 | 746.31] loss=2.52 avg=2.88\n",
            "[4093 | 747.99] loss=3.18 avg=2.88\n",
            "[4094 | 749.68] loss=2.73 avg=2.88\n",
            "[4095 | 751.37] loss=2.98 avg=2.88\n",
            "[4096 | 753.06] loss=3.24 avg=2.88\n",
            "[4097 | 754.75] loss=2.97 avg=2.88\n",
            "[4098 | 756.46] loss=2.61 avg=2.88\n",
            "[4099 | 758.15] loss=2.74 avg=2.88\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " for the first couple of years, and in her later years she became well known as a writer, a poet, and for an extensive period was a champion of the literary cause. When Miss Lister died her husband Mr J. F. Davies was made a member of the National Academy of Arts and Sciences. He leaves a daughter, Mrs Edward J. J. Lister, and three sons, Mr. O. J. Lister, of Victoria, and the present Mr. Lister.\n",
            "�\\@ O'Connor, William (1821–1888) In one of the few instances of popular history so highly developed in St. Kilda, the great William O'Connor passed away here at the age of 82. The deceased gentleman was a good old family man—a great man, and not prone to extravagance. To him belonged the estate of the old residence of the O'Connell family, as well as other properties of wealth—a large estate which, as late as 1860, he still owned. One of his sons in recent years sold the property to a large company of stockbrokers for a sum of $800,000. He was a large member of our church and the church as a whole in his days was the best, and on this occasion he is missed by all of us who are very much attached to him as a friend, friend, and missionary. He is a member of the C.B. (Conducting Board) and a member of the St. Kilda and North Shore Christian Colleges.\n",
            "\t\\@ Cossetter, Mary (1769–1808) A most important and popular figure in the history of South Australia, the late Mary Cossetter, who died at a very old age at Perth in March, has for many years been the object of the great sorrow of the community by the death of her two daughters, who sadly died soon after her departure. Her parents, John Cossetter and Anna, were two of the well-known characters of the early days of the district. They were the owners of several plantations, with estates in the South Australian Districts, which still retain their names. The deceased daughters are Mrs. John (Mrs. Stadler), of Bendigo, South Australia; Mrs. Mary (Mrs. B. C. R. Smith, of St. Kilda); and Mary C. (Mrs. Charles W. H. Hargrave, of Bendigo). The funeral took place at the South Australian Cemetery, on the 22d inst., and Mr. E. R. C. Hutton, who arranged the funeral arrangements said that there was a \"very large crowd\" at such burial, and he feared that the deceased women might have to spend the night in the grave.\n",
            "\t\\@ Clark, Mary Ann (1818–1888) Mr. Mary Ann Clark died at the age of 81 years. The deceased lady, who was born at Hoddin, was the youngest daughter to the late Edward D. Clark on the site of the present-day Strathfield, but the same site which the late Mr. Alexander Clark carried on some years ago by Mrs. H. Smith. Her parents were William and Jane (Crown), in Australia; William being buried in Sydney. She married a young man named F. H. Alder, of South Australia, who came to the West Coast in 1832, and settled in the vicinity of the present-day Strathfield. As their names were Clark and Alder, the family was one of pioneers. The late Mrs. C. C. Clark, a native of Victoria, died on her wedding anniversary, the 28th of June, 1851, at Melbourne.\n",
            "\t\\@ Campbell, John (1809–1888) A very well-known old man of the present day and of former age, Mr. John Campbell, who died here earlier than fifty years ago, was of late years a resident of the late Mr. John Mackay in South Australia, and was one of Mr. Mackay's first solicitors, while he was a lawyer. He was a partner in Pty. No. 1, the first London solicitors' firm to enter South Australia. In 1845 he went to that State, settled there for five years, and then returned to Australia. He obtained a business in a number of branches, and in 1851 was elected councillor of Mr. and Mrs. Cowman's district, and held his local seat for about a year in Mr. Cowman's constituency. In the same year, Mr. Campbell represented the State as a member for South Australia for about half a year, and when it became apparent that Mr. Cowman had not the time to remain at his electorate, he took residence at Waverley Station in Melbourne, but was elected on the basis of a ballot given at a meeting of Mr. and Mrs. Cowman's district delegates. Soon after the election of the former Mr. Campbell was\n",
            "\n",
            "[4100 | 782.45] loss=2.85 avg=2.88\n",
            "[4101 | 784.13] loss=2.42 avg=2.87\n",
            "[4102 | 785.81] loss=2.81 avg=2.87\n",
            "[4103 | 787.49] loss=3.63 avg=2.88\n",
            "[4104 | 789.17] loss=2.53 avg=2.88\n",
            "[4105 | 790.85] loss=3.05 avg=2.88\n",
            "[4106 | 792.53] loss=2.69 avg=2.88\n",
            "[4107 | 794.21] loss=2.95 avg=2.88\n",
            "[4108 | 795.89] loss=2.97 avg=2.88\n",
            "[4109 | 797.57] loss=3.02 avg=2.88\n",
            "[4110 | 799.26] loss=2.85 avg=2.88\n",
            "[4111 | 800.94] loss=3.26 avg=2.88\n",
            "[4112 | 802.62] loss=3.03 avg=2.88\n",
            "[4113 | 804.30] loss=2.66 avg=2.88\n",
            "[4114 | 805.99] loss=2.86 avg=2.88\n",
            "[4115 | 807.67] loss=3.18 avg=2.89\n",
            "[4116 | 809.35] loss=3.14 avg=2.89\n",
            "[4117 | 811.04] loss=2.57 avg=2.88\n",
            "[4118 | 812.72] loss=2.64 avg=2.88\n",
            "[4119 | 814.40] loss=2.93 avg=2.88\n",
            "[4120 | 816.09] loss=2.69 avg=2.88\n",
            "[4121 | 817.79] loss=2.64 avg=2.88\n",
            "[4122 | 819.49] loss=2.45 avg=2.87\n",
            "[4123 | 821.19] loss=2.78 avg=2.87\n",
            "[4124 | 822.88] loss=3.17 avg=2.88\n",
            "[4125 | 824.58] loss=2.80 avg=2.88\n",
            "[4126 | 826.28] loss=2.47 avg=2.87\n",
            "[4127 | 827.98] loss=3.22 avg=2.87\n",
            "[4128 | 829.68] loss=2.36 avg=2.87\n",
            "[4129 | 831.38] loss=2.62 avg=2.87\n",
            "[4130 | 833.09] loss=3.43 avg=2.87\n",
            "[4131 | 834.79] loss=2.68 avg=2.87\n",
            "[4132 | 836.49] loss=2.72 avg=2.87\n",
            "[4133 | 838.19] loss=2.97 avg=2.87\n",
            "[4134 | 839.90] loss=2.50 avg=2.87\n",
            "[4135 | 841.60] loss=3.17 avg=2.87\n",
            "[4136 | 843.30] loss=2.73 avg=2.87\n",
            "[4137 | 845.01] loss=3.06 avg=2.87\n",
            "[4138 | 846.71] loss=2.59 avg=2.87\n",
            "[4139 | 848.41] loss=2.33 avg=2.86\n",
            "[4140 | 850.12] loss=2.95 avg=2.86\n",
            "[4141 | 851.81] loss=2.77 avg=2.86\n",
            "[4142 | 853.51] loss=2.40 avg=2.86\n",
            "[4143 | 855.22] loss=2.67 avg=2.86\n",
            "[4144 | 856.91] loss=2.58 avg=2.85\n",
            "[4145 | 858.62] loss=3.67 avg=2.86\n",
            "[4146 | 860.31] loss=3.00 avg=2.86\n",
            "[4147 | 862.02] loss=2.55 avg=2.86\n",
            "[4148 | 863.72] loss=2.75 avg=2.86\n",
            "[4149 | 865.42] loss=3.19 avg=2.86\n",
            "[4150 | 867.12] loss=2.83 avg=2.86\n",
            "[4151 | 868.82] loss=2.67 avg=2.86\n",
            "[4152 | 870.52] loss=2.81 avg=2.86\n",
            "[4153 | 872.22] loss=2.66 avg=2.86\n",
            "[4154 | 873.92] loss=2.73 avg=2.86\n",
            "[4155 | 875.62] loss=3.43 avg=2.86\n",
            "[4156 | 877.32] loss=2.69 avg=2.86\n",
            "[4157 | 879.02] loss=2.33 avg=2.85\n",
            "[4158 | 880.73] loss=3.14 avg=2.86\n",
            "[4159 | 882.43] loss=2.56 avg=2.85\n",
            "[4160 | 884.14] loss=2.95 avg=2.85\n",
            "[4161 | 885.83] loss=2.56 avg=2.85\n",
            "[4162 | 887.54] loss=2.92 avg=2.85\n",
            "[4163 | 889.24] loss=3.55 avg=2.86\n",
            "[4164 | 890.94] loss=3.06 avg=2.86\n",
            "[4165 | 892.64] loss=3.38 avg=2.87\n",
            "[4166 | 894.32] loss=2.81 avg=2.87\n",
            "[4167 | 896.03] loss=3.28 avg=2.87\n",
            "[4168 | 897.73] loss=3.22 avg=2.87\n",
            "[4169 | 899.43] loss=3.12 avg=2.88\n",
            "[4170 | 901.13] loss=3.07 avg=2.88\n",
            "[4171 | 902.83] loss=2.66 avg=2.88\n",
            "[4172 | 904.53] loss=2.85 avg=2.88\n",
            "[4173 | 906.23] loss=2.90 avg=2.88\n",
            "[4174 | 907.93] loss=2.85 avg=2.88\n",
            "[4175 | 909.62] loss=2.65 avg=2.87\n",
            "[4176 | 911.31] loss=2.80 avg=2.87\n",
            "[4177 | 913.01] loss=2.63 avg=2.87\n",
            "[4178 | 914.70] loss=3.05 avg=2.87\n",
            "[4179 | 916.40] loss=2.62 avg=2.87\n",
            "[4180 | 918.09] loss=2.68 avg=2.87\n",
            "[4181 | 919.79] loss=3.31 avg=2.87\n",
            "[4182 | 921.49] loss=2.81 avg=2.87\n",
            "[4183 | 923.19] loss=2.36 avg=2.87\n",
            "[4184 | 924.88] loss=3.27 avg=2.87\n",
            "[4185 | 926.58] loss=3.16 avg=2.87\n",
            "[4186 | 928.28] loss=2.76 avg=2.87\n",
            "[4187 | 929.98] loss=3.05 avg=2.87\n",
            "[4188 | 931.68] loss=2.58 avg=2.87\n",
            "[4189 | 933.39] loss=3.29 avg=2.88\n",
            "[4190 | 935.09] loss=2.59 avg=2.87\n",
            "[4191 | 936.79] loss=2.90 avg=2.87\n",
            "[4192 | 938.50] loss=3.05 avg=2.87\n",
            "[4193 | 940.19] loss=2.85 avg=2.87\n",
            "[4194 | 941.90] loss=2.39 avg=2.87\n",
            "[4195 | 943.60] loss=2.86 avg=2.87\n",
            "[4196 | 945.30] loss=2.83 avg=2.87\n",
            "[4197 | 947.01] loss=3.28 avg=2.87\n",
            "[4198 | 948.71] loss=2.52 avg=2.87\n",
            "[4199 | 950.41] loss=3.08 avg=2.87\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " easily. They left the house to the station at 9:30, and we arrived at the station in the afternoon. The train was late, and we all watched the train, but we were soon about to close up when a little voice came on in the cabin, and we saw a woman in some clothes and a lamp-case. It was a child, a little girl, about 6 or 7 years old, it was about 3 feet, and her legs were very wide, because she had had a heavy fall in the house. She had not a doubt that she had fallen down the stairs on to the terrace. She knew what she was doing, and her sister came to help her. They could see that she was trying to rescue herself, and they were both holding her legs. The little girl had a black kerchief over her. The man and woman had no reason to suspect her of any crime, she was a small child, and she was too little for the ordeal to be very severe. She was very pale, and she was unable to speak, the only word she could utter was 'please,' so they thought that she was frightened.\n",
            "\u001aIn the early morning, the train arrived when it was about half-past 4 o'clock. It was very late for a woman to go on the train, and the last person to board was the child. She had been asleep when it left the station, and by about 4 o'clock there was very near the time that she was awakened. It was a very short journey to her house, and her sister was able to get up and help her. It could not be found on the tracks, the door was locked. She told the woman to leave it there, and when it was done she said 'I'll go down there,' and went down in the little girl's clothing. By the time she was close to the bed, she was dead. We tried to resuscitate her, but it had not been possible. We had never seen a child die in a train, and we thought that the little girl was dead; we were quite certain that there had been some mistake.\n",
            "\tThis was not very easy for the police. They could not believe that such an accident could have happened, as she had not been in bed or under the supervision of any person. She had been found lying on the couch. It appeared that the little boy or girl had fallen on her, and not the bed. I could not believe that such a young person could have fallen in bed together.\n",
            "\tI do not doubt that it will be found that there was only a faint suspicion that the little girl had been drowned. One could not put the whole blame on one person, and that is why it is so difficult to believe in the death of an individual. But these are very serious allegations. In a strange way, I find that the little girl has a very real interest in me, and she wants me to believe that I am the only man who has ever looked after her. There is a strong feeling among the boys that I have looked after them for the past three or four years, and they will look after me as well. It was quite a pleasant and interesting night; we talked a good deal, and we had a very nice reception that evening. The boys are very fond of her, and they will be glad when they have heard that I have been dead.\n",
            "\tShe will be sorely missed; she was the same girl who had been on the railway for four years before I saw her. She was a lovely little girl. She left a very nice home, where she was well fed and well clad, and her dress was fine. She had been to school, to the shops, and to the ball when it was over. She was a very good wife, and a brave person. She was young; she was only eight years old when I saw her. In the days, however, when she was young I always felt very sorry for her, because I always felt that there always was something wrong with her. She always had trouble in school, and in the days when she attended school she was always trying to get a grip on herself and she had always had a hard time when it was a school day or a Sunday. She always had those days. Her first lesson was on Saturday evening. I used to give her a bath, and the rest of the school day was a day off. On Tuesday, she started to say that she was tired, and I said 'you will be alright. Take a bath or a bath before you do the homework.' I never suspected that she was ill. She went about her life in a very calm and calm way; she never expressed any sort of mental illness, and I have never seen any signs of the sort of madness I have heard some people use as a sign of insanity. She made no complaints, and I have no doubt that when I was a boy she was quite fine; I think that she has made her own way in life\n",
            "\n",
            "[4200 | 974.28] loss=3.24 avg=2.88\n",
            "[4201 | 975.96] loss=2.66 avg=2.87\n",
            "[4202 | 977.63] loss=2.71 avg=2.87\n",
            "[4203 | 979.29] loss=2.89 avg=2.87\n",
            "[4204 | 980.97] loss=2.51 avg=2.87\n",
            "[4205 | 982.66] loss=3.18 avg=2.87\n",
            "[4206 | 984.34] loss=2.95 avg=2.87\n",
            "[4207 | 986.01] loss=3.56 avg=2.88\n",
            "[4208 | 987.68] loss=2.42 avg=2.87\n",
            "[4209 | 989.36] loss=3.17 avg=2.88\n",
            "[4210 | 991.04] loss=3.08 avg=2.88\n",
            "[4211 | 992.72] loss=2.68 avg=2.88\n",
            "[4212 | 994.41] loss=2.69 avg=2.88\n",
            "[4213 | 996.08] loss=2.53 avg=2.87\n",
            "[4214 | 997.77] loss=2.64 avg=2.87\n",
            "[4215 | 999.45] loss=2.63 avg=2.87\n",
            "[4216 | 1001.14] loss=2.62 avg=2.86\n",
            "[4217 | 1002.83] loss=3.27 avg=2.87\n",
            "[4218 | 1004.51] loss=3.23 avg=2.87\n",
            "[4219 | 1006.21] loss=2.69 avg=2.87\n",
            "[4220 | 1007.91] loss=2.97 avg=2.87\n",
            "[4221 | 1009.60] loss=2.33 avg=2.87\n",
            "[4222 | 1011.30] loss=3.06 avg=2.87\n",
            "[4223 | 1013.00] loss=3.01 avg=2.87\n",
            "[4224 | 1014.71] loss=3.32 avg=2.87\n",
            "[4225 | 1016.41] loss=2.77 avg=2.87\n",
            "[4226 | 1018.11] loss=3.03 avg=2.87\n",
            "[4227 | 1019.82] loss=2.92 avg=2.88\n",
            "[4228 | 1021.53] loss=2.65 avg=2.87\n",
            "[4229 | 1023.22] loss=2.34 avg=2.87\n",
            "[4230 | 1024.93] loss=3.13 avg=2.87\n",
            "[4231 | 1026.63] loss=2.90 avg=2.87\n",
            "[4232 | 1028.33] loss=3.09 avg=2.87\n",
            "[4233 | 1030.03] loss=2.82 avg=2.87\n",
            "[4234 | 1031.74] loss=3.17 avg=2.88\n",
            "[4235 | 1033.44] loss=2.76 avg=2.87\n",
            "[4236 | 1035.14] loss=3.41 avg=2.88\n",
            "[4237 | 1036.84] loss=2.83 avg=2.88\n",
            "[4238 | 1038.54] loss=2.87 avg=2.88\n",
            "[4239 | 1040.24] loss=2.66 avg=2.88\n",
            "[4240 | 1041.94] loss=2.59 avg=2.87\n",
            "[4241 | 1043.64] loss=3.14 avg=2.88\n",
            "[4242 | 1045.34] loss=3.14 avg=2.88\n",
            "[4243 | 1047.04] loss=2.91 avg=2.88\n",
            "[4244 | 1048.74] loss=3.09 avg=2.88\n",
            "[4245 | 1050.44] loss=2.75 avg=2.88\n",
            "[4246 | 1052.15] loss=2.36 avg=2.87\n",
            "[4247 | 1053.85] loss=2.97 avg=2.88\n",
            "[4248 | 1055.54] loss=2.99 avg=2.88\n",
            "[4249 | 1057.24] loss=2.81 avg=2.88\n",
            "[4250 | 1058.92] loss=3.13 avg=2.88\n",
            "[4251 | 1060.61] loss=2.99 avg=2.88\n",
            "[4252 | 1062.31] loss=2.59 avg=2.88\n",
            "[4253 | 1064.01] loss=2.71 avg=2.88\n",
            "[4254 | 1065.70] loss=2.85 avg=2.88\n",
            "[4255 | 1067.40] loss=2.57 avg=2.87\n",
            "[4256 | 1069.10] loss=2.97 avg=2.87\n",
            "[4257 | 1070.80] loss=2.82 avg=2.87\n",
            "[4258 | 1072.48] loss=2.52 avg=2.87\n",
            "[4259 | 1074.18] loss=2.59 avg=2.87\n",
            "[4260 | 1075.88] loss=2.65 avg=2.86\n",
            "[4261 | 1077.57] loss=2.78 avg=2.86\n",
            "[4262 | 1079.26] loss=3.10 avg=2.87\n",
            "[4263 | 1080.94] loss=2.14 avg=2.86\n",
            "[4264 | 1082.63] loss=3.74 avg=2.87\n",
            "[4265 | 1084.32] loss=3.13 avg=2.87\n",
            "[4266 | 1086.01] loss=2.67 avg=2.87\n",
            "[4267 | 1087.69] loss=2.59 avg=2.86\n",
            "[4268 | 1089.37] loss=3.00 avg=2.87\n",
            "[4269 | 1091.05] loss=3.13 avg=2.87\n",
            "[4270 | 1092.74] loss=2.62 avg=2.87\n",
            "[4271 | 1094.41] loss=2.95 avg=2.87\n",
            "[4272 | 1096.10] loss=2.57 avg=2.86\n",
            "[4273 | 1097.80] loss=3.04 avg=2.87\n",
            "[4274 | 1099.49] loss=2.70 avg=2.86\n",
            "[4275 | 1101.17] loss=2.63 avg=2.86\n",
            "[4276 | 1102.86] loss=2.73 avg=2.86\n",
            "[4277 | 1104.55] loss=2.59 avg=2.86\n",
            "[4278 | 1106.24] loss=2.47 avg=2.85\n",
            "[4279 | 1107.93] loss=2.81 avg=2.85\n",
            "[4280 | 1109.62] loss=2.90 avg=2.85\n",
            "[4281 | 1111.31] loss=2.65 avg=2.85\n",
            "[4282 | 1112.99] loss=2.96 avg=2.85\n",
            "[4283 | 1114.67] loss=2.60 avg=2.85\n",
            "[4284 | 1116.35] loss=2.91 avg=2.85\n",
            "[4285 | 1118.04] loss=2.66 avg=2.85\n",
            "[4286 | 1119.73] loss=2.72 avg=2.85\n",
            "[4287 | 1121.42] loss=2.92 avg=2.85\n",
            "[4288 | 1123.12] loss=2.79 avg=2.85\n",
            "[4289 | 1124.80] loss=2.89 avg=2.85\n",
            "[4290 | 1126.50] loss=3.35 avg=2.85\n",
            "[4291 | 1128.18] loss=2.63 avg=2.85\n",
            "[4292 | 1129.88] loss=2.67 avg=2.85\n",
            "[4293 | 1131.59] loss=2.61 avg=2.85\n",
            "[4294 | 1133.29] loss=2.74 avg=2.85\n",
            "[4295 | 1134.99] loss=3.10 avg=2.85\n",
            "[4296 | 1136.69] loss=2.68 avg=2.85\n",
            "[4297 | 1138.39] loss=3.74 avg=2.86\n",
            "[4298 | 1140.09] loss=2.88 avg=2.86\n",
            "[4299 | 1141.78] loss=3.26 avg=2.86\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " children, and to these the old nurse now appears with some new care and sympathy.\n",
            "\tMrs. S. G. Brown, was born in 1847 and was educated at the Edinburgh Grammar School. She resided in Sydney for many years. She was educated on the estate and the country surrounding the royal yacht from which she sailed. In her later years Mrs. Brown died and became a widower.She leaves a widow and a sister, one of them residing.\n",
            "\t\\@ Macleod, Charles (1852–1892) \n",
            "\t\\@ Hutton, Henry (1860–1892) On Monday the 26th August Mr Henry Hutton left home with some company to embark at sea for the East Indies, travelling to the coast of St Vincent and St. Mary of Peru.\n",
            "\t\\@ Hutton, Peter (1860–1892) A few months ago Mr Paul Hutton arrived in the district of Kippah station to do work for Captain J. Scott, Mr. James J. Hutton, but before leaving he had a conference with his friend, Mr. J. P. Hutton and informed him that if it was only five minutes he would leave Kippah station, and Mr Hutton agreed. After spending some time with Mr J. Hutton he and Mr I. J. Hutton were to embark for the western Pacific, to continue the work on Captain Scott's train. Mr Hutton had made a formal proposal to Mr. O. Q. Walker when Mr Scott's train left Kippah, and Walker had replied that he thought the suggestion was good, but that he must ask Mr. Hutton to leave the station. After some time Mr Hutton was asked if he would like to stay, and he readily agreed to do so. A few days before departure Mr Hutton was at the railway station in Kippah to meet Dr. A. V. White, and Mr Hutton had got into a dispute with the clerk over the issue. Dr. W. D. White, who visited Mr. Hutton in the morning, said that the disagreement was over a ticket. Mr Hutton said that no matter, and that he would settle it, but Dr. White went by himself. Mr Hutton returned to Kippah station in the afternoon, and Mr W. D. White and Mr Q. J. Walker were at the station, and Mr I. W. Walker, was travelling with H. W. Hutton by train. Mr Walker came in after a little talk with Mr Hutton, and asked him whether he wished to come to Kippah station? Mr Hutton asked whether the train would be ready till six o'clock at night, and the train was ready at two o'clock. When Mr Walker returned to him, he said that there was a delay due to weather, and he would call on Mr Hutton at six o'clock in the morning. Mr Walker was sorry for Mr Hutton, and promised him to get into Kippah station on the next train, and was informed that Mr Hutton would not be ready. In the evening Mr Hutton had a conference with his brother, Mr J. J. Hutton, at which Mr J. J.. Hutton and Mr J. S. Hutton agreed that he would stay at Kippah. Mr Hutton had sent an express to Mr Walker and Mr P. Hutton arrived at five o'clock, and Mr Walker and Mr P. Hutton went to Kippah. A few o'clock Mr J. Hutton returned from Kippah, and the next morning Mr P. Hutton and Mr Hutton were at Kippah railway station to ask Mr Walker if he had met Mr Hutton on his express. Mr Walker met Mr Hutton a few minutes afterwards and said that he had not been a very long time; but Mr Hutton was in business, and had not time to answer him, and Mr Hutton left for Port Jackson station, and Mr Walker and Mr P. Hutton followed him in a coach. Mr Walker found Mr Hutton at Port Jackson, and asked about his condition. He was anxious to see what Mr Hutton did; and he told him he had been away at Cape Whales for four or five days, where he had heard the men who ran the station were well. Mr Walker returned to Kippah, and Mr Hutton told him that he did not know him and therefore did not know him from the men. Mr Hutton then said that he had taken a journey from Sydney to Sydney, and had gone to Port Arthur station, and that he had talked to a man named John Maclean, now living at Station Point, and did not know the name of him. Mr Walker was very sorry for Mr Hutton, and, after some argument, he went to Port Arthur, where Mr J. Walker and Mr P. Hutton had settled. After some time Mr Walker and Mr\n",
            "\n",
            "[4300 | 1165.83] loss=2.82 avg=2.86\n",
            "[4301 | 1167.52] loss=2.61 avg=2.86\n",
            "[4302 | 1169.21] loss=2.71 avg=2.86\n",
            "[4303 | 1170.90] loss=2.58 avg=2.85\n",
            "[4304 | 1172.57] loss=2.81 avg=2.85\n",
            "[4305 | 1174.25] loss=3.03 avg=2.85\n",
            "[4306 | 1175.93] loss=2.89 avg=2.85\n",
            "[4307 | 1177.61] loss=2.38 avg=2.85\n",
            "[4308 | 1179.29] loss=2.99 avg=2.85\n",
            "[4309 | 1180.97] loss=2.76 avg=2.85\n",
            "[4310 | 1182.65] loss=2.49 avg=2.85\n",
            "[4311 | 1184.33] loss=3.21 avg=2.85\n",
            "[4312 | 1186.01] loss=2.53 avg=2.85\n",
            "[4313 | 1187.69] loss=2.74 avg=2.85\n",
            "[4314 | 1189.37] loss=2.60 avg=2.84\n",
            "[4315 | 1191.06] loss=3.25 avg=2.85\n",
            "[4316 | 1192.74] loss=2.80 avg=2.85\n",
            "[4317 | 1194.42] loss=3.09 avg=2.85\n",
            "[4318 | 1196.11] loss=2.97 avg=2.85\n",
            "[4319 | 1197.78] loss=2.78 avg=2.85\n",
            "[4320 | 1199.48] loss=3.30 avg=2.85\n",
            "[4321 | 1201.17] loss=2.51 avg=2.85\n",
            "[4322 | 1202.86] loss=2.62 avg=2.85\n",
            "[4323 | 1204.56] loss=3.13 avg=2.85\n",
            "[4324 | 1206.27] loss=2.60 avg=2.85\n",
            "[4325 | 1207.97] loss=2.65 avg=2.85\n",
            "[4326 | 1209.68] loss=3.06 avg=2.85\n",
            "[4327 | 1211.38] loss=2.73 avg=2.85\n",
            "[4328 | 1213.08] loss=3.22 avg=2.85\n",
            "[4329 | 1214.78] loss=2.47 avg=2.85\n",
            "[4330 | 1216.48] loss=3.07 avg=2.85\n",
            "[4331 | 1218.18] loss=2.85 avg=2.85\n",
            "[4332 | 1219.89] loss=2.96 avg=2.85\n",
            "[4333 | 1221.59] loss=2.94 avg=2.85\n",
            "[4334 | 1223.30] loss=2.65 avg=2.85\n",
            "[4335 | 1225.00] loss=3.05 avg=2.85\n",
            "[4336 | 1226.70] loss=2.85 avg=2.85\n",
            "[4337 | 1228.40] loss=2.98 avg=2.85\n",
            "[4338 | 1230.10] loss=3.26 avg=2.86\n",
            "[4339 | 1231.80] loss=2.83 avg=2.86\n",
            "[4340 | 1233.51] loss=2.41 avg=2.85\n",
            "[4341 | 1235.20] loss=2.87 avg=2.85\n",
            "[4342 | 1236.90] loss=2.87 avg=2.85\n",
            "[4343 | 1238.60] loss=3.14 avg=2.86\n",
            "[4344 | 1240.31] loss=2.69 avg=2.85\n",
            "[4345 | 1242.00] loss=2.70 avg=2.85\n",
            "[4346 | 1243.69] loss=2.54 avg=2.85\n",
            "[4347 | 1245.39] loss=2.68 avg=2.85\n",
            "[4348 | 1247.09] loss=2.62 avg=2.85\n",
            "[4349 | 1248.79] loss=2.59 avg=2.84\n",
            "[4350 | 1250.49] loss=2.92 avg=2.84\n",
            "[4351 | 1252.19] loss=3.03 avg=2.85\n",
            "[4352 | 1253.88] loss=2.59 avg=2.84\n",
            "[4353 | 1255.57] loss=2.69 avg=2.84\n",
            "[4354 | 1257.27] loss=2.59 avg=2.84\n",
            "[4355 | 1258.97] loss=3.08 avg=2.84\n",
            "[4356 | 1260.68] loss=3.18 avg=2.84\n",
            "[4357 | 1262.37] loss=2.81 avg=2.84\n",
            "[4358 | 1264.08] loss=3.33 avg=2.85\n",
            "[4359 | 1265.78] loss=2.83 avg=2.85\n",
            "[4360 | 1267.48] loss=2.94 avg=2.85\n",
            "[4361 | 1269.18] loss=2.76 avg=2.85\n",
            "[4362 | 1270.88] loss=2.88 avg=2.85\n",
            "[4363 | 1272.59] loss=2.38 avg=2.84\n",
            "[4364 | 1274.28] loss=2.87 avg=2.85\n",
            "[4365 | 1275.99] loss=2.84 avg=2.85\n",
            "[4366 | 1277.69] loss=3.52 avg=2.85\n",
            "[4367 | 1279.39] loss=2.68 avg=2.85\n",
            "[4368 | 1281.09] loss=2.36 avg=2.85\n",
            "[4369 | 1282.79] loss=2.69 avg=2.84\n",
            "[4370 | 1284.49] loss=2.45 avg=2.84\n",
            "[4371 | 1286.18] loss=2.48 avg=2.84\n",
            "[4372 | 1287.86] loss=2.80 avg=2.84\n",
            "[4373 | 1289.56] loss=3.16 avg=2.84\n",
            "[4374 | 1291.25] loss=2.72 avg=2.84\n",
            "[4375 | 1292.93] loss=2.76 avg=2.84\n",
            "[4376 | 1294.62] loss=2.88 avg=2.84\n",
            "[4377 | 1296.30] loss=2.48 avg=2.83\n",
            "[4378 | 1297.98] loss=2.70 avg=2.83\n",
            "[4379 | 1299.66] loss=2.57 avg=2.83\n",
            "[4380 | 1301.34] loss=2.55 avg=2.83\n",
            "[4381 | 1303.02] loss=3.06 avg=2.83\n",
            "[4382 | 1304.71] loss=2.75 avg=2.83\n",
            "[4383 | 1306.40] loss=2.42 avg=2.82\n",
            "[4384 | 1308.09] loss=3.09 avg=2.83\n",
            "[4385 | 1309.78] loss=2.51 avg=2.82\n",
            "[4386 | 1311.48] loss=2.62 avg=2.82\n",
            "[4387 | 1313.18] loss=2.39 avg=2.82\n",
            "[4388 | 1314.88] loss=2.44 avg=2.81\n",
            "[4389 | 1316.58] loss=2.44 avg=2.81\n",
            "[4390 | 1318.29] loss=2.45 avg=2.81\n",
            "[4391 | 1319.99] loss=3.19 avg=2.81\n",
            "[4392 | 1321.69] loss=2.84 avg=2.81\n",
            "[4393 | 1323.39] loss=2.37 avg=2.81\n",
            "[4394 | 1325.09] loss=2.72 avg=2.81\n",
            "[4395 | 1326.79] loss=2.54 avg=2.80\n",
            "[4396 | 1328.49] loss=2.73 avg=2.80\n",
            "[4397 | 1330.19] loss=2.96 avg=2.80\n",
            "[4398 | 1331.90] loss=2.10 avg=2.80\n",
            "[4399 | 1333.60] loss=2.77 avg=2.80\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " he has spoken to me, and he feels that he has made friends. He says that he cannot speak for others about what he has done. I say no more, because I know what he has done. I have said nothing about the whole of the Government except what I have told. We shall soon have the chance of speaking about the whole thing to make the case more complete.\n",
            "\t\\@ Davenport, Samuel Alexander (1820–1918) State Library of New South Wales, 479893\n",
            "\t\\@ MacRae, George (1830–1918) \n",
            "\tMr. George MacRae, a most excellent friend of the East-end for many years, died quietly last week.Born at the old residence of Dr. O'Brien, Caulfield Road, Caulfield Park, N.S.W., and educated at Trinity College, Dublin, Mr. MacRae entered the service of the State in 1837 and afterwards served as a barrister. For some years his interest as a barrister was quite distinct in the community, as he acted as a private solicitor for a number of prominent families, including the late Sir Henry Fingleton, Baron MacRae.\n",
            "\u0014The late Mr. MacRae, although by no means a favourite character, had given a good deal of service to the cause. He lost only a few friends in death, and a few had to deal with his death as they lived.\n",
            "\tThe deceased gentleman was for many years well-known to all sections of New South Wales and had a large circle of friends.\n",
            "\tHe was married in 1846 to the daughter of Messrs. W. G. and A. F. MacLennan, of Caulfield, the second son of the late Mr. A. MacLennan of Rookwood. He is survived by his widow, two sons and one daughter.\n",
            "\t\\@ White, John (1837–1918) \n",
            "\tThe death occurred of Mr. John White of Crixton Park, near Ballarat, aged 64, on Saturday last. Deceased, who came to Sydney in 1838, resided at West Crixton until 1861, when he was compelled to leave and enter Sydney and to reside for a while at Ballarat. Deceased, after travelling to Sydney five years ago, continued to reside at Ballarat as a tenant. In 1876 Mr. White was associated with the trustees of the Sydney Hospital, which he had held for more than two years. He received the prize of a knighthood and a large pension for services rendered to the society in the past.\n",
            "\tThe deceased gentleman was one of the oldest tenants in the old Crixton Park.\n",
            "\t\\@ Macgregor, Charles (1839–1918) \n",
            "\tMr. Charles Mcgregor, of Drogheda, was drowned by a falling river on Monday, at about 10 o'clock. He immediately fell into the water and was found drowned a short time later. The deceased gentleman, who was quite infirm, was buried at the Burrong Cemetery, the funeral arrangements being carried out by Mr. C. J. S. Dorn.\n",
            "\tMr Macgregor had gone to visit Mr H. W. Dampier of Drogheda. He came out on Monday morning, and on arriving he found an immense crowd gathering. He rushed quickly towards them to ask for assistance immediately; but his assistance was not forthcoming. Mr. M. M. F. Macgregor of the N.S.W. Hospital assisted after the deceased drowned.\n",
            "\tThis morning we saw one of our most eminent men, Mr. Mcgregor, in the state to which he had been introduced as a young man. He was a leading man at the front and afterwards at the rear. He was a farmer, and was a friend of the late Mr. Dampier for many years.\n",
            "\tIt shall probably be found evident that the late Mr. Charles Mcgregor had a close connection with the old Crixton Park. He was the father of one of the early members of the club, and was the first to welcome the club. He was active in various charities.\n",
            "\tMr. Macgregor's death was a very public one among the public at a time when the whole of the old district was deeply affected.\n",
            "\tThe following notices were sent out yesterday:\n",
            "\tThe President of the Council, Mr. H. G. L. Cushing, yesterday gave the reasons for passing the resolution of the Council as follows:\n",
            "\tOn Tuesday, the 25th inst, Mr. Macgregor, who was then a resident of the district, took a ship to Sydney, and arrived in the same year with the intention of returning with the ship with which he had embarked in the year 1876, although his intention was that he should have returned to his family home in the\n",
            "\n",
            "[4400 | 1357.75] loss=2.88 avg=2.80\n",
            "[4401 | 1359.43] loss=2.76 avg=2.80\n",
            "[4402 | 1361.12] loss=2.51 avg=2.79\n",
            "[4403 | 1362.80] loss=3.54 avg=2.80\n",
            "[4404 | 1364.47] loss=2.52 avg=2.80\n",
            "[4405 | 1366.15] loss=2.46 avg=2.80\n",
            "[4406 | 1367.83] loss=3.03 avg=2.80\n",
            "[4407 | 1369.51] loss=2.65 avg=2.80\n",
            "[4408 | 1371.17] loss=2.45 avg=2.79\n",
            "[4409 | 1372.85] loss=2.42 avg=2.79\n",
            "[4410 | 1374.51] loss=3.01 avg=2.79\n",
            "[4411 | 1376.19] loss=2.57 avg=2.79\n",
            "[4412 | 1377.86] loss=2.63 avg=2.79\n",
            "[4413 | 1379.52] loss=2.67 avg=2.79\n",
            "[4414 | 1381.18] loss=3.04 avg=2.79\n",
            "[4415 | 1382.86] loss=2.47 avg=2.79\n",
            "[4416 | 1384.53] loss=3.25 avg=2.79\n",
            "[4417 | 1386.20] loss=2.96 avg=2.79\n",
            "[4418 | 1387.88] loss=2.74 avg=2.79\n",
            "[4419 | 1389.56] loss=2.45 avg=2.79\n",
            "[4420 | 1391.23] loss=2.35 avg=2.78\n",
            "[4421 | 1392.92] loss=3.03 avg=2.79\n",
            "[4422 | 1394.61] loss=2.61 avg=2.78\n",
            "[4423 | 1396.30] loss=2.94 avg=2.79\n",
            "[4424 | 1397.99] loss=3.30 avg=2.79\n",
            "[4425 | 1399.69] loss=2.73 avg=2.79\n",
            "[4426 | 1401.39] loss=2.45 avg=2.79\n",
            "[4427 | 1403.10] loss=2.51 avg=2.78\n",
            "[4428 | 1404.78] loss=3.15 avg=2.79\n",
            "[4429 | 1406.50] loss=3.19 avg=2.79\n",
            "[4430 | 1408.20] loss=2.54 avg=2.79\n",
            "[4431 | 1409.90] loss=3.07 avg=2.79\n",
            "[4432 | 1411.60] loss=2.45 avg=2.79\n",
            "[4433 | 1413.30] loss=3.05 avg=2.79\n",
            "[4434 | 1415.00] loss=2.44 avg=2.79\n",
            "[4435 | 1416.71] loss=2.89 avg=2.79\n",
            "[4436 | 1418.41] loss=2.92 avg=2.79\n",
            "[4437 | 1420.11] loss=2.76 avg=2.79\n",
            "[4438 | 1421.81] loss=2.88 avg=2.79\n",
            "[4439 | 1423.52] loss=2.86 avg=2.79\n",
            "[4440 | 1425.22] loss=2.53 avg=2.79\n",
            "[4441 | 1426.92] loss=2.82 avg=2.79\n",
            "[4442 | 1428.62] loss=2.47 avg=2.79\n",
            "[4443 | 1430.33] loss=2.55 avg=2.78\n",
            "[4444 | 1432.03] loss=2.92 avg=2.78\n",
            "[4445 | 1433.73] loss=2.87 avg=2.79\n",
            "[4446 | 1435.43] loss=2.70 avg=2.78\n",
            "[4447 | 1437.13] loss=2.95 avg=2.79\n",
            "[4448 | 1438.83] loss=2.61 avg=2.78\n",
            "[4449 | 1440.52] loss=2.71 avg=2.78\n",
            "[4450 | 1442.23] loss=3.25 avg=2.79\n",
            "[4451 | 1443.91] loss=2.91 avg=2.79\n",
            "[4452 | 1445.61] loss=3.09 avg=2.79\n",
            "[4453 | 1447.31] loss=3.15 avg=2.80\n",
            "[4454 | 1449.00] loss=2.73 avg=2.80\n",
            "[4455 | 1450.69] loss=2.43 avg=2.79\n",
            "[4456 | 1452.38] loss=2.87 avg=2.79\n",
            "[4457 | 1454.07] loss=2.51 avg=2.79\n",
            "[4458 | 1455.76] loss=3.08 avg=2.79\n",
            "[4459 | 1457.45] loss=2.77 avg=2.79\n",
            "[4460 | 1459.15] loss=2.68 avg=2.79\n",
            "[4461 | 1460.84] loss=2.79 avg=2.79\n",
            "[4462 | 1462.53] loss=2.71 avg=2.79\n",
            "[4463 | 1464.21] loss=2.70 avg=2.79\n",
            "[4464 | 1465.89] loss=2.53 avg=2.79\n",
            "[4465 | 1467.58] loss=3.10 avg=2.79\n",
            "[4466 | 1469.28] loss=2.53 avg=2.79\n",
            "[4467 | 1470.97] loss=2.93 avg=2.79\n",
            "[4468 | 1472.65] loss=3.17 avg=2.79\n",
            "[4469 | 1474.34] loss=2.63 avg=2.79\n",
            "[4470 | 1476.03] loss=2.59 avg=2.79\n",
            "[4471 | 1477.72] loss=2.68 avg=2.79\n",
            "[4472 | 1479.41] loss=2.56 avg=2.79\n",
            "[4473 | 1481.10] loss=2.92 avg=2.79\n",
            "[4474 | 1482.79] loss=2.64 avg=2.79\n",
            "[4475 | 1484.47] loss=2.83 avg=2.79\n",
            "[4476 | 1486.15] loss=2.33 avg=2.78\n",
            "[4477 | 1487.84] loss=2.98 avg=2.78\n",
            "[4478 | 1489.52] loss=3.07 avg=2.79\n",
            "[4479 | 1491.21] loss=2.95 avg=2.79\n",
            "[4480 | 1492.89] loss=3.02 avg=2.79\n",
            "[4481 | 1494.57] loss=2.76 avg=2.79\n",
            "[4482 | 1496.26] loss=3.00 avg=2.79\n",
            "[4483 | 1497.95] loss=2.97 avg=2.79\n",
            "[4484 | 1499.64] loss=2.54 avg=2.79\n",
            "[4485 | 1501.33] loss=2.48 avg=2.79\n",
            "[4486 | 1503.03] loss=2.67 avg=2.79\n",
            "[4487 | 1504.72] loss=2.89 avg=2.79\n",
            "[4488 | 1506.40] loss=2.46 avg=2.79\n",
            "[4489 | 1508.09] loss=2.55 avg=2.78\n",
            "[4490 | 1509.77] loss=2.84 avg=2.78\n",
            "[4491 | 1511.46] loss=3.22 avg=2.79\n",
            "[4492 | 1513.16] loss=2.66 avg=2.79\n",
            "[4493 | 1514.85] loss=2.26 avg=2.78\n",
            "[4494 | 1516.54] loss=2.48 avg=2.78\n",
            "[4495 | 1518.23] loss=2.87 avg=2.78\n",
            "[4496 | 1519.93] loss=3.58 avg=2.79\n",
            "[4497 | 1521.61] loss=2.83 avg=2.79\n",
            "[4498 | 1523.31] loss=2.56 avg=2.79\n",
            "[4499 | 1525.01] loss=2.95 avg=2.79\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " Christopher had left the service of the army and was at that time stationed at the head of a detachment at the station in the north-west, at Mount Hope, Victoria, about fifty miles distant, when he was captured and sold to Sir Thomas Allen, who retained possession of him for two years. It was at that time that his father, who was also a resident of Victoria, was in a state of deep regret and sorrow at the breaking off of his connection with Mr. and Mrs. Macquarie; and he came and went away in a minute's travel. For many years after his decease the deceased gentleman had been employed in purchasing lands near the town, and in making arrangements to convert the existing homestead into an independent dwelling-house in the nature of a barn-yard. He had acquired a considerable wealth, and his estate was generally well appreciated. About thirty years ago this gentleman left his principal company, and was now employed for the last three or four years as a farmer. He was also engaged in the management of the land, but he had retained his interest in the stock. A large scale establishment was built, and many acres were taken up for cultivation, including the old homestead. In this position the deceased gentleman took great interest, and was very careful in cultivating his properties. In connection with his services he was deeply respected by the town, and was highly respected for his honest and liberal disposition. The deceased gentleman is survived by his widow, Mrs. Osprey, and two sons, Mr. Edwin Osprey, of Warkworth, and Mr. Peter Osprey, of Waverley.\n",
            "\t\\@ Wilson, Robert (1813–1880) \n",
            "\t\\@ Gage, Charles John (1807–1880) The late Mr. Charles P. Gage died suddenly yesterday at His Majesty's request at the residence of his son Mr. Edward W. P. Rolfe, in the suburb of Goulburn. The deceased gentleman was a very old resident of the district, having been resident of Tasmania for the last twenty years. He was a man of considerable age, having been about fifty years of age, and was at the time of his death a member of the Australian branch of the American branch, viz., of the First Australian Bank in Sydney. He was for many years a manager of the branch in which he resided, being one of the best able men for those years to be found. The deceased was, for many years, a resident of Tasmania. He was a son of the late William Gage, the late Lord of the Bench, who was a distinguished judge. The late Mr. J. H. Gage was the first settler of Tasmania, and one time resided there with his parents, the first and eldest son being one of our own people. A wife of the deceased's and a daughter of his sister came to reside in Melbourne in 1826, and married Mr. Richard C. Campbell, one of the late Mr. Gage's sons. He had many sons of both sexes, namely, Henry, William, William Henry, and Messrs. John, Charles, and Joseph Henry. His only daughter was, by William Gage, Mrs. A. W. Jones (Sydney, formerly Mrs. Jones, of the Sydney Hotel), who for many years resided with the late Mr. Gage's elder brother in Tasmania after their father's death. The late Mr. Gage, who had been engaged for some years as a lawyer in his own name, for a time in the practice of his own, and in which he became a leading figure, took residence in Tasmania after obtaining his education in Sydney with the purpose of becoming a magistrate, being elected to the Bench in 1832, being for a brief time a member of the Constitutional Legislative Assembly, and was once a member of the Senate. Then he was twice elected to the Legislative Assembly and again twice on the Bench. He had been one of the representatives of the old Bar of the Northern District for some time but since, during the recent war, he had been in opposition to the Australian Government. He resigned his seat in September last, in consequence of the dissatisfaction of the people, but his nomination to the Legislative Assembly for the Northern District was declined after he was not able to answer the questions put to him. About two months ago he was summoned to reappear before the Legislative Assembly, although he had been in opposition, but he was summoned for his attendance to give evidence that he had a sufficient knowledge of parliamentary proceedings, to answer the questions put to him, but he declined the service, and was refused the seat, which was vacant until he had answered the question put to him. In the Council of the Court of Parl. he served in the earlier days from 1828 to 1831, but with the exception of a short term, he was one of the oldest members of the Constitutional Committee. When he was first elected to the House he was one of the most active members, and\n",
            "\n",
            "[4500 | 1549.15] loss=2.38 avg=2.78\n",
            "[4501 | 1550.83] loss=2.96 avg=2.78\n",
            "[4502 | 1552.52] loss=2.35 avg=2.78\n",
            "[4503 | 1554.21] loss=2.63 avg=2.78\n",
            "[4504 | 1555.89] loss=2.31 avg=2.77\n",
            "[4505 | 1557.57] loss=3.52 avg=2.78\n",
            "[4506 | 1559.26] loss=3.02 avg=2.78\n",
            "[4507 | 1560.94] loss=3.09 avg=2.79\n",
            "[4508 | 1562.62] loss=3.43 avg=2.79\n",
            "[4509 | 1564.31] loss=3.06 avg=2.80\n",
            "[4510 | 1565.98] loss=2.91 avg=2.80\n",
            "[4511 | 1567.67] loss=2.71 avg=2.80\n",
            "[4512 | 1569.35] loss=3.25 avg=2.80\n",
            "[4513 | 1571.04] loss=2.69 avg=2.80\n",
            "[4514 | 1572.72] loss=3.02 avg=2.80\n",
            "[4515 | 1574.40] loss=2.64 avg=2.80\n",
            "[4516 | 1576.07] loss=2.49 avg=2.80\n",
            "[4517 | 1577.76] loss=2.94 avg=2.80\n",
            "[4518 | 1579.44] loss=2.52 avg=2.80\n",
            "[4519 | 1581.12] loss=2.43 avg=2.79\n",
            "[4520 | 1582.80] loss=2.63 avg=2.79\n",
            "[4521 | 1584.49] loss=2.85 avg=2.79\n",
            "[4522 | 1586.16] loss=3.00 avg=2.79\n",
            "[4523 | 1587.85] loss=2.76 avg=2.79\n",
            "[4524 | 1589.54] loss=2.48 avg=2.79\n",
            "[4525 | 1591.22] loss=2.65 avg=2.79\n",
            "[4526 | 1592.91] loss=2.61 avg=2.79\n",
            "[4527 | 1594.60] loss=2.53 avg=2.78\n",
            "[4528 | 1596.29] loss=2.81 avg=2.78\n",
            "[4529 | 1597.98] loss=2.78 avg=2.78\n",
            "[4530 | 1599.67] loss=2.79 avg=2.78\n",
            "[4531 | 1601.35] loss=2.56 avg=2.78\n",
            "[4532 | 1603.03] loss=3.12 avg=2.79\n",
            "[4533 | 1604.72] loss=3.26 avg=2.79\n",
            "[4534 | 1606.41] loss=2.48 avg=2.79\n",
            "[4535 | 1608.11] loss=2.69 avg=2.79\n",
            "[4536 | 1609.80] loss=2.73 avg=2.79\n",
            "[4537 | 1611.50] loss=2.67 avg=2.78\n",
            "[4538 | 1613.19] loss=3.02 avg=2.79\n",
            "[4539 | 1614.87] loss=2.83 avg=2.79\n",
            "[4540 | 1616.56] loss=2.51 avg=2.78\n",
            "[4541 | 1618.25] loss=2.79 avg=2.78\n",
            "[4542 | 1619.94] loss=3.33 avg=2.79\n",
            "[4543 | 1621.64] loss=2.64 avg=2.79\n",
            "[4544 | 1623.32] loss=2.65 avg=2.79\n",
            "[4545 | 1625.02] loss=2.69 avg=2.79\n",
            "[4546 | 1626.71] loss=3.27 avg=2.79\n",
            "[4547 | 1628.40] loss=2.68 avg=2.79\n",
            "[4548 | 1630.08] loss=3.04 avg=2.79\n",
            "[4549 | 1631.78] loss=2.46 avg=2.79\n",
            "[4550 | 1633.47] loss=2.81 avg=2.79\n",
            "[4551 | 1635.16] loss=2.67 avg=2.79\n",
            "[4552 | 1636.86] loss=3.10 avg=2.79\n",
            "[4553 | 1638.55] loss=2.56 avg=2.79\n",
            "[4554 | 1640.25] loss=2.49 avg=2.79\n",
            "[4555 | 1641.95] loss=2.92 avg=2.79\n",
            "[4556 | 1643.64] loss=2.93 avg=2.79\n",
            "[4557 | 1645.33] loss=2.92 avg=2.79\n",
            "[4558 | 1647.03] loss=2.60 avg=2.79\n",
            "[4559 | 1648.72] loss=2.74 avg=2.79\n",
            "[4560 | 1650.42] loss=2.82 avg=2.79\n",
            "[4561 | 1652.11] loss=2.95 avg=2.79\n",
            "[4562 | 1653.82] loss=2.52 avg=2.79\n",
            "[4563 | 1655.52] loss=3.39 avg=2.79\n",
            "[4564 | 1657.22] loss=2.76 avg=2.79\n",
            "[4565 | 1658.92] loss=2.68 avg=2.79\n",
            "[4566 | 1660.62] loss=2.74 avg=2.79\n",
            "[4567 | 1662.31] loss=2.58 avg=2.79\n",
            "[4568 | 1664.00] loss=3.30 avg=2.79\n",
            "[4569 | 1665.70] loss=2.45 avg=2.79\n",
            "[4570 | 1667.39] loss=2.49 avg=2.79\n",
            "[4571 | 1669.08] loss=3.08 avg=2.79\n",
            "[4572 | 1670.77] loss=3.23 avg=2.80\n",
            "[4573 | 1672.46] loss=2.34 avg=2.79\n",
            "[4574 | 1674.17] loss=2.39 avg=2.79\n",
            "[4575 | 1675.87] loss=2.72 avg=2.79\n",
            "[4576 | 1677.57] loss=3.19 avg=2.79\n",
            "[4577 | 1679.27] loss=2.57 avg=2.79\n",
            "[4578 | 1680.97] loss=2.63 avg=2.79\n",
            "[4579 | 1682.67] loss=2.40 avg=2.78\n",
            "[4580 | 1684.37] loss=2.76 avg=2.78\n",
            "[4581 | 1686.07] loss=2.83 avg=2.78\n",
            "[4582 | 1687.78] loss=2.71 avg=2.78\n",
            "[4583 | 1689.48] loss=2.98 avg=2.78\n",
            "[4584 | 1691.18] loss=2.93 avg=2.79\n",
            "[4585 | 1692.89] loss=2.65 avg=2.78\n",
            "[4586 | 1694.58] loss=2.32 avg=2.78\n",
            "[4587 | 1696.29] loss=2.82 avg=2.78\n",
            "[4588 | 1697.99] loss=2.94 avg=2.78\n",
            "[4589 | 1699.68] loss=2.85 avg=2.78\n",
            "[4590 | 1701.38] loss=2.64 avg=2.78\n",
            "[4591 | 1703.08] loss=2.52 avg=2.78\n",
            "[4592 | 1704.78] loss=3.54 avg=2.79\n",
            "[4593 | 1706.48] loss=2.69 avg=2.78\n",
            "[4594 | 1708.18] loss=3.10 avg=2.79\n",
            "[4595 | 1709.88] loss=2.39 avg=2.78\n",
            "[4596 | 1711.59] loss=2.67 avg=2.78\n",
            "[4597 | 1713.28] loss=2.58 avg=2.78\n",
            "[4598 | 1714.99] loss=2.31 avg=2.78\n",
            "[4599 | 1716.69] loss=2.93 avg=2.78\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            ", the most recent issue of the journal, is on p7, entitled: 'A preliminary sketch of the new scientific model of the universe'.\n",
            "\tThe first chapter is on the theory of evolution. Chapter 2 on a new theory on the formation of a universal principle as 'the beginning of all existing phenomena' is dealt with. The third, on the structure of the universe, is discussed. The fourth, on the origin of life, is considered. 'The universe, and in particular life', is the 'origin of things and the beginning of all other phenomena'. Chapter 5 on the origin of the first living organisms, which is called 'The beginning of other living organisms'. Chapter 6 on the origin of the universe, with reference to a new model of the structure of this universe, which is called 'The first life-organism of our solar system'. Chapter 7 on the origin of the whole universe, with reference to a model of the structure, properties and formation of life on the solar system with reference to a model of the formation and evolution of life on different planets, also referred to as 'the solar system', is mentioned.\n",
            "\tIn this chapter (for the time being) the 'origin of the universe' is taken as referring to the evolution of the solar system.\n",
            "\tIn this chapter the 'world-generating power' theory is discussed. It is considered that the earth will, in a few billion years, lose its main source of energy. All the planets within the solar system will lose part of their power. The earth of which it is now made, is not worth much.\n",
            "\tThe fourth chapter on the structure of the universe, also called the 'origins of the universe' is presented. The fifth chapter is on the evolution of the solar system, and that of other planets. The sixth chapter on the formation of life on different planets, also referred to as 'the solar system' is discussed. The Seventh and eighth chapters are on the structure of 'organic matter', which is in a general form of matter of the solar system and is described, as well as the mechanism of making 'organic matter. The ninth chapter on the form of all the solar systems, both the planets and comets, is discussed. The tenth chapter on the formation of all life by the processes of chemical synthesis and biological reproduction, also also referred to as the 'natural universe', is given. The eleventh chapter on the formation of life, also called the 'origin of life' as described, is discussed. The twelfth chapter on life forms and the formation of life-forms, also called the 'organisms', is dealt with here on the first line of the 'The origin of life ' chapter.\n",
            "\tThis chapter deals with the principles of evolution, which will be used in subsequent chapters, while at the same time the theory of the structure of the universe, also referred to as the 'creation of the universe' is discussed.\n",
            "\u0014The fourth chapter on 'The creation of the solar system', is, in its conclusion, on 'The structure and behaviour of the universe'. The fifth chapter on 'The composition of the universe' is on 'Structures of composition'. The sixth chapter on 'The formation of life processes and the evolution of life process in the universe.' The seventh chapter 'The creation of life processes by the processes of formation of life, the origin of organisms', is treated in the same way as 'The formation of the universe', and is called, likewise 'The origin of life'. The eleventh chapter 'The development of planets in the solar system', 'The evolution of planets, comets,' 'The evolution of other life and organisation of planets and comets' and 'The formation and evolution of terrestrial planets' are also dealt with here on the same lines as other chapters of the theory of the structure of the universe. The next chapter on 'The creation of life processes', also called the 'origin of life' as described, is dealt with in the same way as 'The origin of life, in the form of organisms, on planets'. The twelfth chapter on the evolution of planets, comets and life in the universe is given. The twelfth chapter (for the time being) is on 'The origin of the creation of the solar system and the structure of the universe'. The twenty-fourth chapter on the formation of life is dealt with in the same way as other chapters.\n",
            "\tThe twentieth chapter on the creation of the universe is dealt with. The twenty-first chapter, in its discussion, on 'The mechanism of development', is, on the lines of the twentieth chapter, referred to elsewhere in the publication as 'The emergence of the mechanism of life'. The twenty-second chapter on 'The structure of the universe', the 'origin of life, the structure of the universe, the organization of the universe and the origins of life and the origin of organisms' are referred to elsewhere in the publication as 'The origin of the formation of life processes for the formation of life of organic matter,\n",
            "\n",
            "[4600 | 1740.79] loss=2.98 avg=2.78\n",
            "[4601 | 1742.48] loss=2.99 avg=2.78\n",
            "[4602 | 1744.15] loss=3.00 avg=2.78\n",
            "[4603 | 1745.83] loss=2.64 avg=2.78\n",
            "[4604 | 1747.51] loss=2.90 avg=2.78\n",
            "[4605 | 1749.20] loss=2.36 avg=2.78\n",
            "[4606 | 1750.88] loss=3.10 avg=2.78\n",
            "[4607 | 1752.56] loss=3.52 avg=2.79\n",
            "[4608 | 1754.23] loss=2.72 avg=2.79\n",
            "[4609 | 1755.90] loss=2.54 avg=2.79\n",
            "[4610 | 1757.58] loss=2.61 avg=2.78\n",
            "[4611 | 1759.26] loss=2.63 avg=2.78\n",
            "[4612 | 1760.93] loss=2.78 avg=2.78\n",
            "[4613 | 1762.61] loss=2.71 avg=2.78\n",
            "[4614 | 1764.30] loss=2.65 avg=2.78\n",
            "[4615 | 1765.98] loss=2.79 avg=2.78\n",
            "[4616 | 1767.66] loss=2.56 avg=2.78\n",
            "[4617 | 1769.35] loss=3.01 avg=2.78\n",
            "[4618 | 1771.03] loss=2.42 avg=2.78\n",
            "[4619 | 1772.73] loss=2.42 avg=2.77\n",
            "[4620 | 1774.43] loss=3.01 avg=2.78\n",
            "[4621 | 1776.13] loss=2.66 avg=2.78\n",
            "[4622 | 1777.79] loss=2.43 avg=2.77\n",
            "[4623 | 1779.49] loss=3.08 avg=2.77\n",
            "[4624 | 1781.19] loss=3.47 avg=2.78\n",
            "[4625 | 1782.90] loss=3.22 avg=2.79\n",
            "[4626 | 1784.60] loss=2.71 avg=2.79\n",
            "[4627 | 1786.30] loss=2.60 avg=2.78\n",
            "[4628 | 1788.01] loss=2.36 avg=2.78\n",
            "[4629 | 1789.71] loss=2.43 avg=2.78\n",
            "[4630 | 1791.41] loss=2.60 avg=2.77\n",
            "[4631 | 1793.11] loss=2.52 avg=2.77\n",
            "[4632 | 1794.82] loss=2.81 avg=2.77\n",
            "[4633 | 1796.52] loss=3.09 avg=2.78\n",
            "[4634 | 1798.22] loss=2.21 avg=2.77\n",
            "[4635 | 1799.94] loss=3.02 avg=2.77\n",
            "[4636 | 1801.64] loss=2.82 avg=2.77\n",
            "[4637 | 1803.35] loss=2.70 avg=2.77\n",
            "[4638 | 1805.05] loss=2.75 avg=2.77\n",
            "[4639 | 1806.75] loss=3.28 avg=2.78\n",
            "[4640 | 1808.45] loss=2.90 avg=2.78\n",
            "[4641 | 1810.15] loss=2.67 avg=2.78\n",
            "[4642 | 1811.85] loss=2.84 avg=2.78\n",
            "[4643 | 1813.55] loss=2.65 avg=2.78\n",
            "[4644 | 1815.25] loss=2.46 avg=2.77\n",
            "[4645 | 1816.95] loss=2.66 avg=2.77\n",
            "[4646 | 1818.64] loss=2.89 avg=2.77\n",
            "[4647 | 1820.34] loss=2.29 avg=2.77\n",
            "[4648 | 1822.03] loss=2.69 avg=2.77\n",
            "[4649 | 1823.73] loss=2.63 avg=2.77\n",
            "[4650 | 1825.42] loss=2.66 avg=2.77\n",
            "[4651 | 1827.11] loss=2.70 avg=2.76\n",
            "[4652 | 1828.79] loss=2.34 avg=2.76\n",
            "[4653 | 1830.48] loss=2.33 avg=2.76\n",
            "[4654 | 1832.16] loss=3.34 avg=2.76\n",
            "[4655 | 1833.84] loss=2.86 avg=2.76\n",
            "[4656 | 1835.53] loss=2.85 avg=2.76\n",
            "[4657 | 1837.21] loss=2.97 avg=2.77\n",
            "[4658 | 1838.90] loss=2.91 avg=2.77\n",
            "[4659 | 1840.58] loss=3.39 avg=2.77\n",
            "[4660 | 1842.25] loss=3.33 avg=2.78\n",
            "[4661 | 1843.95] loss=2.46 avg=2.78\n",
            "[4662 | 1845.63] loss=2.49 avg=2.77\n",
            "[4663 | 1847.32] loss=2.96 avg=2.77\n",
            "[4664 | 1849.01] loss=2.98 avg=2.78\n",
            "[4665 | 1850.69] loss=2.64 avg=2.78\n",
            "[4666 | 1852.38] loss=3.36 avg=2.78\n",
            "[4667 | 1854.08] loss=2.39 avg=2.78\n",
            "[4668 | 1855.77] loss=2.84 avg=2.78\n",
            "[4669 | 1857.46] loss=2.21 avg=2.77\n",
            "[4670 | 1859.15] loss=2.62 avg=2.77\n",
            "[4671 | 1860.85] loss=2.76 avg=2.77\n",
            "[4672 | 1862.55] loss=2.92 avg=2.77\n",
            "[4673 | 1864.25] loss=2.59 avg=2.77\n",
            "[4674 | 1865.95] loss=2.55 avg=2.77\n",
            "[4675 | 1867.64] loss=2.50 avg=2.77\n",
            "[4676 | 1869.33] loss=2.54 avg=2.76\n",
            "[4677 | 1871.02] loss=2.92 avg=2.76\n",
            "[4678 | 1872.72] loss=3.00 avg=2.77\n",
            "[4679 | 1874.42] loss=2.92 avg=2.77\n",
            "[4680 | 1876.13] loss=2.71 avg=2.77\n",
            "[4681 | 1877.83] loss=2.72 avg=2.77\n",
            "[4682 | 1879.53] loss=2.49 avg=2.76\n",
            "[4683 | 1881.23] loss=3.38 avg=2.77\n",
            "[4684 | 1882.93] loss=3.04 avg=2.77\n",
            "[4685 | 1884.63] loss=3.06 avg=2.78\n",
            "[4686 | 1886.34] loss=3.17 avg=2.78\n",
            "[4687 | 1888.04] loss=2.47 avg=2.78\n",
            "[4688 | 1889.74] loss=2.67 avg=2.78\n",
            "[4689 | 1891.45] loss=2.75 avg=2.78\n",
            "[4690 | 1893.14] loss=2.30 avg=2.77\n",
            "[4691 | 1894.85] loss=2.97 avg=2.77\n",
            "[4692 | 1896.55] loss=2.32 avg=2.77\n",
            "[4693 | 1898.25] loss=2.56 avg=2.77\n",
            "[4694 | 1899.96] loss=2.84 avg=2.77\n",
            "[4695 | 1901.66] loss=2.84 avg=2.77\n",
            "[4696 | 1903.36] loss=2.96 avg=2.77\n",
            "[4697 | 1905.06] loss=3.31 avg=2.78\n",
            "[4698 | 1906.77] loss=2.68 avg=2.77\n",
            "[4699 | 1908.47] loss=2.91 avg=2.78\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " Richard O. Stryker, of Springfield, South Melbourne, who had been ailing and ailing for several years. He died at his residence, Grafton, at 6 o'clock this morning.\n",
            "\tDr. Stryker was always well known for his charitable works and his influence in this district. His name has already been given up in memory of and thanks to many many friends in Australia and abroad.\n",
            "\t\\@ Taylor, William Percy (1837–1930) \n",
            "\tThe death took place yesterday evening and at one o'clock in the afternoon was reported, although the immediate cause was not known. The deceased was a gentleman to be closely followed for his good qualities, which were very marked, and we believe that at a very early age he possessed one of the most admirable and admirable attributes that can be described as \"honest, just, and virtuous.\" He was an aged man, aged 55 years, and was born in St. Vincent's Parish, Melbourne, on January 2, 1837. He came to Victoria more than 40 years ago, and was a native of the town of Melbourne. He took up his residence in St. Vincent's parish, Melbourne, a period which made the old parish a pleasant and agreeable district and a suitable home for him. He afterwards resided until death in that old homestead of St. Vincent's parish, which had been converted into a beautiful residence by Mr. St. James, the pioneer, and one of the founders of the colony. He was a very old resident of Melbourne, and had resided there for many years. At the time of his death he was the only living member of the family of Mrs. Thomas (nee Stilwell), second daughter of the late Dr. and Mrs. S. Stullard. As regards his family, none survived. He is survived by three daughters and one son: —Mrs. A. M. (Mrs. J. D. Tew, of \"the Hillers\"), daughter of the late Captain Charles Thomas, of New Scotland, New South Wales, and Mrs. Stump, sister of the late George A. Tew and John A. Tew, and sister of Mr. James, Mr. and Mrs. C. Tew, and Mrs. C. Tew. The other surviving children are Mrs. M. A. Walker, M.A., of Prahran, Vic.; Mr. Richard F. (Mr. Richard F. Tew), of Pennington, Vic.; Mrs. C. W. (Mrs. John Brougham), of St. Peter's Church, Melbourne, and her sister, Mrs. W. F. J. R. C. P.S., at \"the Hillers.\" Mr. T. H. Brown of Bexley, Tumut — deceased; Mrs. A. L. Wilson, of \"the Stokes,\" Victoria, and Mr. R. L. (Mr. R. L. Brown), also at \"the Hillers.\" Mr. H. J. Hillery, of Bexley, Victoria, and Dr. Hillery at the Tumut Clinic. Mr. W. W. (William) Wood, of St. Augustine, Vic., and Mr. and Mrs. W. W. O. Hillery, in the early days at \"the Hillers,\" Melbourne. The family consists of Mrs. A. P. (Mrs. Wood, of \"the Stokes,\" Vic.), of \"the Hillers,\" who, through illness, died in May last; Mr. T. M. (F. C. M.), of \"the Tumut,\" Victoria; John (Mr. and Mrs. T. F. J. and Mrs. E. H. Hillery (Hills), at \"the Hillers,\" Melbourne, and others of the same family (who survive); and Mrs. L. S. (Mrs. P. H. Giddings, of \"the Hillers,\" Victoria). A very old family is left to mourn the funeral expenses of three members of the immediate family, namely, Mr. William Taylor, of \"the Stokes,\" and John and Mrs. P. E. Hillery (both deceased).\n",
            "\t\\@ McTiernan, George (1845–1930) \n",
            "\tAs some one of our most patriotic men died in our homes yesterday morning, we are greatly relieved to hear of his untimely demise. The deceased gentleman was well known and highly respected in the early period of Australian history, and will be deeply regretted by a large number of old and younger citizens. He was a son of the late Mr George McTiernan, of \"the Stokes,\" and later of Melbourne; his father was a lawyer, and later of \"the Stokes,\" where he lived for many years. Mr George McTiernan left home for Tasmania about 1841 in company with two young officers who were of the latter company and had come to \"\n",
            "\n",
            "[4700 | 1932.55] loss=3.12 avg=2.78\n",
            "[4701 | 1934.24] loss=2.65 avg=2.78\n",
            "[4702 | 1935.94] loss=2.66 avg=2.78\n",
            "[4703 | 1937.61] loss=2.56 avg=2.77\n",
            "[4704 | 1939.29] loss=2.54 avg=2.77\n",
            "[4705 | 1940.97] loss=2.64 avg=2.77\n",
            "[4706 | 1942.65] loss=2.63 avg=2.77\n",
            "[4707 | 1944.33] loss=3.03 avg=2.77\n",
            "[4708 | 1946.00] loss=2.79 avg=2.77\n",
            "[4709 | 1947.67] loss=2.91 avg=2.77\n",
            "[4710 | 1949.36] loss=2.77 avg=2.77\n",
            "[4711 | 1951.04] loss=2.80 avg=2.77\n",
            "[4712 | 1952.71] loss=2.79 avg=2.77\n",
            "[4713 | 1954.40] loss=2.78 avg=2.77\n",
            "[4714 | 1956.08] loss=2.32 avg=2.77\n",
            "[4715 | 1957.76] loss=2.76 avg=2.77\n",
            "[4716 | 1959.45] loss=3.15 avg=2.77\n",
            "[4717 | 1961.13] loss=2.58 avg=2.77\n",
            "[4718 | 1962.82] loss=3.06 avg=2.77\n",
            "[4719 | 1964.51] loss=2.62 avg=2.77\n",
            "[4720 | 1966.21] loss=2.26 avg=2.77\n",
            "[4721 | 1967.89] loss=3.25 avg=2.77\n",
            "[4722 | 1969.59] loss=3.40 avg=2.78\n",
            "[4723 | 1971.29] loss=3.13 avg=2.78\n",
            "[4724 | 1972.98] loss=2.77 avg=2.78\n",
            "[4725 | 1974.68] loss=3.07 avg=2.79\n",
            "[4726 | 1976.38] loss=2.87 avg=2.79\n",
            "[4727 | 1978.08] loss=2.74 avg=2.79\n",
            "[4728 | 1979.78] loss=2.72 avg=2.78\n",
            "[4729 | 1981.49] loss=2.19 avg=2.78\n",
            "[4730 | 1983.18] loss=3.11 avg=2.78\n",
            "[4731 | 1984.88] loss=2.80 avg=2.78\n",
            "[4732 | 1986.59] loss=2.77 avg=2.78\n",
            "[4733 | 1988.29] loss=2.89 avg=2.78\n",
            "[4734 | 1989.99] loss=3.16 avg=2.79\n",
            "[4735 | 1991.69] loss=2.51 avg=2.78\n",
            "[4736 | 1993.39] loss=3.01 avg=2.79\n",
            "[4737 | 1995.10] loss=2.78 avg=2.79\n",
            "[4738 | 1996.79] loss=3.11 avg=2.79\n",
            "[4739 | 1998.50] loss=3.13 avg=2.79\n",
            "[4740 | 2000.19] loss=2.31 avg=2.79\n",
            "[4741 | 2001.90] loss=2.79 avg=2.79\n",
            "[4742 | 2003.60] loss=2.91 avg=2.79\n",
            "[4743 | 2005.30] loss=2.76 avg=2.79\n",
            "[4744 | 2007.00] loss=2.35 avg=2.78\n",
            "[4745 | 2008.71] loss=3.04 avg=2.79\n",
            "[4746 | 2010.41] loss=2.64 avg=2.79\n",
            "[4747 | 2012.11] loss=2.87 avg=2.79\n",
            "[4748 | 2013.82] loss=2.94 avg=2.79\n",
            "[4749 | 2015.51] loss=2.70 avg=2.79\n",
            "[4750 | 2017.22] loss=2.56 avg=2.79\n",
            "[4751 | 2018.92] loss=2.60 avg=2.78\n",
            "[4752 | 2020.62] loss=2.43 avg=2.78\n",
            "[4753 | 2022.32] loss=3.11 avg=2.78\n",
            "[4754 | 2024.02] loss=2.61 avg=2.78\n",
            "[4755 | 2025.72] loss=2.67 avg=2.78\n",
            "[4756 | 2027.42] loss=2.83 avg=2.78\n",
            "[4757 | 2029.12] loss=3.23 avg=2.79\n",
            "[4758 | 2030.81] loss=3.07 avg=2.79\n",
            "[4759 | 2032.51] loss=3.34 avg=2.79\n",
            "[4760 | 2034.20] loss=2.89 avg=2.79\n",
            "[4761 | 2035.89] loss=2.92 avg=2.80\n",
            "[4762 | 2037.59] loss=2.68 avg=2.79\n",
            "[4763 | 2039.29] loss=2.60 avg=2.79\n",
            "[4764 | 2041.00] loss=2.41 avg=2.79\n",
            "[4765 | 2042.68] loss=2.76 avg=2.79\n",
            "[4766 | 2044.37] loss=2.56 avg=2.79\n",
            "[4767 | 2046.06] loss=2.82 avg=2.79\n",
            "[4768 | 2047.75] loss=2.71 avg=2.79\n",
            "[4769 | 2049.43] loss=2.88 avg=2.79\n",
            "[4770 | 2051.11] loss=2.71 avg=2.79\n",
            "[4771 | 2052.80] loss=2.66 avg=2.78\n",
            "[4772 | 2054.48] loss=2.47 avg=2.78\n",
            "[4773 | 2056.17] loss=3.43 avg=2.79\n",
            "[4774 | 2057.86] loss=3.02 avg=2.79\n",
            "[4775 | 2059.55] loss=2.68 avg=2.79\n",
            "[4776 | 2061.23] loss=2.52 avg=2.79\n",
            "[4777 | 2062.91] loss=2.72 avg=2.79\n",
            "[4778 | 2064.59] loss=2.74 avg=2.79\n",
            "[4779 | 2066.27] loss=2.79 avg=2.79\n",
            "[4780 | 2067.95] loss=3.01 avg=2.79\n",
            "[4781 | 2069.63] loss=2.91 avg=2.79\n",
            "[4782 | 2071.32] loss=2.49 avg=2.79\n",
            "[4783 | 2073.01] loss=3.12 avg=2.79\n",
            "[4784 | 2074.67] loss=2.54 avg=2.79\n",
            "[4785 | 2076.36] loss=2.46 avg=2.78\n",
            "[4786 | 2078.03] loss=2.67 avg=2.78\n",
            "[4787 | 2079.72] loss=3.06 avg=2.78\n",
            "[4788 | 2081.40] loss=2.63 avg=2.78\n",
            "[4789 | 2083.08] loss=3.06 avg=2.79\n",
            "[4790 | 2084.77] loss=2.71 avg=2.79\n",
            "[4791 | 2086.45] loss=2.60 avg=2.78\n",
            "[4792 | 2088.13] loss=2.51 avg=2.78\n",
            "[4793 | 2089.81] loss=2.95 avg=2.78\n",
            "[4794 | 2091.49] loss=2.37 avg=2.78\n",
            "[4795 | 2093.18] loss=3.25 avg=2.78\n",
            "[4796 | 2094.86] loss=2.79 avg=2.78\n",
            "[4797 | 2096.54] loss=2.77 avg=2.78\n",
            "[4798 | 2098.23] loss=2.63 avg=2.78\n",
            "[4799 | 2099.91] loss=3.36 avg=2.79\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " work,\" said Mr. Richey. Mr. H. G. Cook, whose father was Mr. W. Cook and whose father was then a member of the Government for Adelaide, and whose elder brother was the late Mr. George Cook, came here as a boy. In 1863 Mr. Huggins was one of the first of his family to go to Australia, and he went to Australia in 1869 — then a colony — to see that his wife and children became emigrants. He married my sister, Miss Ellen Richey, daughter of Mr. and Mrs. H. G. C. Cook — his cousin. She came to this country in the early '60s, and was in the office of the Australian Institute. She retired a little over 25 years ago, but remains in the employ of the Government. When she went to live at Sydney, she came on a large number of trips — and the family, when they settled, brought out a large number of visitors, from all quarters of the world. For many years I used to travel in the Territory and then return in the summer, and I used to talk to my father once or twice a month, and he used to say that he felt the whole Territory had changed.\n",
            "\t\\@ Dickey, Joseph (1830–1924) \n",
            "\tMrs. J. S. F. Dickey (nee Jones), widow of the late Mr. [Joseph] Jones, of The Stables, South Yarra. She accompanied her husband to Melbourne, and lived in London until recently, when she went to Melbourne, where her marriage was annulled.\n",
            "\t\\@ McKeon, Frank (1856–1924) \n",
            "\tAt the death of Mr. Frank McKeon, at the age of 80 years, our resident magistrate, Dr. R. L. Broun, of the old Royal London Medical School, London, was selected to officiate, and Mr. Frank McKeon succeeded. We have just a few minutes to spare, for the deceased took a turn for the better. Having been in the public service so long, he had been an old friend and good neighbor to the community, and was a man of very high energy and ability. During his long career as magistrate, he always kept to himself and made himself an excellent judge of people, and he was often called upon to give advice. By the death of Mr. McKeon, it appears that there has been a general change in the way that persons are called upon to perform their duties, and, as a result of these new conditions, we are all left on our own in the discharge of our work.\n",
            "\t\\@ Goggin, Arthur (1835–1924) A report has been received from Sir Arthur Goggin, of Melbourne, that he is at the age of eighty years and that with his death will be succeeded by his wife, Madame Goggin, of Sydney, and there will be nothing left. He and Madame Goggin are survived by a son, William, and three grandchildren. They were born at Sydney on February 16, 1840, the year of their marriage.\n",
            "\t\\@ Dyer, Henry (1855–1924) State Library of NSW, N508038 The death occurred on Friday night of Mr. Henry Dyer, who was well known to the public during the last few months. Mr. Dyer's father, Mr. George Dyer, was a member of the early Pilgrims, and was buried in the old Church of England cemetery in Sydney, last year. Mr. Dyer, of Sydney, is survived, of Melbourne, by Mrs. Arthur Goggin, of Melbourne, and Mr. R. L. Broun, of Melbourne.\n",
            "\t\\@ White, William (1837–1924) \n",
            "\tWilliam White, a member of the deceased gentleman's family for many years in New South Wales, died on 8th inst.\n",
            "\tHe was formerly a member of the family, and was then a junior at Melbourne Grammar School. About seven years ago, Mr. White entered into an association with Dr. White with the object of inducing Mr. White to take a course at Melbourne Grammar School\n",
            "\tHe went on to obtain his G.A. degree at Cambridge, and, after completing his course, he moved his family to Tasmania with his brothers. Mr. W. G. White was born in Tasmania, where his father, Mr. William White, is the senior. Mr. William White, Mr. Edward White, and Mr. Charles White were all brothers. Mr. White entered the public service with his brother at Sydney about the year 1887. He was then sent overseas.\n",
            "\tMr. White, who is survived by his wife and son, and seven grandchildren, have arranged for burial in the church of St. Mary's, Morpeth. The will was duly signed by the deceased.\n",
            "\t\n",
            "\n",
            "[4800 | 2123.89] loss=2.52 avg=2.78\n",
            "[4801 | 2125.58] loss=2.51 avg=2.78\n",
            "[4802 | 2127.26] loss=2.56 avg=2.78\n",
            "[4803 | 2128.94] loss=2.52 avg=2.78\n",
            "[4804 | 2130.63] loss=2.64 avg=2.78\n",
            "[4805 | 2132.31] loss=3.03 avg=2.78\n",
            "[4806 | 2134.00] loss=2.99 avg=2.78\n",
            "[4807 | 2135.68] loss=2.79 avg=2.78\n",
            "[4808 | 2137.36] loss=2.89 avg=2.78\n",
            "[4809 | 2139.04] loss=2.36 avg=2.78\n",
            "[4810 | 2140.72] loss=2.97 avg=2.78\n",
            "[4811 | 2142.41] loss=2.87 avg=2.78\n",
            "[4812 | 2144.09] loss=2.63 avg=2.78\n",
            "[4813 | 2145.77] loss=3.07 avg=2.78\n",
            "[4814 | 2147.45] loss=3.21 avg=2.79\n",
            "[4815 | 2149.13] loss=3.46 avg=2.79\n",
            "[4816 | 2150.82] loss=3.06 avg=2.80\n",
            "[4817 | 2152.50] loss=2.99 avg=2.80\n",
            "[4818 | 2154.18] loss=2.42 avg=2.79\n",
            "[4819 | 2155.86] loss=2.41 avg=2.79\n",
            "[4820 | 2157.54] loss=2.69 avg=2.79\n",
            "[4821 | 2159.23] loss=3.26 avg=2.79\n",
            "[4822 | 2160.90] loss=2.96 avg=2.79\n",
            "[4823 | 2162.59] loss=3.06 avg=2.80\n",
            "[4824 | 2164.27] loss=2.67 avg=2.80\n",
            "[4825 | 2165.95] loss=2.49 avg=2.79\n",
            "[4826 | 2167.63] loss=2.46 avg=2.79\n",
            "[4827 | 2169.32] loss=2.34 avg=2.79\n",
            "[4828 | 2171.00] loss=2.62 avg=2.78\n",
            "[4829 | 2172.69] loss=2.46 avg=2.78\n",
            "[4830 | 2174.37] loss=2.99 avg=2.78\n",
            "[4831 | 2176.06] loss=2.64 avg=2.78\n",
            "[4832 | 2177.73] loss=2.79 avg=2.78\n",
            "[4833 | 2179.41] loss=2.47 avg=2.78\n",
            "[4834 | 2181.10] loss=2.19 avg=2.77\n",
            "[4835 | 2182.78] loss=2.66 avg=2.77\n",
            "[4836 | 2184.47] loss=2.84 avg=2.77\n",
            "[4837 | 2186.16] loss=2.56 avg=2.77\n",
            "[4838 | 2187.85] loss=2.88 avg=2.77\n",
            "[4839 | 2189.53] loss=2.42 avg=2.77\n",
            "[4840 | 2191.21] loss=3.13 avg=2.77\n",
            "[4841 | 2192.90] loss=2.54 avg=2.77\n",
            "[4842 | 2194.59] loss=2.53 avg=2.77\n",
            "[4843 | 2196.29] loss=2.71 avg=2.77\n",
            "[4844 | 2197.99] loss=3.11 avg=2.77\n",
            "[4845 | 2199.69] loss=2.91 avg=2.77\n",
            "[4846 | 2201.38] loss=2.33 avg=2.77\n",
            "[4847 | 2203.07] loss=2.59 avg=2.76\n",
            "[4848 | 2204.77] loss=3.24 avg=2.77\n",
            "[4849 | 2206.48] loss=2.61 avg=2.77\n",
            "[4850 | 2208.18] loss=2.46 avg=2.76\n",
            "[4851 | 2209.88] loss=2.95 avg=2.77\n",
            "[4852 | 2211.58] loss=2.83 avg=2.77\n",
            "[4853 | 2213.28] loss=2.95 avg=2.77\n",
            "[4854 | 2214.98] loss=2.27 avg=2.76\n",
            "[4855 | 2216.69] loss=2.63 avg=2.76\n",
            "[4856 | 2218.38] loss=2.61 avg=2.76\n",
            "[4857 | 2220.08] loss=2.48 avg=2.76\n",
            "[4858 | 2221.79] loss=2.47 avg=2.76\n",
            "[4859 | 2223.49] loss=2.80 avg=2.76\n",
            "[4860 | 2225.19] loss=3.08 avg=2.76\n",
            "[4861 | 2226.89] loss=2.39 avg=2.76\n",
            "[4862 | 2228.59] loss=2.75 avg=2.76\n",
            "[4863 | 2230.30] loss=2.37 avg=2.75\n",
            "[4864 | 2232.00] loss=3.23 avg=2.76\n",
            "[4865 | 2233.70] loss=2.67 avg=2.76\n",
            "[4866 | 2235.40] loss=2.86 avg=2.76\n",
            "[4867 | 2237.11] loss=2.80 avg=2.76\n",
            "[4868 | 2238.82] loss=2.72 avg=2.76\n",
            "[4869 | 2240.52] loss=2.82 avg=2.76\n",
            "[4870 | 2242.22] loss=2.61 avg=2.76\n",
            "[4871 | 2243.92] loss=3.21 avg=2.76\n",
            "[4872 | 2245.62] loss=2.51 avg=2.76\n",
            "[4873 | 2247.33] loss=2.53 avg=2.76\n",
            "[4874 | 2249.03] loss=3.12 avg=2.76\n",
            "[4875 | 2250.73] loss=2.97 avg=2.76\n",
            "[4876 | 2252.43] loss=3.19 avg=2.77\n",
            "[4877 | 2254.13] loss=2.35 avg=2.76\n",
            "[4878 | 2255.83] loss=2.63 avg=2.76\n",
            "[4879 | 2257.53] loss=2.56 avg=2.76\n",
            "[4880 | 2259.23] loss=2.40 avg=2.75\n",
            "[4881 | 2260.93] loss=2.73 avg=2.75\n",
            "[4882 | 2262.63] loss=2.72 avg=2.75\n",
            "[4883 | 2264.33] loss=3.24 avg=2.76\n",
            "[4884 | 2266.03] loss=2.94 avg=2.76\n",
            "[4885 | 2267.74] loss=2.24 avg=2.76\n",
            "[4886 | 2269.44] loss=2.82 avg=2.76\n",
            "[4887 | 2271.14] loss=2.51 avg=2.75\n",
            "[4888 | 2272.84] loss=2.68 avg=2.75\n",
            "[4889 | 2274.54] loss=2.51 avg=2.75\n",
            "[4890 | 2276.24] loss=3.07 avg=2.75\n",
            "[4891 | 2277.95] loss=2.60 avg=2.75\n",
            "[4892 | 2279.65] loss=2.59 avg=2.75\n",
            "[4893 | 2281.35] loss=2.70 avg=2.75\n",
            "[4894 | 2283.05] loss=2.60 avg=2.75\n",
            "[4895 | 2284.76] loss=2.75 avg=2.75\n",
            "[4896 | 2286.46] loss=2.93 avg=2.75\n",
            "[4897 | 2288.16] loss=2.22 avg=2.74\n",
            "[4898 | 2289.86] loss=2.58 avg=2.74\n",
            "[4899 | 2291.56] loss=2.60 avg=2.74\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " was sent to Australia with the expedition, but, when the opportunity presented itself he gave up the attempt, leaving the settlement on the coast of Australia.\n",
            "\tHe also carried out important public works, such as the opening of an office for the purpose of public administration by which funds were sent to the colony, and, in exchange for the privilege of his entering upon the public service, he gave up all claims to fame, and began to live in retirement. He died on December 13, 1839, leaving behind him a widow, six children, and three brothers and sisters, the eldest being Mrs. A. G. Jones, daughter of Mr. G. Jones, Esq., of Adelaide; the second, Mrs. George Lubbock, with the same name; the third, his brother, Mr. Stephen D. Jones, Esq., of Adelaide; and the last, Mrs. Jones.\n",
            "\tAfter a distinguished career of service to his country, and the support of great friends, Mr. Jones became a member of Parliament for that district, and during the last few months had occupied a seat in the House on the hon. Ministerial Committee, which was elected on September 28, 1844. He was a resident of that place for the entire period of his association with this colony, and was a member of the Royal Society for a number of years. In 1855 he commenced to publish a volume of poetry, entitled \"The Poems of Sir John Harrison,\" which was printed in the same year that the first volume of a similar nature was published in this colony.\n",
            "\tMr. Jones had a special and important interest in the public affairs of his country, as he had for many years been the only citizen who maintained the original of the Charter of the British and Loyal States of Australia.\n",
            "\tThe deceased gentleman was the first member of the Royal Society to whom the award, which he conferred on the late Dr. John D. T. Jones, was conferred, and he died in his honour. He was also a member of the Board of Control of the Australian Broadcasting Authority, an officer of the Royal Society of Britain, and a member of the Royal Commission into the Causes of the Revolution.\n",
            "\t\\@ Bowerman, Benjamin Henry (1822–1895) \n",
            "\tThe sad death occurred late yesterday of Mr. Benjamin Henry Bowerman, formerly Minister for the Colonies, in his 79th year. Although it was believed that the deceased had been in a fit for some time during his residence in the district, Dr. Denton, a well-known physician, who was on his way to assist in the operation, declared that the former Minister would not have died so young.\n",
            "\tThe deceased gentleman was born at Merv, in the Western District of Victoria, and was the eldest son of the late J. L. Bowersma. In 1823 Mr. Bowerman moved with his parents and two children to the district, and spent the next twelve years at Warrenton, where he married Sarah, the eldest of his two sisters (the last was at Warrenton). In 1825 he left Warrenton and went to join the War Department, and then went out to the colony, where he was appointed Inspector-General of the Police Service.\n",
            "\tWith reference to the State government he was very active in the administration work, in which capacity he presided over his younger brother, Major Bower, during the period 1828 to 1848, and then, in 1854, for a time as a member of the Legislative Assembly.\n",
            "\tMr. Bowerman had always been a public man, and was always regarded as one of the earliest settlers in this district. He was at all times prominent in public affairs, and was a member of the Town Council, of the Royal Society , of the Colonies Convention of 1843, and a director of various companies in the colony, and was a son of the late Mr. Thomas Bowerman, late M.P.\n",
            "\tThe late Mr. Bowerman is survived by his wife and three daughters, all of whom are of sound minds, and one sister is married.\n",
            "\t\\@ Hutton, William (1779–1895) In the early days of the Colony William Hutton, who died at Newcastle, was probably the oldest settler in Victoria, and who has left a legacy of influence in his colony which many descendants will cherish. He was born at Kilmore, near Melbourne, in 1776, and his father had come to the colony from the country of the Pilbara, about 12½ miles from Victoria. His first wife was a widow, but he left for Australia after his second wife had died and, when they were both about fifty, he married another of his sisters, Julia. Their children are: Messrs. J. E. Hutton, of Kempsey, and R. P. Hutton , of Narrow Bay. Of Mrs. Hutton's daughters he only survived. The\n",
            "\n",
            "[4900 | 2315.51] loss=3.12 avg=2.75\n",
            "[4901 | 2317.19] loss=2.43 avg=2.74\n",
            "[4902 | 2318.87] loss=2.62 avg=2.74\n",
            "[4903 | 2320.55] loss=2.49 avg=2.74\n",
            "[4904 | 2322.22] loss=2.75 avg=2.74\n",
            "[4905 | 2323.90] loss=2.52 avg=2.74\n",
            "[4906 | 2325.57] loss=2.60 avg=2.74\n",
            "[4907 | 2327.24] loss=3.20 avg=2.74\n",
            "[4908 | 2328.92] loss=2.75 avg=2.74\n",
            "[4909 | 2330.58] loss=2.35 avg=2.74\n",
            "[4910 | 2332.26] loss=2.68 avg=2.74\n",
            "[4911 | 2333.94] loss=2.58 avg=2.73\n",
            "[4912 | 2335.62] loss=2.86 avg=2.74\n",
            "[4913 | 2337.31] loss=2.83 avg=2.74\n",
            "[4914 | 2338.98] loss=3.15 avg=2.74\n",
            "[4915 | 2340.66] loss=2.89 avg=2.74\n",
            "[4916 | 2342.34] loss=3.41 avg=2.75\n",
            "[4917 | 2344.02] loss=2.78 avg=2.75\n",
            "[4918 | 2345.70] loss=2.70 avg=2.75\n",
            "[4919 | 2347.39] loss=2.51 avg=2.75\n",
            "[4920 | 2349.08] loss=2.32 avg=2.74\n",
            "[4921 | 2350.76] loss=2.70 avg=2.74\n",
            "[4922 | 2352.47] loss=2.67 avg=2.74\n",
            "[4923 | 2354.17] loss=2.61 avg=2.74\n",
            "[4924 | 2355.86] loss=3.03 avg=2.74\n",
            "[4925 | 2357.55] loss=2.48 avg=2.74\n",
            "[4926 | 2359.25] loss=2.46 avg=2.74\n",
            "[4927 | 2360.95] loss=2.19 avg=2.73\n",
            "[4928 | 2362.64] loss=2.87 avg=2.73\n",
            "[4929 | 2364.34] loss=2.54 avg=2.73\n",
            "[4930 | 2366.04] loss=2.74 avg=2.73\n",
            "[4931 | 2367.74] loss=2.45 avg=2.73\n",
            "[4932 | 2369.45] loss=3.10 avg=2.73\n",
            "[4933 | 2371.15] loss=2.93 avg=2.73\n",
            "[4934 | 2372.86] loss=2.48 avg=2.73\n",
            "[4935 | 2374.56] loss=2.24 avg=2.73\n",
            "[4936 | 2376.26] loss=2.44 avg=2.72\n",
            "[4937 | 2377.97] loss=2.88 avg=2.72\n",
            "[4938 | 2379.67] loss=2.64 avg=2.72\n",
            "[4939 | 2381.37] loss=3.09 avg=2.73\n",
            "[4940 | 2383.07] loss=3.10 avg=2.73\n",
            "[4941 | 2384.77] loss=2.52 avg=2.73\n",
            "[4942 | 2386.48] loss=2.84 avg=2.73\n",
            "[4943 | 2388.17] loss=2.88 avg=2.73\n",
            "[4944 | 2389.88] loss=2.49 avg=2.73\n",
            "[4945 | 2391.58] loss=2.65 avg=2.73\n",
            "[4946 | 2393.28] loss=2.92 avg=2.73\n",
            "[4947 | 2394.99] loss=3.01 avg=2.73\n",
            "[4948 | 2396.68] loss=2.91 avg=2.74\n",
            "[4949 | 2398.39] loss=2.42 avg=2.73\n",
            "[4950 | 2400.09] loss=2.97 avg=2.73\n",
            "[4951 | 2401.79] loss=2.85 avg=2.74\n",
            "[4952 | 2403.49] loss=3.04 avg=2.74\n",
            "[4953 | 2405.20] loss=2.37 avg=2.73\n",
            "[4954 | 2406.89] loss=3.37 avg=2.74\n",
            "[4955 | 2408.59] loss=2.45 avg=2.74\n",
            "[4956 | 2410.30] loss=2.61 avg=2.74\n",
            "[4957 | 2412.00] loss=2.86 avg=2.74\n",
            "[4958 | 2413.70] loss=2.52 avg=2.74\n",
            "[4959 | 2415.41] loss=2.40 avg=2.73\n",
            "[4960 | 2417.10] loss=2.35 avg=2.73\n",
            "[4961 | 2418.81] loss=2.51 avg=2.73\n",
            "[4962 | 2420.50] loss=2.53 avg=2.72\n",
            "[4963 | 2422.21] loss=3.21 avg=2.73\n",
            "[4964 | 2423.91] loss=2.84 avg=2.73\n",
            "[4965 | 2425.61] loss=2.98 avg=2.73\n",
            "[4966 | 2427.31] loss=2.27 avg=2.73\n",
            "[4967 | 2429.01] loss=2.35 avg=2.72\n",
            "[4968 | 2430.71] loss=2.96 avg=2.73\n",
            "[4969 | 2432.41] loss=2.46 avg=2.72\n",
            "[4970 | 2434.12] loss=2.27 avg=2.72\n",
            "[4971 | 2435.82] loss=2.86 avg=2.72\n",
            "[4972 | 2437.52] loss=2.99 avg=2.72\n",
            "[4973 | 2439.22] loss=2.29 avg=2.72\n",
            "[4974 | 2440.90] loss=2.34 avg=2.72\n",
            "[4975 | 2442.61] loss=2.83 avg=2.72\n",
            "[4976 | 2444.31] loss=2.83 avg=2.72\n",
            "[4977 | 2446.01] loss=2.65 avg=2.72\n",
            "[4978 | 2447.72] loss=2.77 avg=2.72\n",
            "[4979 | 2449.41] loss=2.74 avg=2.72\n",
            "[4980 | 2451.11] loss=2.43 avg=2.72\n",
            "[4981 | 2452.82] loss=2.56 avg=2.71\n",
            "[4982 | 2454.52] loss=3.14 avg=2.72\n",
            "[4983 | 2456.22] loss=2.67 avg=2.72\n",
            "[4984 | 2457.92] loss=3.00 avg=2.72\n",
            "[4985 | 2459.62] loss=3.13 avg=2.72\n",
            "[4986 | 2461.33] loss=2.76 avg=2.72\n",
            "[4987 | 2463.03] loss=2.35 avg=2.72\n",
            "[4988 | 2464.72] loss=3.14 avg=2.73\n",
            "[4989 | 2466.43] loss=2.77 avg=2.73\n",
            "[4990 | 2468.13] loss=3.31 avg=2.73\n",
            "[4991 | 2469.83] loss=2.26 avg=2.73\n",
            "[4992 | 2471.54] loss=2.90 avg=2.73\n",
            "[4993 | 2473.23] loss=2.68 avg=2.73\n",
            "[4994 | 2474.93] loss=2.39 avg=2.72\n",
            "[4995 | 2476.63] loss=3.31 avg=2.73\n",
            "[4996 | 2478.34] loss=2.87 avg=2.73\n",
            "[4997 | 2480.04] loss=3.03 avg=2.74\n",
            "[4998 | 2481.75] loss=2.48 avg=2.73\n",
            "[4999 | 2483.44] loss=2.71 avg=2.73\n",
            "Saving checkpoint/run1/model-5000\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "There appears to have been an agreement that the property is to be used as a summer home for children or other carers.\n",
            "\tAlthough he is believed to have made a good living in the past, Sir John was a keen golfer himself.\n",
            "\tIn 1937 he was ranked fourth in the junior golf competition for Melbourne and in 1940 he was voted into the Melbourne Cup, becoming only the second Australian to win three titles. The first being a Grand Slam win at the Sydney Amateur Club.\n",
            "\tTo celebrate the success of his career, Sir John's former business partner, a carpenter named James Brown, opened a business called John Brown Company on Palmerston, and during their first year sold over half a million cars. A year later they closed.\n",
            "\tDuring the 1950s, Brown had many visitors, including the Queen and Prince Philip, as well as a member of the royal family, Princess Margaret and Prince Phillip.\n",
            "\tHowever, Sir John took a somewhat cold attitude toward Brown and did not appreciate the mania for cars he had achieved.\n",
            "\t\"In the days when there were no cars there was always the temptation to get one for the Queen and Prince Philip at Christmas,\" Brown wrote in one of his autobiographies. \"But he was such a good car enthusiast that everyone, even though it was a great deal on the motor, would love to have him one.\"\n",
            "\tSir John was also a keen golfer, having won the state championship in 1952.\n",
            "\tSir John Brown, who suffered from cancer of the brain, lungs and lymphatic system, died in Melbourne on May 26th. The late Sir John's death was announced by Australian Prime Minister Sir John Menzies.\n",
            "\tWhile Sir John Brown was in his 90s he was very active in the Australian Golf Association and golf courses were often shown in his honour.\n",
            "\tA special tribute is being paid to Sir John by the RAC, which has sponsored the event which he attended and is organising for a day-long charity gala at the Royal Oak Golf Club which is to be held on October 8, 2014.\n",
            "\tIn addition, some 350 golf courses around Australia will also have their names etched on a plaque outside.\n",
            "\tThe RAC is also holding a series of events in his honour. The Royal Oak Golf Club is hosting a special gala on October 8, attended by members of the Queen's Royal Australian Legion and guests from across Australia, along with some of the late Sir John's other sports.\n",
            "\tThere will be a reception for all to take place from 4pm at the clubhouse.\n",
            "\tOn Tuesday, the Australian Golf Association has announced a £600,000 golf course to be built at Palmerston in memory of one of the most significant sporting figures in Australian sporting history.\n",
            "\tThe project, dubbed The Palmerston Course is about 60 years in the making, and is the first of its kind in Australia. The course will run for the next 40 years and features a four-hole par-72.\n",
            "\tThe Palmerston Course has become an international success, and the course is still the official golf course for the Royal Australian Legion.\n",
            "\tIt is due to open in the coming months.\n",
            "\t''It is with deep sadness I announce the death of John Brown,'' chief executive Mark Hahn said.\n",
            "\tThe late Mr Brown was born in Brisbane on July 10 in 1916. He went to school in Brisbane, studied at university in Melbourne, and went to work at Palmerston General Hospital in Queensland, where he was a member of three clinical units there.\n",
            "\tHis family went to Western Australia then to Tasmania. There he worked in the medical department of the Waratah Dam, where he learned about the biology of the Dam.\n",
            "\tAfter leaving the medical division he returned to Queensland, where he found work as a trainee anaesthetist at the Radley Hospital, and after that, at the Radley Hospital of Queensland.\n",
            "\tThere were no children at the time, so he became responsible for the care of a few in the Hospital.\n",
            "\tIn 1932 he became medical superintendent at the Radley Hospital, then in 1939 became medical superintendent at the A.P.H. hospital in Queensland.\n",
            "\tThe post at the Radley Hospital was a very stressful job, but Mr Brown was well qualified, and in 1950 he became a director of the Queensland Hospital Authority.\n",
            "\tHe became the first director emeritus (since 1956) and director emeritus of the Queensland Hospital Authority.\n",
            "\tHe retired from the hospital in 1954 to go to Queensland, and continued as director emeritus until his death.\n",
            "\tIn 1957, with his wife, a former hospital nurse, he returned to Queensland and became executive director of the Queensland Hospital Authority in 1971.\n",
            "\tIn that role he developed the QHCA as an organisation into such a strong and functional institution that it was taken over by the Royal Health and Hospital Authority in 1973.\n",
            "\tIn 1975, a new director emeritus and director emeritus\n",
            "\n",
            "[5000 | 2518.21] loss=2.81 avg=2.73\n",
            "[5001 | 2519.96] loss=2.50 avg=2.73\n",
            "[5002 | 2521.74] loss=2.52 avg=2.73\n",
            "[5003 | 2523.50] loss=2.55 avg=2.73\n",
            "[5004 | 2525.24] loss=2.78 avg=2.73\n",
            "[5005 | 2526.98] loss=2.82 avg=2.73\n",
            "[5006 | 2528.70] loss=2.58 avg=2.73\n",
            "[5007 | 2530.42] loss=3.04 avg=2.73\n",
            "[5008 | 2532.12] loss=2.15 avg=2.72\n",
            "[5009 | 2533.83] loss=2.97 avg=2.73\n",
            "[5010 | 2535.53] loss=2.51 avg=2.72\n",
            "[5011 | 2537.23] loss=2.93 avg=2.73\n",
            "[5012 | 2538.93] loss=2.51 avg=2.72\n",
            "[5013 | 2540.62] loss=2.53 avg=2.72\n",
            "[5014 | 2542.30] loss=2.74 avg=2.72\n",
            "[5015 | 2543.98] loss=2.82 avg=2.72\n",
            "[5016 | 2545.66] loss=2.71 avg=2.72\n",
            "[5017 | 2547.32] loss=3.47 avg=2.73\n",
            "[5018 | 2548.99] loss=2.73 avg=2.73\n",
            "[5019 | 2550.66] loss=2.60 avg=2.73\n",
            "[5020 | 2552.32] loss=3.11 avg=2.73\n",
            "[5021 | 2553.98] loss=2.55 avg=2.73\n",
            "[5022 | 2555.64] loss=2.23 avg=2.73\n",
            "[5023 | 2557.30] loss=3.12 avg=2.73\n",
            "[5024 | 2558.96] loss=2.92 avg=2.73\n",
            "[5025 | 2560.62] loss=2.48 avg=2.73\n",
            "[5026 | 2562.29] loss=2.23 avg=2.72\n",
            "[5027 | 2563.95] loss=2.91 avg=2.73\n",
            "[5028 | 2565.63] loss=2.85 avg=2.73\n",
            "[5029 | 2567.29] loss=2.78 avg=2.73\n",
            "[5030 | 2568.96] loss=2.73 avg=2.73\n",
            "[5031 | 2570.63] loss=3.03 avg=2.73\n",
            "[5032 | 2572.30] loss=3.10 avg=2.74\n",
            "[5033 | 2573.98] loss=2.83 avg=2.74\n",
            "[5034 | 2575.66] loss=2.60 avg=2.73\n",
            "[5035 | 2577.35] loss=2.58 avg=2.73\n",
            "[5036 | 2579.03] loss=3.06 avg=2.74\n",
            "[5037 | 2580.72] loss=2.77 avg=2.74\n",
            "[5038 | 2582.43] loss=2.61 avg=2.74\n",
            "[5039 | 2584.12] loss=3.08 avg=2.74\n",
            "[5040 | 2585.83] loss=2.39 avg=2.74\n",
            "[5041 | 2587.53] loss=2.73 avg=2.74\n",
            "[5042 | 2589.23] loss=2.86 avg=2.74\n",
            "[5043 | 2590.94] loss=2.50 avg=2.73\n",
            "[5044 | 2592.64] loss=2.16 avg=2.73\n",
            "[5045 | 2594.34] loss=2.34 avg=2.72\n",
            "[5046 | 2596.05] loss=2.65 avg=2.72\n",
            "[5047 | 2597.75] loss=2.54 avg=2.72\n",
            "[5048 | 2599.45] loss=2.74 avg=2.72\n",
            "[5049 | 2601.15] loss=2.74 avg=2.72\n",
            "[5050 | 2602.85] loss=3.27 avg=2.73\n",
            "[5051 | 2604.55] loss=2.84 avg=2.73\n",
            "[5052 | 2606.25] loss=3.05 avg=2.73\n",
            "[5053 | 2607.95] loss=2.58 avg=2.73\n",
            "[5054 | 2609.65] loss=2.43 avg=2.73\n",
            "[5055 | 2611.35] loss=2.71 avg=2.73\n",
            "[5056 | 2613.05] loss=2.53 avg=2.73\n",
            "[5057 | 2614.75] loss=2.98 avg=2.73\n",
            "[5058 | 2616.45] loss=2.61 avg=2.73\n",
            "[5059 | 2618.15] loss=2.97 avg=2.73\n",
            "[5060 | 2619.85] loss=2.47 avg=2.73\n",
            "[5061 | 2621.54] loss=2.87 avg=2.73\n",
            "[5062 | 2623.22] loss=2.97 avg=2.73\n",
            "[5063 | 2624.91] loss=3.32 avg=2.74\n",
            "[5064 | 2626.60] loss=2.56 avg=2.73\n",
            "[5065 | 2628.29] loss=3.08 avg=2.74\n",
            "[5066 | 2629.98] loss=2.62 avg=2.74\n",
            "[5067 | 2631.67] loss=2.24 avg=2.73\n",
            "[5068 | 2633.36] loss=2.86 avg=2.73\n",
            "[5069 | 2635.05] loss=2.16 avg=2.73\n",
            "[5070 | 2636.73] loss=2.93 avg=2.73\n",
            "[5071 | 2638.42] loss=2.26 avg=2.72\n",
            "[5072 | 2640.09] loss=3.01 avg=2.73\n",
            "[5073 | 2641.78] loss=2.88 avg=2.73\n",
            "[5074 | 2643.46] loss=2.76 avg=2.73\n",
            "[5075 | 2645.14] loss=3.04 avg=2.73\n",
            "[5076 | 2646.83] loss=2.78 avg=2.73\n",
            "[5077 | 2648.51] loss=2.80 avg=2.73\n",
            "[5078 | 2650.20] loss=2.86 avg=2.74\n",
            "[5079 | 2651.88] loss=2.95 avg=2.74\n",
            "[5080 | 2653.57] loss=2.87 avg=2.74\n",
            "[5081 | 2655.23] loss=2.72 avg=2.74\n",
            "[5082 | 2656.93] loss=2.67 avg=2.74\n",
            "[5083 | 2658.63] loss=2.93 avg=2.74\n",
            "[5084 | 2660.32] loss=2.50 avg=2.74\n",
            "[5085 | 2662.02] loss=2.12 avg=2.73\n",
            "[5086 | 2663.71] loss=2.52 avg=2.73\n",
            "[5087 | 2665.42] loss=3.05 avg=2.73\n",
            "[5088 | 2667.12] loss=2.92 avg=2.73\n",
            "[5089 | 2668.81] loss=3.01 avg=2.74\n",
            "[5090 | 2670.50] loss=2.80 avg=2.74\n",
            "[5091 | 2672.20] loss=2.70 avg=2.74\n",
            "[5092 | 2673.90] loss=2.49 avg=2.73\n",
            "[5093 | 2675.61] loss=3.46 avg=2.74\n",
            "[5094 | 2677.31] loss=3.07 avg=2.75\n",
            "[5095 | 2679.01] loss=2.39 avg=2.74\n",
            "[5096 | 2680.72] loss=2.89 avg=2.74\n",
            "[5097 | 2682.41] loss=3.54 avg=2.75\n",
            "[5098 | 2684.11] loss=2.43 avg=2.75\n",
            "[5099 | 2685.82] loss=2.50 avg=2.75\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            "\t>A man of good moral and chivalrous instincts. The death of Mr. Robert McEvoy on Saturday leaves three sons, Harry and Alfred McEvoy. Harry is the eldest son and Alfred is the second. Harry was married at St. Thomas' College (Rosedale), in May, 1916. This marriage is recorded in the late Fred A. McEwan's book 'The Life and Times of Alfred McEvoy', published in 1928. Mr McEwan's father took part in his mother's war work in WWI, and was among the first men who served upon the front. It is recorded in the book that Mr McEwan's father, the late Mr C. A. McEvoy, was the first to enlist in the 1st Battalion Royal Lancashire Rifles. Mr McEvoy was promoted to corporal and was promoted to sergeant before he was sent into combat, serving with the 1st Battalion in France. He was awarded the Military Cross. He remained at the front as a private officer until the end of the war. He was, Mr McEwan says, 'a gentleman from the outset.' The funeral will take place this afternoon.\n",
            "\t\\@ Fergusson, William (1851–1928) News will be circulated on Saturday, August 7, that Mr. Bill Fergusson, owner, manager, and director of the National Bank, Sydney, was fatally wounded in an accident at North Point on the 29th August, just a short distance from his residence, North Bay.The late Mr. Fergusson, who was 81 years of age, leaves a wife and two young children (he never married) to mourn the sad death of a well-known man and an important banker. Mr. Fergusson, who was born in England, was a son of the late Sir William Fergusson, M.P.\"Sebastian,\" M.L.A., Chairman of the Royal Bank of Australia, and also a Fellow of the Royal Society. He was born in England in 1851 and was educated at St. Paul's College , Melbourne, and in Sydney University, where he was knighted by the Queen in 1882.The late Mr. Fergusson spent his early life in Sydney, and after gaining his qualifications, entered into banking life at the Bank of Australasia, Sydney , in 1887. With other banking houses he went to Paris and became Managing Director of the Commercial Bank of New England , Australia, which was incorporated on the basis of the National Bank, of Sydney, that was incorporated on the same basis as the Bank of South Australia. During that time, he had a long and distinguished practice in New England and South Africa, and he was a director of the Bank of South Australia for a period. Mr. Fergusson was for years head of the Commercial and Trustees Service at the Commercial Bank of New England, and was on a visit to America in 1888, after visiting Australia for the past fourteen years, when Mr. Fergusson was killed.The deceased was a prominent member of the church, having been a member of St. Paul's College, Melbourne, and St. Paul's College, Melbourne. He was a member of the Royal Australian Society, a brother of Mrs. Hilda Lefroy Fergusson, of Windsor. He was a member of the Christian Brothers' Charitable Charitable Fund, and a director of the Southern Cross Bank, Sydney, and of the Royal Agricultural Mortgage Co. He was also an active member of various groups, including the Royal Society of Arts and the Order of the New England Jubilee.His family is highly respected in the Sydney metropolitan area and the district as a whole, and he also held a number of positions of public trust and government responsibility.A memorial service is to be held at St. Paul's College, Melbourne, today, to pay tribute to a man of such great integrity, such a great man, and the man who knew more about money than anybody else in town.\n",
            "\t\\@ Clarke, James (1847–1928) State Library of New South Wales, B 133933\n",
            "\t\\@ Liddell, Sir George (1874–1928) \n",
            "\tAt a private meeting of members of the Legislative Council, Mr George Liddell, of North Sydney (and later of North Gosford), expressed his regret that he had not been given a chance of going to Melbourne during the six weeks' time given the members.\n",
            "\tMr Liddell left Sydney on August 30, 1883. While he was abroad he held a position as Manager to the General Manager of Bank of New South Wales, Australia, and as a director of the Bank of New South Wales, Australia. He had no part in the banking business until he purchased North Gosford in 1899, and had then taken a general view of the business and the district. He then embarked upon the management of the district.\n",
            "\n",
            "[5100 | 2709.74] loss=2.77 avg=2.75\n",
            "[5101 | 2711.42] loss=2.46 avg=2.74\n",
            "[5102 | 2713.10] loss=2.19 avg=2.74\n",
            "[5103 | 2714.78] loss=3.29 avg=2.74\n",
            "[5104 | 2716.44] loss=3.50 avg=2.75\n",
            "[5105 | 2718.12] loss=2.87 avg=2.75\n",
            "[5106 | 2719.80] loss=2.71 avg=2.75\n",
            "[5107 | 2721.48] loss=2.65 avg=2.75\n",
            "[5108 | 2723.15] loss=2.43 avg=2.75\n",
            "[5109 | 2724.82] loss=2.65 avg=2.75\n",
            "[5110 | 2726.50] loss=3.12 avg=2.75\n",
            "[5111 | 2728.18] loss=2.45 avg=2.75\n",
            "[5112 | 2729.85] loss=2.70 avg=2.75\n",
            "[5113 | 2731.53] loss=2.37 avg=2.74\n",
            "[5114 | 2733.21] loss=2.46 avg=2.74\n",
            "[5115 | 2734.89] loss=2.24 avg=2.73\n",
            "[5116 | 2736.58] loss=3.40 avg=2.74\n",
            "[5117 | 2738.26] loss=2.67 avg=2.74\n",
            "[5118 | 2739.94] loss=2.78 avg=2.74\n",
            "[5119 | 2741.63] loss=2.49 avg=2.74\n",
            "[5120 | 2743.31] loss=2.30 avg=2.73\n",
            "[5121 | 2745.01] loss=2.21 avg=2.73\n",
            "[5122 | 2746.69] loss=2.66 avg=2.73\n",
            "[5123 | 2748.39] loss=3.21 avg=2.73\n",
            "[5124 | 2750.08] loss=2.39 avg=2.73\n",
            "[5125 | 2751.78] loss=2.60 avg=2.73\n",
            "[5126 | 2753.48] loss=2.59 avg=2.73\n",
            "[5127 | 2755.19] loss=3.32 avg=2.73\n",
            "[5128 | 2756.88] loss=2.82 avg=2.73\n",
            "[5129 | 2758.59] loss=2.60 avg=2.73\n",
            "[5130 | 2760.29] loss=2.41 avg=2.73\n",
            "[5131 | 2762.00] loss=2.63 avg=2.73\n",
            "[5132 | 2763.70] loss=2.68 avg=2.73\n",
            "[5133 | 2765.40] loss=2.61 avg=2.73\n",
            "[5134 | 2767.10] loss=3.16 avg=2.73\n",
            "[5135 | 2768.80] loss=2.36 avg=2.73\n",
            "[5136 | 2770.50] loss=2.95 avg=2.73\n",
            "[5137 | 2772.20] loss=3.10 avg=2.73\n",
            "[5138 | 2773.91] loss=2.54 avg=2.73\n",
            "[5139 | 2775.61] loss=2.72 avg=2.73\n",
            "[5140 | 2777.31] loss=2.47 avg=2.73\n",
            "[5141 | 2779.01] loss=2.55 avg=2.73\n",
            "[5142 | 2780.71] loss=2.32 avg=2.72\n",
            "[5143 | 2782.39] loss=2.69 avg=2.72\n",
            "[5144 | 2784.10] loss=2.58 avg=2.72\n",
            "[5145 | 2785.80] loss=3.00 avg=2.72\n",
            "[5146 | 2787.50] loss=2.77 avg=2.72\n",
            "[5147 | 2789.20] loss=3.24 avg=2.73\n",
            "[5148 | 2790.90] loss=2.99 avg=2.73\n",
            "[5149 | 2792.60] loss=2.44 avg=2.73\n",
            "[5150 | 2794.30] loss=2.53 avg=2.73\n",
            "[5151 | 2796.00] loss=2.25 avg=2.72\n",
            "[5152 | 2797.69] loss=3.23 avg=2.73\n",
            "[5153 | 2799.38] loss=3.21 avg=2.73\n",
            "[5154 | 2801.08] loss=2.76 avg=2.73\n",
            "[5155 | 2802.78] loss=2.73 avg=2.73\n",
            "[5156 | 2804.48] loss=3.51 avg=2.74\n",
            "[5157 | 2806.16] loss=2.71 avg=2.74\n",
            "[5158 | 2807.86] loss=2.47 avg=2.74\n",
            "[5159 | 2809.55] loss=2.47 avg=2.73\n",
            "[5160 | 2811.25] loss=2.79 avg=2.73\n",
            "[5161 | 2812.93] loss=3.23 avg=2.74\n",
            "[5162 | 2814.64] loss=2.59 avg=2.74\n",
            "[5163 | 2816.32] loss=3.06 avg=2.74\n",
            "[5164 | 2818.01] loss=2.26 avg=2.74\n",
            "[5165 | 2819.70] loss=2.27 avg=2.73\n",
            "[5166 | 2821.39] loss=2.83 avg=2.73\n",
            "[5167 | 2823.08] loss=2.35 avg=2.73\n",
            "[5168 | 2824.76] loss=2.99 avg=2.73\n",
            "[5169 | 2826.45] loss=2.88 avg=2.73\n",
            "[5170 | 2828.13] loss=2.88 avg=2.73\n",
            "[5171 | 2829.81] loss=2.54 avg=2.73\n",
            "[5172 | 2831.50] loss=2.75 avg=2.73\n",
            "[5173 | 2833.19] loss=2.70 avg=2.73\n",
            "[5174 | 2834.86] loss=3.38 avg=2.74\n",
            "[5175 | 2836.55] loss=2.58 avg=2.74\n",
            "[5176 | 2838.24] loss=2.35 avg=2.73\n",
            "[5177 | 2839.92] loss=2.67 avg=2.73\n",
            "[5178 | 2841.61] loss=2.69 avg=2.73\n",
            "[5179 | 2843.30] loss=2.70 avg=2.73\n",
            "[5180 | 2844.98] loss=2.52 avg=2.73\n",
            "[5181 | 2846.67] loss=2.46 avg=2.73\n",
            "[5182 | 2848.35] loss=2.79 avg=2.73\n",
            "[5183 | 2850.03] loss=2.58 avg=2.73\n",
            "[5184 | 2851.72] loss=2.72 avg=2.73\n",
            "[5185 | 2853.41] loss=3.00 avg=2.73\n",
            "[5186 | 2855.09] loss=2.21 avg=2.72\n",
            "[5187 | 2856.78] loss=2.38 avg=2.72\n",
            "[5188 | 2858.47] loss=2.83 avg=2.72\n",
            "[5189 | 2860.15] loss=2.66 avg=2.72\n",
            "[5190 | 2861.81] loss=2.78 avg=2.72\n",
            "[5191 | 2863.49] loss=2.92 avg=2.72\n",
            "[5192 | 2865.17] loss=2.60 avg=2.72\n",
            "[5193 | 2866.86] loss=2.89 avg=2.72\n",
            "[5194 | 2868.54] loss=2.40 avg=2.72\n",
            "[5195 | 2870.24] loss=2.25 avg=2.72\n",
            "[5196 | 2871.91] loss=2.72 avg=2.72\n",
            "[5197 | 2873.59] loss=2.55 avg=2.71\n",
            "[5198 | 2875.28] loss=2.57 avg=2.71\n",
            "[5199 | 2876.96] loss=2.82 avg=2.71\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " a great, brave, and gallant officer.\"\n",
            "\t\\@ Gwynne, Robert (1858–1955) The remains of Mr. Robert Gwynne, of New Castle, were removed from the Western District Hospital yesterday to Sydney.Deceased, who was in his 88th year, was well known in the Western District. He was known by members of the public as a well-liked and respected member of the town and region. Mr. Gwynne was well known in other districts in Australia. In the Western District, he was a member of the Western District Council for 18 years. He was a member of the Western District Council of the Northern Rivers. He was a director of the Gorton Mining Company and vice-president of the Western District Golf Club in New South Wales. He was a member of the Western District Council for about ten years, and in addition to being a member of the council held the office of Registrar of Chancery for a term of about 14 years. He was a generous gift of a few weeks' allowance. The funeral took place at the Western District Hospital yesterday at the hour appointed by the deceased's widow. The remains were interred in the Presbyterian portion of the Newtown Cemetery, and the funeral of the deceased took place in the Copley Cemetery.\n",
            "\t\\@ Halliday, John Aetherell (1857–1955) Mr. Halliday, an old resident of St. Vitus, R.I., died suddenly at home on Sunday, August 1. He was 78 years of age, and had lived there for about 40 years. He was a well-known member of the agricultural community, and was a member of the New Britain branch of the New Britain Sheepbreeders' Association. The funeral will be held in the Presbyterian portion of the Newtown Cemetery at 11 a.m. to-day, the Rev. A. D. Wilson officiating at the graveside. He was the only surviving son of Mr. and Mrs. C. J. Halliday, of St. Vitus, R.I., who came to the city about 40 years ago. He married Miss Alice Hodge in London about four-and-a-half years ago, and is a son of the late Rev. John Aetherell Hodge—a leading member of the Baptist congregation in St. Vitus. He leaves a widow and six children to mourn their loss. Among the many relatives who attended at the funeral were his brother-in-law, Dr. and Mrs. E. J. Hodge, and many members of the Baptist and pastoral societies. The late Mr. Halliday was a regular presence at the St. Vitus Railway Station, and in his capacity as a member of the church he regularly contributed to the Railway Trust Fund, which fund has for many years been held in trust for the use of the railway. He was also a leading player in the St. Vitus Tennis Club. He leaves a widow, four children, and three stepchildren, the sons of his wife and two sons of his sons.\n",
            "\t\\@ Tully, Charles Charles (?–1955) \n",
            "\tCharles Charles Tully, of Glenroy, N.S.W., who died suddenly, aged 66, on Sunday, September 30, was a son of the late Mr and Mrs Edward Campbell and grandson of Mr and Mrs George Laudan (Tuthill) Tully. For many years Mr. Tully's work was done by the family estate at Tuthill, N.S.W., and he was on Sunday married.\n",
            "\t\\@ O'Toole, John Anthony (1856–1955) The death occurred at his residence at Punt Street, North Melbourne, of Major John O'Toole, second son of the late Mr and Mrs John O'Toole at the early age of 16 years.The son was born at Wattledale, North Victoria, in 1856. Later he moved to Penrith where he became clerk to the Superintendent of Lands in Victoria.He was an accomplished cricketer, as well as being an officer of the Victoria Cricket Club, and was also for several years chairman of the Cricket Association of Australia. He was a member of the South Australia Cricket Association for many years.Mr. Seddon, a cousin of the late Mr. O'Toole, has informed the press that the late Mr. O'Toole was a splendid person. He leaves a widow and 3 daughters to mourn their loss.\n",
            "\t\\@ Campbell, John (1843–1955) One of the last remaining sons of one of the pioneers of this colony died on Friday, in the person of Mr. John Campbell. The deceased was born in Victoria about 1834, and was employed at Sydney for a period of four years. On leaving home for his motherland he went to his father's field at Nesbitt, where he lived until 1861,\n",
            "\n",
            "[5200 | 2900.91] loss=2.50 avg=2.71\n",
            "[5201 | 2902.60] loss=2.98 avg=2.71\n",
            "[5202 | 2904.28] loss=2.67 avg=2.71\n",
            "[5203 | 2905.95] loss=2.86 avg=2.72\n",
            "[5204 | 2907.64] loss=2.32 avg=2.71\n",
            "[5205 | 2909.32] loss=2.42 avg=2.71\n",
            "[5206 | 2911.00] loss=2.56 avg=2.71\n",
            "[5207 | 2912.69] loss=3.16 avg=2.71\n",
            "[5208 | 2914.37] loss=2.29 avg=2.71\n",
            "[5209 | 2916.05] loss=2.87 avg=2.71\n",
            "[5210 | 2917.73] loss=2.17 avg=2.70\n",
            "[5211 | 2919.41] loss=2.95 avg=2.71\n",
            "[5212 | 2921.10] loss=2.50 avg=2.70\n",
            "[5213 | 2922.78] loss=2.62 avg=2.70\n",
            "[5214 | 2924.46] loss=2.99 avg=2.71\n",
            "[5215 | 2926.14] loss=3.31 avg=2.71\n",
            "[5216 | 2927.82] loss=2.96 avg=2.71\n",
            "[5217 | 2929.50] loss=2.74 avg=2.72\n",
            "[5218 | 2931.18] loss=2.43 avg=2.71\n",
            "[5219 | 2932.86] loss=2.96 avg=2.71\n",
            "[5220 | 2934.55] loss=2.99 avg=2.72\n",
            "[5221 | 2936.22] loss=2.98 avg=2.72\n",
            "[5222 | 2937.91] loss=2.30 avg=2.72\n",
            "[5223 | 2939.59] loss=2.91 avg=2.72\n",
            "[5224 | 2941.27] loss=3.54 avg=2.73\n",
            "[5225 | 2942.96] loss=2.43 avg=2.72\n",
            "[5226 | 2944.65] loss=2.45 avg=2.72\n",
            "[5227 | 2946.34] loss=2.62 avg=2.72\n",
            "[5228 | 2948.03] loss=2.92 avg=2.72\n",
            "[5229 | 2949.72] loss=2.36 avg=2.72\n",
            "[5230 | 2951.41] loss=2.03 avg=2.71\n",
            "[5231 | 2953.11] loss=3.17 avg=2.72\n",
            "[5232 | 2954.79] loss=2.65 avg=2.71\n",
            "[5233 | 2956.48] loss=2.66 avg=2.71\n",
            "[5234 | 2958.18] loss=2.79 avg=2.71\n",
            "[5235 | 2959.86] loss=2.94 avg=2.72\n",
            "[5236 | 2961.56] loss=2.69 avg=2.72\n",
            "[5237 | 2963.24] loss=2.69 avg=2.72\n",
            "[5238 | 2964.94] loss=2.97 avg=2.72\n",
            "[5239 | 2966.63] loss=2.88 avg=2.72\n",
            "[5240 | 2968.32] loss=2.69 avg=2.72\n",
            "[5241 | 2970.01] loss=2.10 avg=2.71\n",
            "[5242 | 2971.71] loss=2.72 avg=2.71\n",
            "[5243 | 2973.40] loss=2.52 avg=2.71\n",
            "[5244 | 2975.10] loss=3.20 avg=2.72\n",
            "[5245 | 2976.80] loss=2.78 avg=2.72\n",
            "[5246 | 2978.50] loss=2.62 avg=2.72\n",
            "[5247 | 2980.20] loss=2.35 avg=2.71\n",
            "[5248 | 2981.89] loss=2.78 avg=2.71\n",
            "[5249 | 2983.58] loss=2.92 avg=2.72\n",
            "[5250 | 2985.28] loss=3.11 avg=2.72\n",
            "[5251 | 2986.98] loss=2.77 avg=2.72\n",
            "[5252 | 2988.68] loss=2.42 avg=2.72\n",
            "[5253 | 2990.38] loss=3.14 avg=2.72\n",
            "[5254 | 2992.08] loss=2.59 avg=2.72\n",
            "[5255 | 2993.77] loss=3.15 avg=2.72\n",
            "[5256 | 2995.47] loss=3.01 avg=2.73\n",
            "[5257 | 2997.17] loss=2.82 avg=2.73\n",
            "[5258 | 2998.87] loss=2.95 avg=2.73\n",
            "[5259 | 3000.58] loss=2.77 avg=2.73\n",
            "[5260 | 3002.28] loss=2.80 avg=2.73\n",
            "[5261 | 3003.98] loss=2.56 avg=2.73\n",
            "[5262 | 3005.68] loss=2.64 avg=2.73\n",
            "[5263 | 3007.38] loss=2.45 avg=2.73\n",
            "[5264 | 3009.09] loss=2.64 avg=2.73\n",
            "[5265 | 3010.78] loss=2.34 avg=2.72\n",
            "[5266 | 3012.49] loss=2.69 avg=2.72\n",
            "[5267 | 3014.19] loss=2.62 avg=2.72\n",
            "[5268 | 3015.89] loss=2.20 avg=2.72\n",
            "[5269 | 3017.59] loss=2.38 avg=2.71\n",
            "[5270 | 3019.29] loss=2.81 avg=2.71\n",
            "[5271 | 3020.99] loss=2.52 avg=2.71\n",
            "[5272 | 3022.70] loss=1.47 avg=2.70\n",
            "[5273 | 3024.39] loss=3.01 avg=2.70\n",
            "[5274 | 3026.09] loss=2.56 avg=2.70\n",
            "[5275 | 3027.80] loss=2.84 avg=2.70\n",
            "[5276 | 3029.51] loss=2.42 avg=2.70\n",
            "[5277 | 3031.21] loss=2.46 avg=2.70\n",
            "[5278 | 3032.91] loss=2.92 avg=2.70\n",
            "[5279 | 3034.61] loss=3.01 avg=2.70\n",
            "[5280 | 3036.31] loss=2.92 avg=2.70\n",
            "[5281 | 3038.02] loss=2.31 avg=2.70\n",
            "[5282 | 3039.72] loss=2.23 avg=2.70\n",
            "[5283 | 3041.42] loss=2.73 avg=2.70\n",
            "[5284 | 3043.13] loss=2.61 avg=2.69\n",
            "[5285 | 3044.82] loss=2.86 avg=2.70\n",
            "[5286 | 3046.52] loss=3.28 avg=2.70\n",
            "[5287 | 3048.24] loss=3.69 avg=2.71\n",
            "[5288 | 3049.93] loss=2.62 avg=2.71\n",
            "[5289 | 3051.64] loss=2.38 avg=2.71\n",
            "[5290 | 3053.34] loss=2.20 avg=2.70\n",
            "[5291 | 3055.04] loss=2.40 avg=2.70\n",
            "[5292 | 3056.74] loss=2.31 avg=2.70\n",
            "[5293 | 3058.44] loss=2.82 avg=2.70\n",
            "[5294 | 3060.15] loss=3.15 avg=2.70\n",
            "[5295 | 3061.85] loss=2.34 avg=2.70\n",
            "[5296 | 3063.55] loss=2.40 avg=2.70\n",
            "[5297 | 3065.25] loss=2.15 avg=2.69\n",
            "[5298 | 3066.95] loss=3.06 avg=2.69\n",
            "[5299 | 3068.65] loss=2.54 avg=2.69\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " Madden. His father, Mr. George M. Smith, was a magistrate in Sydney, and in his early days was a partner of the firm of H. Smith & Co. It was only when he joined the company of Mr. John W. Hulsey, the well-known solicitor in New South Wales, that the elder Smith found himself able to enter the commercial circles that are so often the home of great men, and this was the beginning of his famous career. As a solicitor the elder Smith took an active interest in all the pursuits of the firm, and the old lawyer often remarked that Mr. John Smith had the greatest knowledge of the legal profession in the state; for he had been in charge of the firm on several occasions, and had been chairman. Mr. John Smith's first business was that of a land speculator; but he also acquired a vast real estate, which he had in several cases sold with success. He married the sister of Mr. Arthur Young, and a few years afterwards he married Miss Emily Minton, of St Petersbury in Victoria, a daughter of the late Mr. E. Young, the lawyer and member of the Legislative Council. For many years Mr. Smith, at his own expense, brought up a large family; and during the last war he was a great and influential member of the Legislative Council. He was a favourite citizen in New South Wales, and after winning the sympathy of the community was frequently asked for by the press. He was a native of North Queensland and South Australia; and he was a son of the late Mr. J. S. Smith, who was one of the pioneer traders of that State. He was for many years a manager in New South Wales, and many years ago became a partner in the firm of the late Mr. J. W. Hulsey, the well-known solicitor, of New South Wales. For several years Mr. J. M. Smith was an elected member of the Legislative Council, the only member on that body being Mr. O. E. Hulsey, of New South Wales. His election took place on Monday last; the vote of the new committee was 7. It was one of the loudest demonstrations of sentiment known. After the meeting Mr. J. M. Smith was a large crowd of supporters gathered round him and clapped to show appreciation of that wonderful gesture; Mr. W. Hulsey, at one time Mr. J. M. Smith's only friend, after speaking to him of Mr. Smith and his great capacity was one of the most cordial and cordial of all men and ladies who have so long been associated with our State. The whole of our legislative body, and particularly those who are the members of the executive, are very well represented in New South Wales; the whole of the executive are members of the Legislative Council (except one), with the exception of the members who are in the executive, of which few are more experienced men than Mr. James H. Harris, of Queensland, and Mr. Charles Hulsey of New South Wales. Mr. J. M. Smith is a large and widely circulated figure in all quarters: a well-known man throughout New South Wales—even among his friends, and those who have known him, he will not take an easy way of the public. He was a minister in every state in Australia, and a member of the Legislative Assembly in New South Wales at all times. In addition to the usual number of representatives of the state in Parliament he had also an equal number of ministers, and had been a member for the last seven years, besides being a member of the Executive. He was a great supporter of the Australian Institute, and the only one in the Legislative Council who has been appointed chairman was Mr. Hulsey. Mr J. M. Smith in consequence of some temporary difficulties relating to his health had many years ago left New South Wales for England, where he resided there until about two years past years. His last visit to his old land was about a year ago, when, on account of the fact that the property that he had been for some years occupying had fallen into ruin he resolved to see his old residence again. He had never been out of England on business in any state, but he has been a great support to the local bodies which have been set up from time to time in similar places. He is very well received in England, being highly respected. He is a native of the district of New South Wales, and was born in the district on the 4th ult. His father's late profession was that of magistrate in Sydney for some years. He was married within a very short time of the marriage in 1872 between a Miss Evelyn Young, of Sydney, son of Mr. and Mrs. George Young, and daughter of Mr. and Mrs. J. Young. It is believed that the marriage took place on the same morning as the marriage between Mr. J. M. Smith and Miss Emily Minton in 1873.\n",
            "\tMr\n",
            "\n",
            "[5300 | 3092.80] loss=2.44 avg=2.69\n",
            "[5301 | 3094.47] loss=2.57 avg=2.69\n",
            "[5302 | 3096.15] loss=2.33 avg=2.68\n",
            "[5303 | 3097.82] loss=3.22 avg=2.69\n",
            "[5304 | 3099.48] loss=2.34 avg=2.69\n",
            "[5305 | 3101.15] loss=2.28 avg=2.68\n",
            "[5306 | 3102.81] loss=2.63 avg=2.68\n",
            "[5307 | 3104.48] loss=2.45 avg=2.68\n",
            "[5308 | 3106.14] loss=3.00 avg=2.68\n",
            "[5309 | 3107.80] loss=2.64 avg=2.68\n",
            "[5310 | 3109.48] loss=2.40 avg=2.68\n",
            "[5311 | 3111.14] loss=3.09 avg=2.68\n",
            "[5312 | 3112.82] loss=2.55 avg=2.68\n",
            "[5313 | 3114.49] loss=2.99 avg=2.69\n",
            "[5314 | 3116.17] loss=2.54 avg=2.68\n",
            "[5315 | 3117.85] loss=3.15 avg=2.69\n",
            "[5316 | 3119.53] loss=2.23 avg=2.68\n",
            "[5317 | 3121.22] loss=2.38 avg=2.68\n",
            "[5318 | 3122.90] loss=2.78 avg=2.68\n",
            "[5319 | 3124.59] loss=2.35 avg=2.68\n",
            "[5320 | 3126.27] loss=2.76 avg=2.68\n",
            "[5321 | 3127.96] loss=2.42 avg=2.68\n",
            "[5322 | 3129.67] loss=2.28 avg=2.67\n",
            "[5323 | 3131.37] loss=2.39 avg=2.67\n",
            "[5324 | 3133.07] loss=3.31 avg=2.68\n",
            "[5325 | 3134.78] loss=3.00 avg=2.68\n",
            "[5326 | 3136.48] loss=2.76 avg=2.68\n",
            "[5327 | 3138.18] loss=2.83 avg=2.68\n",
            "[5328 | 3139.89] loss=2.81 avg=2.68\n",
            "[5329 | 3141.59] loss=2.38 avg=2.68\n",
            "[5330 | 3143.30] loss=2.57 avg=2.68\n",
            "[5331 | 3145.01] loss=2.72 avg=2.68\n",
            "[5332 | 3146.71] loss=2.10 avg=2.67\n",
            "[5333 | 3148.41] loss=2.34 avg=2.67\n",
            "[5334 | 3150.11] loss=2.29 avg=2.67\n",
            "[5335 | 3151.81] loss=2.51 avg=2.66\n",
            "[5336 | 3153.51] loss=2.53 avg=2.66\n",
            "[5337 | 3155.21] loss=2.60 avg=2.66\n",
            "[5338 | 3156.91] loss=2.95 avg=2.67\n",
            "[5339 | 3158.61] loss=2.52 avg=2.66\n",
            "[5340 | 3160.32] loss=2.36 avg=2.66\n",
            "[5341 | 3162.01] loss=2.59 avg=2.66\n",
            "[5342 | 3163.72] loss=3.00 avg=2.66\n",
            "[5343 | 3165.41] loss=2.76 avg=2.66\n",
            "[5344 | 3167.11] loss=3.40 avg=2.67\n",
            "[5345 | 3168.80] loss=2.83 avg=2.67\n",
            "[5346 | 3170.50] loss=3.27 avg=2.68\n",
            "[5347 | 3172.19] loss=2.29 avg=2.68\n",
            "[5348 | 3173.87] loss=2.60 avg=2.67\n",
            "[5349 | 3175.55] loss=3.19 avg=2.68\n",
            "[5350 | 3177.23] loss=2.28 avg=2.68\n",
            "[5351 | 3178.92] loss=3.04 avg=2.68\n",
            "[5352 | 3180.60] loss=2.67 avg=2.68\n",
            "[5353 | 3182.28] loss=2.60 avg=2.68\n",
            "[5354 | 3183.97] loss=3.07 avg=2.68\n",
            "[5355 | 3185.65] loss=2.55 avg=2.68\n",
            "[5356 | 3187.33] loss=2.77 avg=2.68\n",
            "[5357 | 3189.01] loss=2.57 avg=2.68\n",
            "[5358 | 3190.69] loss=2.28 avg=2.68\n",
            "[5359 | 3192.38] loss=2.29 avg=2.67\n",
            "[5360 | 3194.07] loss=2.04 avg=2.67\n",
            "[5361 | 3195.75] loss=3.46 avg=2.67\n",
            "[5362 | 3197.44] loss=2.55 avg=2.67\n",
            "[5363 | 3199.12] loss=2.38 avg=2.67\n",
            "[5364 | 3200.81] loss=2.91 avg=2.67\n",
            "[5365 | 3202.50] loss=2.38 avg=2.67\n",
            "[5366 | 3204.20] loss=2.52 avg=2.67\n",
            "[5367 | 3205.89] loss=2.47 avg=2.67\n",
            "[5368 | 3207.58] loss=3.19 avg=2.67\n",
            "[5369 | 3209.28] loss=2.75 avg=2.67\n",
            "[5370 | 3210.98] loss=2.91 avg=2.68\n",
            "[5371 | 3212.68] loss=2.84 avg=2.68\n",
            "[5372 | 3214.38] loss=2.60 avg=2.68\n",
            "[5373 | 3216.08] loss=2.50 avg=2.67\n",
            "[5374 | 3217.78] loss=2.22 avg=2.67\n",
            "[5375 | 3219.46] loss=2.35 avg=2.67\n",
            "[5376 | 3221.15] loss=2.35 avg=2.66\n",
            "[5377 | 3222.85] loss=3.56 avg=2.67\n",
            "[5378 | 3224.56] loss=2.66 avg=2.67\n",
            "[5379 | 3226.26] loss=2.24 avg=2.67\n",
            "[5380 | 3227.96] loss=2.37 avg=2.66\n",
            "[5381 | 3229.66] loss=2.60 avg=2.66\n",
            "[5382 | 3231.36] loss=2.61 avg=2.66\n",
            "[5383 | 3233.07] loss=2.84 avg=2.67\n",
            "[5384 | 3234.76] loss=3.27 avg=2.67\n",
            "[5385 | 3236.46] loss=2.87 avg=2.67\n",
            "[5386 | 3238.20] loss=2.06 avg=2.67\n",
            "[5387 | 3239.90] loss=2.45 avg=2.67\n",
            "[5388 | 3241.61] loss=2.50 avg=2.66\n",
            "[5389 | 3243.31] loss=2.58 avg=2.66\n",
            "[5390 | 3245.01] loss=3.01 avg=2.67\n",
            "[5391 | 3246.72] loss=2.81 avg=2.67\n",
            "[5392 | 3248.41] loss=2.10 avg=2.66\n",
            "[5393 | 3250.12] loss=2.51 avg=2.66\n",
            "[5394 | 3251.83] loss=2.60 avg=2.66\n",
            "[5395 | 3253.52] loss=2.65 avg=2.66\n",
            "[5396 | 3255.23] loss=2.38 avg=2.66\n",
            "[5397 | 3256.93] loss=2.77 avg=2.66\n",
            "[5398 | 3258.62] loss=2.38 avg=2.66\n",
            "[5399 | 3260.33] loss=2.18 avg=2.65\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            ", in an open field, his eyes, which had been all too heavily bandaged, revealed their secret in a kind of dreamlike expression. As we entered the house, the dead and dying were being led away for burial. A few moments before death he opened his eyes again, and said: \"You see there it stands here.\" The dead were all buried to his memory, and we were all buried with him in the churchyard. On Thursday the day before his decease, on account of his heavy bandaged eyes, his death took place in the very churchyard where his body and those of his family had been put together by the priests, who were carrying him to his last rest and burial. The priest carried the body a distance of about three miles round the house, but he was a little disturbed by the dead body, and went about it some more, and afterwards carried it to the grave. Mr. Cattie, one of those who accompanied the unfortunate gentleman to the churchyard, said he was most kindly received by the priests while he was in the house; he was the only one who touched him once, and the other priests who came to visit were able to touch him with the rest of the brethren. Upon the arrival of the funeral procession to the churchyard Mr. Hodge, the secretary, carried out the funeral details, and after the funeral was over, Mr. Hodge left for the post office, in consequence of the great interest he had received before it was over; the funeral arrangements being made, a very large number of persons went to the post office to pay their last tribute of respect in this most friendly of ways. The funeral arrangements were somewhat different from those which have been formerly done, and it is now very unusual that a single clergyman has ever gone to the post office to pay his last tribute of respect on the dead person, so many of us, it seems, have gone to pay our last tribute of respect, not only to our kinsmen and relatives, but to the late Mr. Cottle, the only real friend to the deceased gentleman. When it is said that Mr. Cottle had a deep and affectionate and profound sympathy with him, which the public should feel, it is true that the deceased gentleman is as far from a stranger to him in the nature of the case as he would have been elsewhere. When Mr. Cottle first came out into the city some years ago, there was a man upon his father's estate, named S. B. Brown, who had a property on the old North Sydney Railway, which, with the new rail lines from the East, was becoming so much the more important. When the government undertook the necessary railway works across Queensland for the purpose of providing roads for a railway system in the Northern Territory, the railway companies for which this gentleman was now managing, were asked by the government for one or two thousand acres along the Northern Territory, of which the deceased gentleman had been elected a representative to the board of directors of one of the companies. But when this gentleman came to the Northern Territory, in view of the difficulties which were to confront the people of that northern Territory, who were to be found far and wide in the great majority of the Southern states, and where the population, as well as the land had not yet been thoroughly formed on the principle of the British rule, the question was then brought to the notice of the deceased gentleman, and he, in consultation with the other directors, advised the government to supply him with the territory on a very liberal basis, so that in case of war, the Northern Territory could then be given over to England. The deceased gentleman immediately replied, and said that he would only supply the Southern states on a moderate basis in order to save the life of his client. When it became an open topic, he said he would provide the Northern territories, so that we might continue to exist if we were allowed to exist; but at the same time he said that the Northern Territories would be ours only in case we were obliged by war, to submit to the English rule. But, as in the case of his colleague Sir George Ferguson, the Northern states now had very little to do with the administration of the Southern territories, so they must be controlled by English rule, to provide for the administration of the territory, and so enable the Southern monarchs to be satisfied with his authority as the Crown of Scotland. On reflection, he explained to the directors that he had not the slightest doubt that when the war broke out the Southern states would consent to the Government's handing over the Southern territories to England. On being asked to explain so far as to what he meant by \"handling the Southern states,\" he said that they should be brought to their former situation, and that at the same time be allowed to continue to exist, in so far that the Southern monarchs would be satisfied with his authority as the Crown of the State. Of the question of Southern states, he said he had the most serious doubts, and that it was a question\n",
            "\n",
            "[5400 | 3284.52] loss=2.86 avg=2.65\n",
            "[5401 | 3286.20] loss=2.23 avg=2.65\n",
            "[5402 | 3287.87] loss=2.41 avg=2.65\n",
            "[5403 | 3289.54] loss=2.70 avg=2.65\n",
            "[5404 | 3291.22] loss=2.65 avg=2.65\n",
            "[5405 | 3292.89] loss=2.30 avg=2.64\n",
            "[5406 | 3294.55] loss=2.23 avg=2.64\n",
            "[5407 | 3296.22] loss=2.60 avg=2.64\n",
            "[5408 | 3297.90] loss=3.21 avg=2.64\n",
            "[5409 | 3299.58] loss=3.10 avg=2.65\n",
            "[5410 | 3301.24] loss=2.43 avg=2.65\n",
            "[5411 | 3302.91] loss=2.52 avg=2.65\n",
            "[5412 | 3304.58] loss=3.09 avg=2.65\n",
            "[5413 | 3306.26] loss=2.43 avg=2.65\n",
            "[5414 | 3307.95] loss=2.83 avg=2.65\n",
            "[5415 | 3309.63] loss=2.67 avg=2.65\n",
            "[5416 | 3311.31] loss=2.68 avg=2.65\n",
            "[5417 | 3313.00] loss=2.38 avg=2.65\n",
            "[5418 | 3314.68] loss=2.77 avg=2.65\n",
            "[5419 | 3316.37] loss=3.15 avg=2.65\n",
            "[5420 | 3318.06] loss=3.03 avg=2.66\n",
            "[5421 | 3319.77] loss=2.86 avg=2.66\n",
            "[5422 | 3321.47] loss=2.32 avg=2.66\n",
            "[5423 | 3323.17] loss=2.15 avg=2.65\n",
            "[5424 | 3324.87] loss=2.61 avg=2.65\n",
            "[5425 | 3326.57] loss=2.36 avg=2.65\n",
            "[5426 | 3328.28] loss=2.96 avg=2.65\n",
            "[5427 | 3329.97] loss=1.94 avg=2.64\n",
            "[5428 | 3331.68] loss=2.52 avg=2.64\n",
            "[5429 | 3333.38] loss=3.18 avg=2.65\n",
            "[5430 | 3335.08] loss=2.95 avg=2.65\n",
            "[5431 | 3336.79] loss=2.99 avg=2.65\n",
            "[5432 | 3338.48] loss=2.49 avg=2.65\n",
            "[5433 | 3340.19] loss=3.04 avg=2.66\n",
            "[5434 | 3341.89] loss=2.87 avg=2.66\n",
            "[5435 | 3343.59] loss=2.61 avg=2.66\n",
            "[5436 | 3345.29] loss=2.43 avg=2.66\n",
            "[5437 | 3346.99] loss=2.41 avg=2.65\n",
            "[5438 | 3348.69] loss=2.75 avg=2.65\n",
            "[5439 | 3350.39] loss=2.61 avg=2.65\n",
            "[5440 | 3352.09] loss=2.94 avg=2.66\n",
            "[5441 | 3353.79] loss=2.98 avg=2.66\n",
            "[5442 | 3355.48] loss=2.65 avg=2.66\n",
            "[5443 | 3357.17] loss=2.49 avg=2.66\n",
            "[5444 | 3358.87] loss=2.74 avg=2.66\n",
            "[5445 | 3360.56] loss=2.40 avg=2.66\n",
            "[5446 | 3362.25] loss=2.33 avg=2.65\n",
            "[5447 | 3363.95] loss=2.57 avg=2.65\n",
            "[5448 | 3365.65] loss=3.17 avg=2.66\n",
            "[5449 | 3367.34] loss=3.01 avg=2.66\n",
            "[5450 | 3369.03] loss=2.60 avg=2.66\n",
            "[5451 | 3370.73] loss=2.28 avg=2.66\n",
            "[5452 | 3372.42] loss=2.67 avg=2.66\n",
            "[5453 | 3374.11] loss=2.32 avg=2.65\n",
            "[5454 | 3375.79] loss=2.67 avg=2.65\n",
            "[5455 | 3377.48] loss=2.81 avg=2.65\n",
            "[5456 | 3379.16] loss=3.27 avg=2.66\n",
            "[5457 | 3380.83] loss=2.46 avg=2.66\n",
            "[5458 | 3382.51] loss=2.47 avg=2.66\n",
            "[5459 | 3384.19] loss=3.01 avg=2.66\n",
            "[5460 | 3385.88] loss=2.61 avg=2.66\n",
            "[5461 | 3387.56] loss=2.69 avg=2.66\n",
            "[5462 | 3389.25] loss=2.69 avg=2.66\n",
            "[5463 | 3390.93] loss=2.80 avg=2.66\n",
            "[5464 | 3392.62] loss=2.09 avg=2.66\n",
            "[5465 | 3394.30] loss=2.40 avg=2.65\n",
            "[5466 | 3395.98] loss=2.52 avg=2.65\n",
            "[5467 | 3397.67] loss=2.03 avg=2.65\n",
            "[5468 | 3399.35] loss=2.72 avg=2.65\n",
            "[5469 | 3401.03] loss=2.59 avg=2.65\n",
            "[5470 | 3402.71] loss=2.60 avg=2.65\n",
            "[5471 | 3404.39] loss=2.55 avg=2.64\n",
            "[5472 | 3406.07] loss=2.42 avg=2.64\n",
            "[5473 | 3407.76] loss=2.73 avg=2.64\n",
            "[5474 | 3409.45] loss=2.55 avg=2.64\n",
            "[5475 | 3411.13] loss=2.67 avg=2.64\n",
            "[5476 | 3412.82] loss=3.20 avg=2.65\n",
            "[5477 | 3414.49] loss=2.14 avg=2.64\n",
            "[5478 | 3416.19] loss=2.58 avg=2.64\n",
            "[5479 | 3417.87] loss=3.26 avg=2.65\n",
            "[5480 | 3419.56] loss=3.06 avg=2.65\n",
            "[5481 | 3421.24] loss=2.51 avg=2.65\n",
            "[5482 | 3422.92] loss=2.93 avg=2.65\n",
            "[5483 | 3424.61] loss=2.26 avg=2.65\n",
            "[5484 | 3426.29] loss=2.35 avg=2.65\n",
            "[5485 | 3427.96] loss=2.90 avg=2.65\n",
            "[5486 | 3429.65] loss=2.89 avg=2.65\n",
            "[5487 | 3431.34] loss=2.93 avg=2.65\n",
            "[5488 | 3433.03] loss=2.78 avg=2.66\n",
            "[5489 | 3434.72] loss=2.40 avg=2.65\n",
            "[5490 | 3436.41] loss=2.83 avg=2.66\n",
            "[5491 | 3438.10] loss=2.74 avg=2.66\n",
            "[5492 | 3439.80] loss=1.96 avg=2.65\n",
            "[5493 | 3441.49] loss=2.82 avg=2.65\n",
            "[5494 | 3443.18] loss=2.53 avg=2.65\n",
            "[5495 | 3444.88] loss=2.81 avg=2.65\n",
            "[5496 | 3446.56] loss=3.04 avg=2.66\n",
            "[5497 | 3448.24] loss=2.67 avg=2.66\n",
            "[5498 | 3449.94] loss=2.47 avg=2.65\n",
            "[5499 | 3451.64] loss=2.23 avg=2.65\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " family. He served many years in the Legislative Assembly and served in the Legislature for South Yarra from 1930 to 1938.In 1938 he was re-elected in South Yarra, against the opposition of Dr George Whitehouse, the chief minister, but the Government decided to throw the seat out of order and voted for a by-election for the former constituency of North Yarra. In March 1941 Sir John had a stroke and died at the Royal Perth Hospital.Mr. Whitehouse, who was on his way to his last public appearance on Monday, was accompanied by Mr. John W. Hocking, secretary of the South Yarra branch of the ALP, and Mr. and Mrs. V. B. Whitehouse, of the Adelaide branch of the Communist Party.The funeral will take place to-day from the North Yarra cemetery at 2 p.m.<|endoftext|>After nearly three decades of living, working and living in London, I am finally happy to be able to report I am officially retiring from the private sector at 21st Century Fox.I became a director at the age of 27. I had a very successful and highly qualified career and enjoyed the freedom of a private position. I loved my work and wanted to continue it. However, I had to make tough decisions about a large and growing family. I decided to give up my private sector positions to give my four children a decent start in a family of five with my wife Ann and son Alex.The only thing I did not give up was the fact that I was a huge, passionate, passionate professional. I had an insatiable passion for my field and had a keen understanding and empathy for all levels of the business, from consultants to sales, from consultants to people with no business background. I always took my job very seriously and in a way that had the opposite effect as I hoped it would have.I think of myself as one of the great Australian public health professionals because that is what I have achieved, the ability to serve people where I know them best. I have gone to over 80 countries with a particular focus on public health, including Asia. I am very much attracted by what I hear from business people and they have some of the most positive, uplifting and positive public health stories I am told.My first experience of public health work was in Vietnam from 1968. I worked closely with the UN World Health organisation during the conflict during my final eight years with the organisation.I worked primarily with UN health agencies and I saw more than 150 countries. I saw the conflict and the health systems, the problems people faced along the way while trying to help people. It was an incredible work environment.My time in Vietnam saw me experience first-hand the consequences of the conflict. I saw how war can change people and change lives. In many ways, I felt a profound personal loss at the time, and I had to work a lot harder than I normally would have.As I saw the impacts, I became more and more concerned for people. I was very deeply involved in the Peace Corps. We have a history of a great relationship that runs through the development of our countries, whether it be the US Peace Corps, EU Peace Corps, Australia Peace Corps, CEPIC - the United Nations Peace Corps. I felt it was a good way to connect to the UN, especially at the time when everyone was so focused on other international bodies trying to find us.I became involved with the Australian Association of University Student Associations (AAUSSA) when they were developing Australia's international profile. The Australian Peace Corps is about a decade old, which I was involved with closely through Peace Corps as well as through UN peace agencies. It was not something I enjoyed going to the UN to join. It is a very old organisation, which is still very much in business.I have always liked to spend time in the back office or in the meeting rooms - meeting people, discussing and understanding, being a team player.I was part of some of the biggest public health projects in Europe. I spent time in the USA and South Africa and in some of the least developed countries. In South Africa, during the time we coordinated with the civil defence, I spent some time meeting some of the local people in the area with the UN peace corps. And in the USA we had meetings like the US Peace Corps Conference that was happening up at the time, so it was my time there.I was a co-chair of the first national conference on mental health in South Africa and an ex-chairwoman of the conference in Australia. I chaired many of the new conventions around health. In the US I worked in USA with the American Cancer Society, with the American Hospital Association, with the American Heart Association, with the American Academy of Family Physicians, the American Medical Association, the Australian Society of Neurological Surgeons - all of these were important areas of my work.I was a co-author of a whole range of papers in social sciences, such as social psychology, economics, evolutionary psychology, political philosophy and health. I co-\n",
            "\n",
            "[5500 | 3475.48] loss=2.27 avg=2.65\n",
            "[5501 | 3477.17] loss=2.63 avg=2.65\n",
            "[5502 | 3478.84] loss=2.64 avg=2.65\n",
            "[5503 | 3480.52] loss=3.04 avg=2.65\n",
            "[5504 | 3482.20] loss=2.79 avg=2.65\n",
            "[5505 | 3483.87] loss=2.97 avg=2.65\n",
            "[5506 | 3485.55] loss=2.48 avg=2.65\n",
            "[5507 | 3487.23] loss=3.25 avg=2.66\n",
            "[5508 | 3488.89] loss=2.95 avg=2.66\n",
            "[5509 | 3490.57] loss=2.29 avg=2.66\n",
            "[5510 | 3492.24] loss=2.82 avg=2.66\n",
            "[5511 | 3493.92] loss=2.50 avg=2.66\n",
            "[5512 | 3495.60] loss=2.52 avg=2.66\n",
            "[5513 | 3497.28] loss=3.07 avg=2.66\n",
            "[5514 | 3498.96] loss=2.84 avg=2.66\n",
            "[5515 | 3500.64] loss=3.11 avg=2.67\n",
            "[5516 | 3502.32] loss=3.09 avg=2.67\n",
            "[5517 | 3504.00] loss=2.61 avg=2.67\n",
            "[5518 | 3505.68] loss=3.18 avg=2.68\n",
            "[5519 | 3507.37] loss=2.59 avg=2.67\n",
            "[5520 | 3509.05] loss=2.85 avg=2.68\n",
            "[5521 | 3510.73] loss=2.19 avg=2.67\n",
            "[5522 | 3512.42] loss=2.46 avg=2.67\n",
            "[5523 | 3514.11] loss=2.98 avg=2.67\n",
            "[5524 | 3515.79] loss=2.76 avg=2.67\n",
            "[5525 | 3517.49] loss=2.59 avg=2.67\n",
            "[5526 | 3519.18] loss=3.03 avg=2.68\n",
            "[5527 | 3520.87] loss=3.06 avg=2.68\n",
            "[5528 | 3522.55] loss=2.64 avg=2.68\n",
            "[5529 | 3524.23] loss=2.79 avg=2.68\n",
            "[5530 | 3525.93] loss=2.38 avg=2.68\n",
            "[5531 | 3527.63] loss=2.28 avg=2.67\n",
            "[5532 | 3529.33] loss=2.77 avg=2.67\n",
            "[5533 | 3531.03] loss=2.60 avg=2.67\n",
            "[5534 | 3532.73] loss=2.88 avg=2.68\n",
            "[5535 | 3534.43] loss=2.81 avg=2.68\n",
            "[5536 | 3536.13] loss=2.96 avg=2.68\n",
            "[5537 | 3537.83] loss=3.01 avg=2.68\n",
            "[5538 | 3539.53] loss=2.60 avg=2.68\n",
            "[5539 | 3541.24] loss=2.47 avg=2.68\n",
            "[5540 | 3542.94] loss=3.39 avg=2.69\n",
            "[5541 | 3544.64] loss=2.47 avg=2.69\n",
            "[5542 | 3546.34] loss=2.82 avg=2.69\n",
            "[5543 | 3548.04] loss=3.11 avg=2.69\n",
            "[5544 | 3549.74] loss=2.28 avg=2.69\n",
            "[5545 | 3551.45] loss=2.52 avg=2.68\n",
            "[5546 | 3553.15] loss=2.43 avg=2.68\n",
            "[5547 | 3554.85] loss=2.66 avg=2.68\n",
            "[5548 | 3556.56] loss=3.38 avg=2.69\n",
            "[5549 | 3558.25] loss=2.79 avg=2.69\n",
            "[5550 | 3559.96] loss=3.09 avg=2.69\n",
            "[5551 | 3561.66] loss=2.69 avg=2.69\n",
            "[5552 | 3563.36] loss=2.09 avg=2.69\n",
            "[5553 | 3565.06] loss=2.85 avg=2.69\n",
            "[5554 | 3566.76] loss=3.03 avg=2.69\n",
            "[5555 | 3568.46] loss=2.32 avg=2.69\n",
            "[5556 | 3570.16] loss=2.35 avg=2.69\n",
            "[5557 | 3571.86] loss=2.99 avg=2.69\n",
            "[5558 | 3573.56] loss=2.27 avg=2.68\n",
            "[5559 | 3575.26] loss=3.41 avg=2.69\n",
            "[5560 | 3576.96] loss=2.87 avg=2.69\n",
            "[5561 | 3578.65] loss=2.56 avg=2.69\n",
            "[5562 | 3580.35] loss=2.99 avg=2.70\n",
            "[5563 | 3582.05] loss=2.67 avg=2.69\n",
            "[5564 | 3583.75] loss=2.39 avg=2.69\n",
            "[5565 | 3585.46] loss=2.18 avg=2.69\n",
            "[5566 | 3587.15] loss=2.59 avg=2.69\n",
            "[5567 | 3588.84] loss=2.75 avg=2.69\n",
            "[5568 | 3590.55] loss=2.79 avg=2.69\n",
            "[5569 | 3592.25] loss=2.60 avg=2.69\n",
            "[5570 | 3593.95] loss=2.66 avg=2.69\n",
            "[5571 | 3595.66] loss=2.49 avg=2.68\n",
            "[5572 | 3597.35] loss=2.82 avg=2.69\n",
            "[5573 | 3599.05] loss=2.17 avg=2.68\n",
            "[5574 | 3600.76] loss=3.00 avg=2.68\n",
            "[5575 | 3602.46] loss=2.18 avg=2.68\n",
            "[5576 | 3604.16] loss=3.76 avg=2.69\n",
            "[5577 | 3605.86] loss=3.22 avg=2.69\n",
            "[5578 | 3607.56] loss=2.75 avg=2.70\n",
            "[5579 | 3609.26] loss=3.11 avg=2.70\n",
            "[5580 | 3610.96] loss=2.30 avg=2.70\n",
            "[5581 | 3612.66] loss=2.44 avg=2.69\n",
            "[5582 | 3614.36] loss=2.66 avg=2.69\n",
            "[5583 | 3616.06] loss=2.65 avg=2.69\n",
            "[5584 | 3617.74] loss=2.40 avg=2.69\n",
            "[5585 | 3619.44] loss=3.14 avg=2.69\n",
            "[5586 | 3621.15] loss=2.57 avg=2.69\n",
            "[5587 | 3622.85] loss=2.70 avg=2.69\n",
            "[5588 | 3624.55] loss=2.68 avg=2.69\n",
            "[5589 | 3626.25] loss=2.37 avg=2.69\n",
            "[5590 | 3627.95] loss=2.79 avg=2.69\n",
            "[5591 | 3629.66] loss=2.86 avg=2.69\n",
            "[5592 | 3631.36] loss=2.46 avg=2.69\n",
            "[5593 | 3633.06] loss=2.27 avg=2.69\n",
            "[5594 | 3634.76] loss=2.71 avg=2.69\n",
            "[5595 | 3636.46] loss=3.30 avg=2.69\n",
            "[5596 | 3638.16] loss=2.17 avg=2.69\n",
            "[5597 | 3639.87] loss=2.47 avg=2.68\n",
            "[5598 | 3641.57] loss=2.51 avg=2.68\n",
            "[5599 | 3643.27] loss=2.48 avg=2.68\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " time. Mrs. J. B. Jodie was Mrs. H. M. McBride's widow. Another sister, Mrs. J. L. Jodie, of the family of the late Mr. William Jodie, of Kinchelagh; one brother, Mr. F. J. M. Jodie, of Narreroe; and one sister, Mrs. W. R. D'Aurelio, of St. Stephen's Church, Wollongong, are also relatives of the deceased.\n",
            "\t\\@ Margetts, William (1834–1894) The well-known South Head residents have received information of the death of William Margetts, whose death at the advanced age of 81 years removed a prominent figure in the district. The late Mr. Margetts was born in Edinburgh in the year 1836, his father being the late Mr. Alexander Margetts, a native of Scotland, but coming to Australia on a voyage for England to obtain a commercial position. About 1858 he came to Tasmania, and took up his residence in the village of Port Douglas, South Head, where he resided for about 35 years up to the time of his death. At the time of the passing over to the land of his forefathers, Mr. Margetts was engaged as proprietor of Laddock and Sturt, but for many years he used to travel about the district, and the late Mr. Margetts, who was a member of the original Laddock and Sturt Railway Companies, was known as one of the best-known railwaymen in the district. When the Laddock Railway was formed, it was of the opinion of the government—that it was unnecessary to increase the number of roads so as to ensure sufficient service for the whole district so as to provide sufficient room for all and the various needs of the people, and the government did in fact proceed in this direction, and in consequence of the increase of population and the development of the railway the Laddock railway service has been greatly increased. The Margetts Railway Company was formed, and when the town of Port Douglas was included under the railway, the late Mr. Margetts took charge of the management of it, he remaining in that position until his death. The late Mr. Margetts was a brother of Mr. William I. Horsley Margetts, M.P, a nephew of Mr. James Horsley, whose widow, Ann Horsley, is a sister.\n",
            "\t\\@ MacGregor, Charles R. (1828–1894) An account of the death of Charles R. (Jack) MacGregor, relict of the late Andrew MacGregor, is published in Mr. F. Wilson's \"A.N.Z.E.\", p. 15, as follows:–On Sunday afternoon last he was removed to the Goulburn Hospital where he was operated for severe headache. On Monday he was given some rest for a few hours and received some relief on Sunday evening. But, during that time the doctors and nurses found that he was in a very critical state, until the ninth hour of he was put on a life-support machine. On Monday afternoon he was taken home and on the following morning a large crowd attended the funeral, which had its usual dimensions. Most of the mourners, being of high rank and distinction, bore the marks of a great deal of public attention, while a great part of those present also took a deep personal interest, and were very numerous as witnesses who witnessed the close of a personal and long-lived life.The corpse was conveyed to the Goulburn Cemetery, where the remains of two of the four original members of the family, the late Mrs. MacGregor (Dame Mary MacGregor), and Mrs. [John] MacGregor, were laid to rest beside those of their parents who have for the last seventeen years been the members of this family. The funeral cortege was made up from the City to the Laddock Cemetery, and it will leave the City some time to-morrow.\n",
            "\t\\@ Dorey, Robert (1849–1894) \n",
            "\t\\@ Coote, John Thomas (Bob) (1859–1894) \n",
            "\tMr. Coote, the late William M. Coote, died in New Zealand on Saturday, at the age of 78 years.\n",
            "\tMr. Coote had been ailing for some time, and had been an active worker for an industry in the southern-most section of the country.\n",
            "\tHe married a niece, who is a daughter of the late Mr. F. W. Gee. He spent his life in an industry of the highest possible character, and a very high standard, and he greatly contributed to the welfare of the community in which he resided.\n",
            "\tMr. Coote had an ardent affection for his native land\n",
            "\n",
            "[5600 | 3667.30] loss=2.58 avg=2.68\n",
            "[5601 | 3668.97] loss=2.70 avg=2.68\n",
            "[5602 | 3670.65] loss=2.33 avg=2.68\n",
            "[5603 | 3672.32] loss=2.30 avg=2.67\n",
            "[5604 | 3673.99] loss=3.55 avg=2.68\n",
            "[5605 | 3675.66] loss=3.12 avg=2.69\n",
            "[5606 | 3677.34] loss=2.88 avg=2.69\n",
            "[5607 | 3679.00] loss=2.76 avg=2.69\n",
            "[5608 | 3680.68] loss=3.32 avg=2.70\n",
            "[5609 | 3682.35] loss=2.99 avg=2.70\n",
            "[5610 | 3684.02] loss=2.66 avg=2.70\n",
            "[5611 | 3685.69] loss=2.56 avg=2.70\n",
            "[5612 | 3687.37] loss=2.96 avg=2.70\n",
            "[5613 | 3689.05] loss=2.56 avg=2.70\n",
            "[5614 | 3690.73] loss=2.39 avg=2.69\n",
            "[5615 | 3692.41] loss=2.32 avg=2.69\n",
            "[5616 | 3694.09] loss=2.55 avg=2.69\n",
            "[5617 | 3695.77] loss=3.00 avg=2.69\n",
            "[5618 | 3697.46] loss=2.34 avg=2.69\n",
            "[5619 | 3699.14] loss=3.00 avg=2.69\n",
            "[5620 | 3700.83] loss=2.33 avg=2.69\n",
            "[5621 | 3702.52] loss=2.43 avg=2.69\n",
            "[5622 | 3704.22] loss=2.42 avg=2.68\n",
            "[5623 | 3705.92] loss=2.94 avg=2.69\n",
            "[5624 | 3707.62] loss=2.84 avg=2.69\n",
            "[5625 | 3709.31] loss=2.77 avg=2.69\n",
            "[5626 | 3711.02] loss=3.12 avg=2.69\n",
            "[5627 | 3712.70] loss=2.43 avg=2.69\n",
            "[5628 | 3714.41] loss=2.30 avg=2.69\n",
            "[5629 | 3716.10] loss=2.49 avg=2.68\n",
            "[5630 | 3717.80] loss=2.76 avg=2.68\n",
            "[5631 | 3719.51] loss=2.71 avg=2.68\n",
            "[5632 | 3721.21] loss=2.74 avg=2.69\n",
            "[5633 | 3722.91] loss=2.38 avg=2.68\n",
            "[5634 | 3724.61] loss=3.15 avg=2.69\n",
            "[5635 | 3726.32] loss=2.70 avg=2.69\n",
            "[5636 | 3728.02] loss=2.49 avg=2.69\n",
            "[5637 | 3729.72] loss=2.62 avg=2.68\n",
            "[5638 | 3731.42] loss=2.90 avg=2.69\n",
            "[5639 | 3733.12] loss=2.62 avg=2.69\n",
            "[5640 | 3734.82] loss=3.59 avg=2.69\n",
            "[5641 | 3736.52] loss=3.11 avg=2.70\n",
            "[5642 | 3738.22] loss=2.45 avg=2.70\n",
            "[5643 | 3739.92] loss=2.03 avg=2.69\n",
            "[5644 | 3741.62] loss=3.18 avg=2.69\n",
            "[5645 | 3743.31] loss=3.01 avg=2.70\n",
            "[5646 | 3745.01] loss=2.75 avg=2.70\n",
            "[5647 | 3746.71] loss=2.65 avg=2.70\n",
            "[5648 | 3748.41] loss=2.26 avg=2.69\n",
            "[5649 | 3750.11] loss=2.17 avg=2.69\n",
            "[5650 | 3751.80] loss=3.09 avg=2.69\n",
            "[5651 | 3753.49] loss=2.41 avg=2.69\n",
            "[5652 | 3755.19] loss=2.29 avg=2.69\n",
            "[5653 | 3756.89] loss=2.37 avg=2.68\n",
            "[5654 | 3758.59] loss=2.38 avg=2.68\n",
            "[5655 | 3760.29] loss=2.74 avg=2.68\n",
            "[5656 | 3761.99] loss=2.24 avg=2.68\n",
            "[5657 | 3763.68] loss=2.79 avg=2.68\n",
            "[5658 | 3765.37] loss=2.59 avg=2.68\n",
            "[5659 | 3767.06] loss=2.49 avg=2.67\n",
            "[5660 | 3768.77] loss=2.21 avg=2.67\n",
            "[5661 | 3770.46] loss=3.34 avg=2.68\n",
            "[5662 | 3772.14] loss=2.54 avg=2.67\n",
            "[5663 | 3773.83] loss=2.31 avg=2.67\n",
            "[5664 | 3775.53] loss=2.37 avg=2.67\n",
            "[5665 | 3777.21] loss=2.83 avg=2.67\n",
            "[5666 | 3778.91] loss=2.64 avg=2.67\n",
            "[5667 | 3780.60] loss=3.21 avg=2.67\n",
            "[5668 | 3782.28] loss=2.81 avg=2.68\n",
            "[5669 | 3783.97] loss=2.66 avg=2.68\n",
            "[5670 | 3785.65] loss=3.15 avg=2.68\n",
            "[5671 | 3787.33] loss=2.44 avg=2.68\n",
            "[5672 | 3789.01] loss=2.61 avg=2.68\n",
            "[5673 | 3790.70] loss=2.51 avg=2.68\n",
            "[5674 | 3792.38] loss=2.59 avg=2.68\n",
            "[5675 | 3794.07] loss=2.34 avg=2.67\n",
            "[5676 | 3795.76] loss=2.89 avg=2.67\n",
            "[5677 | 3797.44] loss=3.41 avg=2.68\n",
            "[5678 | 3799.12] loss=2.70 avg=2.68\n",
            "[5679 | 3800.81] loss=3.19 avg=2.69\n",
            "[5680 | 3802.48] loss=2.33 avg=2.68\n",
            "[5681 | 3804.17] loss=2.79 avg=2.68\n",
            "[5682 | 3805.85] loss=2.15 avg=2.68\n",
            "[5683 | 3807.53] loss=2.42 avg=2.68\n",
            "[5684 | 3809.21] loss=3.00 avg=2.68\n",
            "[5685 | 3810.89] loss=2.56 avg=2.68\n",
            "[5686 | 3812.58] loss=3.29 avg=2.68\n",
            "[5687 | 3814.26] loss=2.56 avg=2.68\n",
            "[5688 | 3815.94] loss=2.74 avg=2.68\n",
            "[5689 | 3817.62] loss=2.44 avg=2.68\n",
            "[5690 | 3819.30] loss=2.37 avg=2.68\n",
            "[5691 | 3820.99] loss=2.50 avg=2.68\n",
            "[5692 | 3822.67] loss=2.70 avg=2.68\n",
            "[5693 | 3824.35] loss=2.55 avg=2.68\n",
            "[5694 | 3826.04] loss=2.40 avg=2.67\n",
            "[5695 | 3827.73] loss=2.69 avg=2.67\n",
            "[5696 | 3829.41] loss=2.94 avg=2.68\n",
            "[5697 | 3831.10] loss=3.05 avg=2.68\n",
            "[5698 | 3832.78] loss=2.32 avg=2.68\n",
            "[5699 | 3834.47] loss=2.49 avg=2.67\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " ago about two years ago it came out, and it was not long before other gentlemen were taking interest. That gentleman, the late Mr. J. S. Moseley, a Mr. L. J. Gurney, and three years ago the late Mr. H. R. Lister. In about a year or two a young lady by her marriage was born. In September last, at the instigation of some gentlemen of Edinburgh, she was brought to Tasmania by a friend, and within four years from the time she became a widow has been maintaining eight children, six of whom have attained to her age, she having married several years ago. She was very fond of a horse called Cushman, which she rode very successfully, and then, when that died, Cushman's friends took it. She has not left her home, and has not missed the opportunity, which is now, of giving up. She is a very kind individual, not only in her social and family relations with the natives, but also with the visitors from Tasmania, her letters having been received very favourably. It was due to the benevolent advice given of Ms Moseley by her husband, that Cushman was made into a \"horse of honour.\"\n",
            "\t\\@ Coughlan, Joseph Ernest (1868–1946) \n",
            "\tThe death occurred in the London Hospital of Mr, Joseph Ernest Coughlan, which occurred, as it was for many months, in isolation. Mr. Coughlan, who was well-known locally for many years, was an old resident of the Hawkesbury region. He left in 1918 for Sydney, to live there for a time, as he believed that in England he was doing the best he could for the cause of liberty. His last illness occurred soon after his arrival in Sydney, which was in September, 1940. There have been few men in this part of the world who have been as kind and generous as Mr. Coughlan. He was a member of the Hawkesbury Valley Board, the local branch of the London School of Economics. He was a native of this part of the colony, and was a brother of Mrs. T. M. Coughlan, of Mount Dennis, and Mr. J. E. Coughlan.\n",
            "\tMr. Coughlan had a house at Blyth-street, which he had bought with part of his wife's property, at a large discount, when the latter had just come out from England. Mr. Coughlan married his second wife, Miss R. A. Wilson, of Taringa station, and came out to the Hawkesbury in 1928. About 50 years ago he was married, with his first wife, to Miss G. L. H. Coughlan, and they had one son, Messrs. E. R. Coughlan and W. E. Coughlan. They had five daughters—Mrs. C. S. Phelan, Mrs. Macpherson, Misses T. E. and D. J. Coughlan, Misses G. L. Murchie, Mary C, and Mrs. J. W. Coughlan.\n",
            "\t\\@ Codditch, George Frederick William (1910–1946) Mr. George Frederick William (Fred) Codditch, formerly of Burlingame, died last week at an early age and at his bedside yesterday morning was remembered as a good old-fashioned gentleman to all who knew him. He was born at Port Macquarie as the eldest of three sons of Mrs. H. L. Codditch, of Prahran, and was educated at Burlingame.His mother died in 1919, leaving only the remains of the four surviving brothers. The rest of the family lived in a country home in the Macquarie River. He began work with his brother George in 1894, and was the third son. He was a fine rider, and with his own two hands could outrun any man in one-two-two, and was also a fine cook. In 1905, when he went to work at the Nambucca Estate, to which he was attached, he took a well-known horse for the clientele, and with the horse in his hand proved a most reliable companion and handy colleague. He won the New Zealand Cup with the Coughlins, then he won again for his own horse and won again on the Nambucca estate, a champion in the south of Australia, the great favourites in New Zealand, and a great favourite in England. The Nambucca horse won him a place at the Canterbury Masters and then a place in the English Equiture. He was a good judge on every horse, and always was ready to go for a horse he thought did something for him. He rode the famous Wimmera in the Wellington Cup that was to come. For a long time he was the official representative of Burmahurst-\n",
            "\n",
            "[5700 | 3858.42] loss=2.85 avg=2.68\n",
            "[5701 | 3860.11] loss=2.87 avg=2.68\n",
            "[5702 | 3861.79] loss=2.56 avg=2.68\n",
            "[5703 | 3863.47] loss=2.47 avg=2.67\n",
            "[5704 | 3865.14] loss=3.02 avg=2.68\n",
            "[5705 | 3866.82] loss=2.59 avg=2.68\n",
            "[5706 | 3868.48] loss=2.25 avg=2.67\n",
            "[5707 | 3870.16] loss=2.87 avg=2.67\n",
            "[5708 | 3871.83] loss=2.23 avg=2.67\n",
            "[5709 | 3873.50] loss=2.34 avg=2.67\n",
            "[5710 | 3875.17] loss=2.94 avg=2.67\n",
            "[5711 | 3876.85] loss=2.47 avg=2.67\n",
            "[5712 | 3878.53] loss=2.82 avg=2.67\n",
            "[5713 | 3880.21] loss=2.42 avg=2.67\n",
            "[5714 | 3881.89] loss=2.57 avg=2.67\n",
            "[5715 | 3883.57] loss=2.31 avg=2.66\n",
            "[5716 | 3885.25] loss=2.75 avg=2.66\n",
            "[5717 | 3886.93] loss=2.16 avg=2.66\n",
            "[5718 | 3888.61] loss=3.09 avg=2.66\n",
            "[5719 | 3890.30] loss=3.26 avg=2.67\n",
            "[5720 | 3891.99] loss=3.06 avg=2.67\n",
            "[5721 | 3893.68] loss=3.16 avg=2.68\n",
            "[5722 | 3895.38] loss=2.21 avg=2.67\n",
            "[5723 | 3897.08] loss=3.10 avg=2.68\n",
            "[5724 | 3898.79] loss=2.52 avg=2.68\n",
            "[5725 | 3900.49] loss=2.68 avg=2.68\n",
            "[5726 | 3902.19] loss=2.96 avg=2.68\n",
            "[5727 | 3903.89] loss=2.89 avg=2.68\n",
            "[5728 | 3905.59] loss=3.25 avg=2.69\n",
            "[5729 | 3907.29] loss=2.90 avg=2.69\n",
            "[5730 | 3909.00] loss=2.49 avg=2.69\n",
            "[5731 | 3910.70] loss=2.83 avg=2.69\n",
            "[5732 | 3912.40] loss=2.85 avg=2.69\n",
            "[5733 | 3914.10] loss=2.57 avg=2.69\n",
            "[5734 | 3915.80] loss=2.72 avg=2.69\n",
            "[5735 | 3917.50] loss=2.59 avg=2.69\n",
            "[5736 | 3919.21] loss=3.31 avg=2.69\n",
            "[5737 | 3920.91] loss=2.62 avg=2.69\n",
            "[5738 | 3922.61] loss=2.58 avg=2.69\n",
            "[5739 | 3924.31] loss=3.54 avg=2.70\n",
            "[5740 | 3926.01] loss=2.89 avg=2.70\n",
            "[5741 | 3927.70] loss=2.46 avg=2.70\n",
            "[5742 | 3929.39] loss=2.21 avg=2.69\n",
            "[5743 | 3931.10] loss=2.75 avg=2.70\n",
            "[5744 | 3932.79] loss=2.71 avg=2.70\n",
            "[5745 | 3934.50] loss=2.61 avg=2.69\n",
            "[5746 | 3936.20] loss=2.96 avg=2.70\n",
            "[5747 | 3937.90] loss=2.87 avg=2.70\n",
            "[5748 | 3939.59] loss=2.47 avg=2.70\n",
            "[5749 | 3941.28] loss=2.23 avg=2.69\n",
            "[5750 | 3942.97] loss=3.04 avg=2.70\n",
            "[5751 | 3944.66] loss=2.56 avg=2.69\n",
            "[5752 | 3946.35] loss=2.60 avg=2.69\n",
            "[5753 | 3948.05] loss=2.36 avg=2.69\n",
            "[5754 | 3949.74] loss=3.03 avg=2.69\n",
            "[5755 | 3951.43] loss=2.27 avg=2.69\n",
            "[5756 | 3953.13] loss=2.34 avg=2.69\n",
            "[5757 | 3954.82] loss=2.48 avg=2.68\n",
            "[5758 | 3956.51] loss=2.67 avg=2.68\n",
            "[5759 | 3958.20] loss=2.67 avg=2.68\n",
            "[5760 | 3959.90] loss=2.63 avg=2.68\n",
            "[5761 | 3961.58] loss=2.53 avg=2.68\n",
            "[5762 | 3963.28] loss=2.56 avg=2.68\n",
            "[5763 | 3964.97] loss=2.28 avg=2.68\n",
            "[5764 | 3966.66] loss=2.57 avg=2.67\n",
            "[5765 | 3968.35] loss=2.61 avg=2.67\n",
            "[5766 | 3970.03] loss=3.04 avg=2.68\n",
            "[5767 | 3971.71] loss=2.48 avg=2.68\n",
            "[5768 | 3973.39] loss=3.00 avg=2.68\n",
            "[5769 | 3975.07] loss=2.47 avg=2.68\n",
            "[5770 | 3976.75] loss=2.36 avg=2.67\n",
            "[5771 | 3978.44] loss=2.86 avg=2.68\n",
            "[5772 | 3980.13] loss=2.96 avg=2.68\n",
            "[5773 | 3981.81] loss=3.13 avg=2.68\n",
            "[5774 | 3983.49] loss=2.85 avg=2.68\n",
            "[5775 | 3985.18] loss=2.99 avg=2.69\n",
            "[5776 | 3986.86] loss=3.01 avg=2.69\n",
            "[5777 | 3988.55] loss=2.62 avg=2.69\n",
            "[5778 | 3990.23] loss=3.03 avg=2.69\n",
            "[5779 | 3991.92] loss=2.44 avg=2.69\n",
            "[5780 | 3993.60] loss=2.29 avg=2.69\n",
            "[5781 | 3995.28] loss=2.91 avg=2.69\n",
            "[5782 | 3996.97] loss=2.12 avg=2.68\n",
            "[5783 | 3998.65] loss=2.66 avg=2.68\n",
            "[5784 | 4000.33] loss=3.10 avg=2.69\n",
            "[5785 | 4002.01] loss=3.00 avg=2.69\n",
            "[5786 | 4003.69] loss=2.35 avg=2.69\n",
            "[5787 | 4005.38] loss=3.03 avg=2.69\n",
            "[5788 | 4007.06] loss=2.93 avg=2.69\n",
            "[5789 | 4008.74] loss=2.68 avg=2.69\n",
            "[5790 | 4010.42] loss=2.97 avg=2.70\n",
            "[5791 | 4012.11] loss=3.09 avg=2.70\n",
            "[5792 | 4013.79] loss=2.66 avg=2.70\n",
            "[5793 | 4015.48] loss=2.70 avg=2.70\n",
            "[5794 | 4017.16] loss=2.42 avg=2.70\n",
            "[5795 | 4018.85] loss=2.28 avg=2.69\n",
            "[5796 | 4020.54] loss=2.64 avg=2.69\n",
            "[5797 | 4022.23] loss=2.91 avg=2.69\n",
            "[5798 | 4023.91] loss=2.34 avg=2.69\n",
            "[5799 | 4025.60] loss=2.82 avg=2.69\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " education of the children by education, education, education and by education.\"\n",
            "\n",
            "\n",
            "The school also opened the \"Oral Exam School\" for the students, at which the teacher, a German girl named Jan König, took part. It is thought that this may be where the secret to its success will be found, although no record of König's life remains; König was killed by the mob who attacked her and the school. König was born in a well-to-do home in S. Königsburg and grew up in a house where her father worked as a butcher. When she went to study business in Zurich, she learnt first-hand that the working life in the German-speaking world was extremely hard and that the rich had to work so hard that they had no one to work with. Then she heard some stories of the poor women going to their homes and complaining about their jobs. König went on business with her father and family but was forced to work in the stockyards. That worked out so she came to London, where she worked in various factories and was finally forced to retire as chief executive of London and Australia. This was in 1925 – the year when World War I broke out in Europe. König had travelled overseas extensively to study history, history and sociology at Trinity College and had worked at the London School of Economics. She was also a keen student of French. She was a member of the Committee of Women of World War I (CWHI), Trinity College Cambridge, a C.B.E., a C.G.E., and a C.M.E. After a spell in Paris, she went to study for the Civil Service Examination at a French university under professor A. R. S. Levesque during the war. This was at a time when the men at the back of the examination had been sent to concentration camps.König also served on the advisory committee of Ladies' High School, Cambridge. She visited Australia and France during the war. At the end of the war, she returned to London and, though she had been a life member of CWHI and the committee of the Women's Institute, the Ministry of War Industry was preparing a bill to create a Department and office for war veterans.König wanted to continue her studies in Europe, but with the help of friend Lillie Smith, she made up her mind to go abroad for a year, including time in France. When she returned, they decided to return to Ireland. There, König was to receive a diploma in the History of Art Department of Royal Ulster College. She made a remarkable recovery from her illness, but suffered further setbacks. In 1925, she came out of her two-year hospitalisation, joined the family and married Henry, a barrister, a former lecturer in law at the London School of Economics. Henry and his wife left Ireland for Britain in 1929 following the depression.König returned to London in February and studied a history of the war. She was very enthusiastic about her research and had started the first exhibition at Trinity College, Cambridge, in 1934. Her work at Trinity College was not recognised in later years until a series of exhibitions of work at different institutions was held in Britain. She was also the author of a number of articles for the Illustrated London News.In 1930, König was offered the position of secretary of the Labour Party and, with her father, was given responsibility for running the party's propaganda, which was held at a local branch. She was the only woman to have served as secretary in the war's Great Depression days. She then returned to France after the war and was one of the first women to attend a meeting of the National Federation of Women's Clubs of Britain in London in 1930. She later founded the Association of French Women's Working Slaves and helped it to develop into a branch.König's life changed radically in 1939 when she was arrested by the Gestapo on the railway line to the Berlin concentration camps. Her father and mother managed to escape with her but König's mother and brother died. She travelled extensively throughout Europe and Australia to get documents to prove her father was in Nazi-occupied France.König also lived in Melbourne, was educated at the Melbourne Girls' College and worked at the Australian Institute of Mining at Canberra for a time. She also took a long time to learn French and was an expert linguist. She was a keen student and scholar. König married Henry in 1936. At the time of her death, Henry had two sons – Max and Paul – and the family did not continue their education. Her two sons were all educated at other institutions.\"As we look back at a time when the only women in the World War I era (the great depression) who were allowed to serve in the military did so from the Home Guard, we can be sure that women found jobs and went on to have successful careers throughout life as well as helping raise families and raise their\n",
            "\n",
            "[5800 | 4049.61] loss=2.31 avg=2.69\n",
            "[5801 | 4051.29] loss=2.55 avg=2.69\n",
            "[5802 | 4052.98] loss=2.40 avg=2.68\n",
            "[5803 | 4054.66] loss=3.00 avg=2.69\n",
            "[5804 | 4056.34] loss=2.42 avg=2.68\n",
            "[5805 | 4058.02] loss=2.72 avg=2.68\n",
            "[5806 | 4059.70] loss=2.68 avg=2.68\n",
            "[5807 | 4061.36] loss=2.74 avg=2.69\n",
            "[5808 | 4063.04] loss=2.81 avg=2.69\n",
            "[5809 | 4064.73] loss=3.02 avg=2.69\n",
            "[5810 | 4066.40] loss=2.22 avg=2.68\n",
            "[5811 | 4068.07] loss=2.47 avg=2.68\n",
            "[5812 | 4069.75] loss=2.42 avg=2.68\n",
            "[5813 | 4071.43] loss=2.23 avg=2.68\n",
            "[5814 | 4073.11] loss=2.93 avg=2.68\n",
            "[5815 | 4074.80] loss=2.34 avg=2.67\n",
            "[5816 | 4076.48] loss=2.67 avg=2.67\n",
            "[5817 | 4078.16] loss=2.99 avg=2.68\n",
            "[5818 | 4079.84] loss=2.41 avg=2.68\n",
            "[5819 | 4081.53] loss=2.58 avg=2.67\n",
            "[5820 | 4083.21] loss=2.35 avg=2.67\n",
            "[5821 | 4084.90] loss=2.55 avg=2.67\n",
            "[5822 | 4086.59] loss=2.38 avg=2.67\n",
            "[5823 | 4088.27] loss=3.17 avg=2.67\n",
            "[5824 | 4089.96] loss=2.81 avg=2.67\n",
            "[5825 | 4091.64] loss=2.17 avg=2.67\n",
            "[5826 | 4093.33] loss=2.59 avg=2.67\n",
            "[5827 | 4095.03] loss=2.68 avg=2.67\n",
            "[5828 | 4096.73] loss=2.97 avg=2.67\n",
            "[5829 | 4098.41] loss=2.34 avg=2.67\n",
            "[5830 | 4100.10] loss=2.75 avg=2.67\n",
            "[5831 | 4101.79] loss=2.36 avg=2.67\n",
            "[5832 | 4103.50] loss=2.62 avg=2.66\n",
            "[5833 | 4105.20] loss=2.48 avg=2.66\n",
            "[5834 | 4106.90] loss=2.89 avg=2.67\n",
            "[5835 | 4108.60] loss=3.09 avg=2.67\n",
            "[5836 | 4110.30] loss=2.44 avg=2.67\n",
            "[5837 | 4112.00] loss=3.05 avg=2.67\n",
            "[5838 | 4113.70] loss=2.67 avg=2.67\n",
            "[5839 | 4115.41] loss=2.71 avg=2.67\n",
            "[5840 | 4117.11] loss=2.64 avg=2.67\n",
            "[5841 | 4118.81] loss=2.61 avg=2.67\n",
            "[5842 | 4120.51] loss=2.42 avg=2.67\n",
            "[5843 | 4122.22] loss=2.72 avg=2.67\n",
            "[5844 | 4123.92] loss=2.74 avg=2.67\n",
            "[5845 | 4125.63] loss=2.77 avg=2.67\n",
            "[5846 | 4127.31] loss=2.70 avg=2.67\n",
            "[5847 | 4129.01] loss=2.76 avg=2.67\n",
            "[5848 | 4130.71] loss=3.24 avg=2.68\n",
            "[5849 | 4132.41] loss=2.26 avg=2.67\n",
            "[5850 | 4134.12] loss=2.67 avg=2.67\n",
            "[5851 | 4135.82] loss=2.18 avg=2.67\n",
            "[5852 | 4137.52] loss=2.04 avg=2.66\n",
            "[5853 | 4139.22] loss=2.64 avg=2.66\n",
            "[5854 | 4140.92] loss=2.51 avg=2.66\n",
            "[5855 | 4142.62] loss=2.38 avg=2.66\n",
            "[5856 | 4144.32] loss=2.52 avg=2.66\n",
            "[5857 | 4146.02] loss=3.38 avg=2.66\n",
            "[5858 | 4147.72] loss=2.26 avg=2.66\n",
            "[5859 | 4149.42] loss=3.01 avg=2.66\n",
            "[5860 | 4151.12] loss=2.25 avg=2.66\n",
            "[5861 | 4152.82] loss=2.71 avg=2.66\n",
            "[5862 | 4154.52] loss=2.90 avg=2.66\n",
            "[5863 | 4156.23] loss=2.99 avg=2.66\n",
            "[5864 | 4157.93] loss=2.00 avg=2.66\n",
            "[5865 | 4159.63] loss=2.75 avg=2.66\n",
            "[5866 | 4161.33] loss=2.77 avg=2.66\n",
            "[5867 | 4163.03] loss=2.63 avg=2.66\n",
            "[5868 | 4164.73] loss=2.36 avg=2.66\n",
            "[5869 | 4166.43] loss=3.08 avg=2.66\n",
            "[5870 | 4168.13] loss=3.17 avg=2.67\n",
            "[5871 | 4169.83] loss=2.58 avg=2.67\n",
            "[5872 | 4171.53] loss=2.67 avg=2.67\n",
            "[5873 | 4173.23] loss=2.97 avg=2.67\n",
            "[5874 | 4174.92] loss=3.03 avg=2.67\n",
            "[5875 | 4176.62] loss=2.60 avg=2.67\n",
            "[5876 | 4178.32] loss=3.08 avg=2.68\n",
            "[5877 | 4180.02] loss=2.70 avg=2.68\n",
            "[5878 | 4181.73] loss=2.79 avg=2.68\n",
            "[5879 | 4183.42] loss=2.76 avg=2.68\n",
            "[5880 | 4185.12] loss=2.24 avg=2.67\n",
            "[5881 | 4186.83] loss=2.90 avg=2.68\n",
            "[5882 | 4188.53] loss=2.54 avg=2.67\n",
            "[5883 | 4190.22] loss=2.50 avg=2.67\n",
            "[5884 | 4191.92] loss=2.62 avg=2.67\n",
            "[5885 | 4193.62] loss=2.86 avg=2.67\n",
            "[5886 | 4195.32] loss=2.33 avg=2.67\n",
            "[5887 | 4197.02] loss=2.68 avg=2.67\n",
            "[5888 | 4198.72] loss=2.83 avg=2.67\n",
            "[5889 | 4200.42] loss=3.42 avg=2.68\n",
            "[5890 | 4202.13] loss=2.72 avg=2.68\n",
            "[5891 | 4203.82] loss=2.41 avg=2.68\n",
            "[5892 | 4205.52] loss=2.96 avg=2.68\n",
            "[5893 | 4207.22] loss=2.73 avg=2.68\n",
            "[5894 | 4208.93] loss=2.33 avg=2.68\n",
            "[5895 | 4210.62] loss=2.64 avg=2.68\n",
            "[5896 | 4212.33] loss=2.85 avg=2.68\n",
            "[5897 | 4214.03] loss=2.51 avg=2.68\n",
            "[5898 | 4215.73] loss=3.08 avg=2.68\n",
            "[5899 | 4217.43] loss=1.51 avg=2.67\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " by the fact of his imprisonment. Dr. Cunneen, when Mr. Farrar informed him that he was going with him to his aunt's, said:—\"Oh, I believe you got into prison for such a long time, Mr. Farrar. Can't the Doctor give you the best medical advice you can get?\" \"No, no. Can't I?\" \"Oh, absolutely,\" said Mr. Farrar, and added: \"Can't you please come to me?\" He had promised his friends that he would, and they promised to him that they would. There was a great deal of waiting waiting on him. He was to come back, after he was at an open-air tea party in Mr. Farrar's garden; and a lot of his friends would be going over to see him. As a result of Dr. Cunneen's advice he was to get in very well in the morning before the departure, and when he came out from his tea party he was so well dressed that it was not often possible for him to be seen anywhere anywhere. He was to be in no better shape, that morning, than he had been in just after tea, when he was in an agony for two or three days. The fact was so fortunate, Mr. Farrar assured himself, that they could both be out of the agony on the same morning of the next. They had all been there, all of them, and it was not a week since Mr. Farrar had been in agony. He would have been back on Friday morning last, a week previously. However, as it was not necessary for him, it must be admitted that it was difficult; and there was something of a chance that he might have been out in an hour or so, and not returned for several days. Dr. Cunneen, at one time, was of opinion that Dr. Farrar's last illness should have been a severe one. Mr Farrar, for the last six weeks, as well as for many weeks before, had been in a very severe state of recovery, and Dr. Cunneen regarded this as a sign that his death was almost in prospect. He knew very well that if Mr. Farrar had been allowed to go he would have been dead about six weeks ago at the advanced age of 82 years and 10 months. \"I told my mother to put my head under the pillow in the flat, and to shut the door behind me; and my head was under the pillow, and I could hear her whispering to me,\" said Mr. Farrar, in a very profound way. The circumstances of this illness are very different from those that so often accompany old age, and he was not a very good nurse, as he was. He told a very different story of it than most doctors, and the patient made him promise that he would never be more than an honest man. Mr. Farrar's aunt did everything in her power for him, and if they ever got him in and were in a state to keep him alive, she would have done her utmost. In this way she was very much in the way of Mr. Farrar's friends, who would send him on his way to get him when he could be helped by others, when the old man was in an awful state of sickness. However, they did not, and, as a matter of fact, the same could not be said of the doctor. They sent him on his way as a friend only, and there is no telling what was the result of this, for he had been in the state of such great pain that doctors could not help to cure him. As it is, the patient is dead, and he will be missed very much by his friends, and by his relatives. By Dr. Cunneen's opinion it is very likely that he came home in a fit, which is supposed to be one reason he was not there when the young doctor was in a fit. Mr. Farrar was a very clever, well-educated man, and he knew all the most delicate of medical knowledge, and was, perhaps, of the first of the nurses to come to hospital. Before Mr. Farrar went to hospital it was understood that he would be a very useful nurse; and that the nurse of the time had been Mrs. Moulton (of Dingle). Mrs. Moulton was very well, and she knew him very well. She knew him almost from the moment he came into hospital, and she was able to take into consideration all the needs. Mrs. Farrar was as kind as Mrs. Farrart was. She would take good care of Mr. Farrar, and would come back to his hospital room each night, in a very friendly voice. Mrs. Farrart had not a bad time of it before she came to hospital, and so far as Mrs. Farrar was concerned it was one good\n",
            "\n",
            "[5900 | 4241.37] loss=3.27 avg=2.67\n",
            "[5901 | 4243.04] loss=2.97 avg=2.68\n",
            "[5902 | 4244.71] loss=2.79 avg=2.68\n",
            "[5903 | 4246.39] loss=2.35 avg=2.68\n",
            "[5904 | 4248.05] loss=2.40 avg=2.67\n",
            "[5905 | 4249.71] loss=2.54 avg=2.67\n",
            "[5906 | 4251.39] loss=3.26 avg=2.68\n",
            "[5907 | 4253.05] loss=2.85 avg=2.68\n",
            "[5908 | 4254.72] loss=2.31 avg=2.68\n",
            "[5909 | 4256.40] loss=2.68 avg=2.68\n",
            "[5910 | 4258.06] loss=2.70 avg=2.68\n",
            "[5911 | 4259.74] loss=2.50 avg=2.67\n",
            "[5912 | 4261.41] loss=2.71 avg=2.67\n",
            "[5913 | 4263.09] loss=2.57 avg=2.67\n",
            "[5914 | 4264.77] loss=2.99 avg=2.68\n",
            "[5915 | 4266.45] loss=2.78 avg=2.68\n",
            "[5916 | 4268.14] loss=2.44 avg=2.68\n",
            "[5917 | 4269.82] loss=2.81 avg=2.68\n",
            "[5918 | 4271.52] loss=3.14 avg=2.68\n",
            "[5919 | 4273.22] loss=2.78 avg=2.68\n",
            "[5920 | 4274.91] loss=1.92 avg=2.67\n",
            "[5921 | 4276.60] loss=2.31 avg=2.67\n",
            "[5922 | 4278.30] loss=2.28 avg=2.67\n",
            "[5923 | 4280.00] loss=2.68 avg=2.67\n",
            "[5924 | 4281.70] loss=2.65 avg=2.67\n",
            "[5925 | 4283.39] loss=2.32 avg=2.66\n",
            "[5926 | 4285.09] loss=2.68 avg=2.66\n",
            "[5927 | 4286.80] loss=2.29 avg=2.66\n",
            "[5928 | 4288.50] loss=2.99 avg=2.66\n",
            "[5929 | 4290.20] loss=2.88 avg=2.67\n",
            "[5930 | 4291.90] loss=3.16 avg=2.67\n",
            "[5931 | 4293.60] loss=2.46 avg=2.67\n",
            "[5932 | 4295.30] loss=3.03 avg=2.67\n",
            "[5933 | 4297.00] loss=2.90 avg=2.67\n",
            "[5934 | 4298.70] loss=2.82 avg=2.68\n",
            "[5935 | 4300.40] loss=2.73 avg=2.68\n",
            "[5936 | 4302.10] loss=2.30 avg=2.67\n",
            "[5937 | 4303.81] loss=2.99 avg=2.68\n",
            "[5938 | 4305.50] loss=2.19 avg=2.67\n",
            "[5939 | 4307.19] loss=2.78 avg=2.67\n",
            "[5940 | 4308.89] loss=2.79 avg=2.67\n",
            "[5941 | 4310.59] loss=2.35 avg=2.67\n",
            "[5942 | 4312.28] loss=2.40 avg=2.67\n",
            "[5943 | 4313.97] loss=3.02 avg=2.67\n",
            "[5944 | 4315.66] loss=2.37 avg=2.67\n",
            "[5945 | 4317.35] loss=2.44 avg=2.67\n",
            "[5946 | 4319.03] loss=2.05 avg=2.66\n",
            "[5947 | 4320.71] loss=2.59 avg=2.66\n",
            "[5948 | 4322.39] loss=3.06 avg=2.66\n",
            "[5949 | 4324.07] loss=2.36 avg=2.66\n",
            "[5950 | 4325.75] loss=3.00 avg=2.66\n",
            "[5951 | 4327.44] loss=2.84 avg=2.66\n",
            "[5952 | 4329.12] loss=3.22 avg=2.67\n",
            "[5953 | 4330.80] loss=2.60 avg=2.67\n",
            "[5954 | 4332.49] loss=2.03 avg=2.66\n",
            "[5955 | 4334.16] loss=2.77 avg=2.66\n",
            "[5956 | 4335.85] loss=2.94 avg=2.67\n",
            "[5957 | 4337.53] loss=2.94 avg=2.67\n",
            "[5958 | 4339.21] loss=2.93 avg=2.67\n",
            "[5959 | 4340.89] loss=2.88 avg=2.67\n",
            "[5960 | 4342.58] loss=2.50 avg=2.67\n",
            "[5961 | 4344.26] loss=2.76 avg=2.67\n",
            "[5962 | 4345.95] loss=2.74 avg=2.67\n",
            "[5963 | 4347.64] loss=2.36 avg=2.67\n",
            "[5964 | 4349.33] loss=2.46 avg=2.67\n",
            "[5965 | 4351.03] loss=2.16 avg=2.66\n",
            "[5966 | 4352.72] loss=2.38 avg=2.66\n",
            "[5967 | 4354.41] loss=2.96 avg=2.66\n",
            "[5968 | 4356.09] loss=2.84 avg=2.67\n",
            "[5969 | 4357.78] loss=2.70 avg=2.67\n",
            "[5970 | 4359.47] loss=2.97 avg=2.67\n",
            "[5971 | 4361.16] loss=2.05 avg=2.66\n",
            "[5972 | 4362.86] loss=1.87 avg=2.66\n",
            "[5973 | 4364.55] loss=3.02 avg=2.66\n",
            "[5974 | 4366.25] loss=2.35 avg=2.66\n",
            "[5975 | 4367.95] loss=2.49 avg=2.65\n",
            "[5976 | 4369.65] loss=3.16 avg=2.66\n",
            "[5977 | 4371.33] loss=2.02 avg=2.65\n",
            "[5978 | 4373.03] loss=2.18 avg=2.65\n",
            "[5979 | 4374.72] loss=2.72 avg=2.65\n",
            "[5980 | 4376.42] loss=2.14 avg=2.64\n",
            "[5981 | 4378.12] loss=3.11 avg=2.65\n",
            "[5982 | 4379.82] loss=2.75 avg=2.65\n",
            "[5983 | 4381.52] loss=2.77 avg=2.65\n",
            "[5984 | 4383.22] loss=2.58 avg=2.65\n",
            "[5985 | 4384.92] loss=2.98 avg=2.65\n",
            "[5986 | 4386.63] loss=2.73 avg=2.65\n",
            "[5987 | 4388.32] loss=2.61 avg=2.65\n",
            "[5988 | 4390.03] loss=2.74 avg=2.65\n",
            "[5989 | 4391.73] loss=2.46 avg=2.65\n",
            "[5990 | 4393.43] loss=3.14 avg=2.66\n",
            "[5991 | 4395.14] loss=2.39 avg=2.65\n",
            "[5992 | 4396.81] loss=2.68 avg=2.65\n",
            "[5993 | 4398.50] loss=2.34 avg=2.65\n",
            "[5994 | 4400.21] loss=2.28 avg=2.65\n",
            "[5995 | 4401.91] loss=2.58 avg=2.65\n",
            "[5996 | 4403.61] loss=2.76 avg=2.65\n",
            "[5997 | 4405.31] loss=3.41 avg=2.66\n",
            "[5998 | 4407.01] loss=2.72 avg=2.66\n",
            "[5999 | 4408.71] loss=2.73 avg=2.66\n",
            "Saving checkpoint/run1/model-6000\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " Robertson also, the brother of Mr. B.A. S. (Broken Hill), and the wife of Mr. Thomas W. St. Clair, who, while serving in the French army, was killed in action near Paris, August 15, 1864. This family was mentioned by the late Sir Walter Scott in describing the late Mr. Robert Chalk (of South Sydney Town and Country Hospital, who was killed in the Rising of August, 1852), of whom Sir Walter Scott also said (in The Story of the Life of the Present Prime Minister Sir Robert Chalk) that \"he knew nothing of that important event, nor did he know the deceased soldier—who had been shot in Boston and who had come to New South Wales under the name of \"Alderman Halsell\"—lived at all.\"\n",
            "\t\\@ Cunynghame, John (1833–1895) \n",
            "�Mr. John Cunynghame, one of the oldest residents of the township of Caddie on the River, died at his residence on Wednesday (October 10) from asylums fever, after a short illness, some four months and several years ago.\n",
            "\tHe was born at Litchfield and was a son of the late Mr. and Mrs. George Cunynghame, who came to this part of Victoria with their two sons at the time of the first settlement of the district near the mouth of the River. About 1825 Mr. and Mrs. Cunynghame acquired the property now called Caddie, near a well-known water-course on the Wimmera; it has since been taken up by them. At the time of the latter's death he was engaged in pastoral pursuits, but his pastoral pursuits were discontinued about 40 years of life. He was a prominent business man, especially for a time proprietor of the Wimmera Hotel, and held the position of solicitor in the City of Melbourne. His sons owned considerable tracts of property along the Wagga line.\n",
            "\tMr. John Cunynghame left the late father half a century ago, and came to Caddie, taking up the family estate. The deceased, in his youth, was a great gambler, and with his family was seen round most of the famous places. At the age of 15 he and his father took up land at Lake Wimmera, where John took up grazing property, and in his later years was a heavy-bodied rider. The late Mr. Cunynghame married the widow of Mr. John Macarthur, who died some years ago. He also married Elizabeth (nee Worsley), daughter of the late Mr. and Mrs. W. Wardle, late of Woorundah Station. Mrs. Cunynghame leaves a family of three sons and four daughters—four, Messrs. E. C. Cunynghame, of the New Zealand Bank of Commerce; J. C. Cunynghame, of Cairns; T., and A. Cunynghame, of the firm of Cinque Ports. The second son died about 12 months ago.\n",
            "\t\\@ Loughnan, Mary Ann (1840–1895) \n",
            "\tA sad affair has occurred upon the North West Coast, at Burwood, where the death occurred. A lady in her 80th year, Mrs. Mary Ann Loughnan, of Burwood, died suddenly from influenza on Sunday afternoon. The deceased lady was taken from her residence on the Aitbrook Railway by two horses and taken to the Burwood to be cared for by Dr. Wren, who was called from Sydney to assist. As the patient was now at a great extent of pain, Dr. Loughnan took to her bed, and the deceased lady, who was suffering from influenza, passed away with the death of a lady who had been a beloved and respected resident of the district for several years.\n",
            "\t\\@ Dangar, Margaret (1831–1895) \n",
            "\tMRS. MARY ANDERSON and Mrs. Thomas Dangar, of the Bank of Australasia branch of the firm of Lewis (1796) and Dangar (1813) died at home on Sunday. The following are the particulars of the incident: There had been some slight recurrence of trouble in the home of the deceased's father, and after a consultation with Dr. Thomas De Gras, he concluded to go to the city, and on the following morning arrived at the place of his choosing, on the road to Goulburn. Leaving at the appointed spot, he passed a short time in the neighbourhood, before going to the East Highway. There in the following circumstances have been connected: — Mr. Thomas Dangar, whose father was the founder of the late Sir James Dangar, was a man of very great ability in business matters, and was successful with a wide range of clients, but was\n",
            "\n",
            "[6000 | 4443.64] loss=2.89 avg=2.66\n",
            "[6001 | 4445.39] loss=2.34 avg=2.66\n",
            "[6002 | 4447.15] loss=2.44 avg=2.65\n",
            "[6003 | 4448.90] loss=2.65 avg=2.65\n",
            "[6004 | 4450.65] loss=2.01 avg=2.65\n",
            "[6005 | 4452.38] loss=2.44 avg=2.65\n",
            "[6006 | 4454.12] loss=3.19 avg=2.65\n",
            "[6007 | 4455.83] loss=2.47 avg=2.65\n",
            "[6008 | 4457.54] loss=2.77 avg=2.65\n",
            "[6009 | 4459.24] loss=2.76 avg=2.65\n",
            "[6010 | 4460.93] loss=2.95 avg=2.65\n",
            "[6011 | 4462.63] loss=3.32 avg=2.66\n",
            "[6012 | 4464.32] loss=2.63 avg=2.66\n",
            "[6013 | 4466.00] loss=2.73 avg=2.66\n",
            "[6014 | 4467.67] loss=2.69 avg=2.66\n",
            "[6015 | 4469.35] loss=2.20 avg=2.66\n",
            "[6016 | 4471.02] loss=3.64 avg=2.67\n",
            "[6017 | 4472.69] loss=2.64 avg=2.67\n",
            "[6018 | 4474.35] loss=2.53 avg=2.67\n",
            "[6019 | 4476.01] loss=2.21 avg=2.66\n",
            "[6020 | 4477.68] loss=2.91 avg=2.66\n",
            "[6021 | 4479.34] loss=3.09 avg=2.67\n",
            "[6022 | 4481.00] loss=2.59 avg=2.67\n",
            "[6023 | 4482.66] loss=3.22 avg=2.67\n",
            "[6024 | 4484.31] loss=2.61 avg=2.67\n",
            "[6025 | 4485.98] loss=2.55 avg=2.67\n",
            "[6026 | 4487.64] loss=2.97 avg=2.67\n",
            "[6027 | 4489.31] loss=2.50 avg=2.67\n",
            "[6028 | 4490.97] loss=3.06 avg=2.68\n",
            "[6029 | 4492.63] loss=2.84 avg=2.68\n",
            "[6030 | 4494.31] loss=3.21 avg=2.68\n",
            "[6031 | 4495.97] loss=2.04 avg=2.68\n",
            "[6032 | 4497.65] loss=3.43 avg=2.68\n",
            "[6033 | 4499.33] loss=2.85 avg=2.69\n",
            "[6034 | 4501.00] loss=2.81 avg=2.69\n",
            "[6035 | 4502.68] loss=2.48 avg=2.68\n",
            "[6036 | 4504.36] loss=3.12 avg=2.69\n",
            "[6037 | 4506.05] loss=2.63 avg=2.69\n",
            "[6038 | 4507.75] loss=2.73 avg=2.69\n",
            "[6039 | 4509.44] loss=2.36 avg=2.69\n",
            "[6040 | 4511.12] loss=3.37 avg=2.69\n",
            "[6041 | 4512.82] loss=2.40 avg=2.69\n",
            "[6042 | 4514.52] loss=2.27 avg=2.69\n",
            "[6043 | 4516.23] loss=2.15 avg=2.68\n",
            "[6044 | 4517.92] loss=2.54 avg=2.68\n",
            "[6045 | 4519.63] loss=2.29 avg=2.67\n",
            "[6046 | 4521.33] loss=3.16 avg=2.68\n",
            "[6047 | 4523.04] loss=2.55 avg=2.68\n",
            "[6048 | 4524.74] loss=2.25 avg=2.67\n",
            "[6049 | 4526.45] loss=2.19 avg=2.67\n",
            "[6050 | 4528.14] loss=2.73 avg=2.67\n",
            "[6051 | 4529.85] loss=2.57 avg=2.67\n",
            "[6052 | 4531.55] loss=2.59 avg=2.67\n",
            "[6053 | 4533.25] loss=2.89 avg=2.67\n",
            "[6054 | 4534.95] loss=3.05 avg=2.67\n",
            "[6055 | 4536.65] loss=2.73 avg=2.67\n",
            "[6056 | 4538.35] loss=2.64 avg=2.67\n",
            "[6057 | 4540.06] loss=2.55 avg=2.67\n",
            "[6058 | 4541.75] loss=3.22 avg=2.68\n",
            "[6059 | 4543.44] loss=3.43 avg=2.69\n",
            "[6060 | 4545.14] loss=2.59 avg=2.69\n",
            "[6061 | 4546.84] loss=3.01 avg=2.69\n",
            "[6062 | 4548.53] loss=2.34 avg=2.68\n",
            "[6063 | 4550.24] loss=2.93 avg=2.69\n",
            "[6064 | 4551.94] loss=2.21 avg=2.68\n",
            "[6065 | 4553.64] loss=2.50 avg=2.68\n",
            "[6066 | 4555.34] loss=2.41 avg=2.68\n",
            "[6067 | 4557.04] loss=2.95 avg=2.68\n",
            "[6068 | 4558.75] loss=2.49 avg=2.68\n",
            "[6069 | 4560.45] loss=2.61 avg=2.68\n",
            "[6070 | 4562.15] loss=2.81 avg=2.68\n",
            "[6071 | 4563.85] loss=3.58 avg=2.69\n",
            "[6072 | 4565.55] loss=2.82 avg=2.69\n",
            "[6073 | 4567.26] loss=2.30 avg=2.69\n",
            "[6074 | 4568.95] loss=2.51 avg=2.68\n",
            "[6075 | 4570.65] loss=2.42 avg=2.68\n",
            "[6076 | 4572.36] loss=2.62 avg=2.68\n",
            "[6077 | 4574.06] loss=3.03 avg=2.68\n",
            "[6078 | 4575.76] loss=2.11 avg=2.68\n",
            "[6079 | 4577.46] loss=2.11 avg=2.67\n",
            "[6080 | 4579.16] loss=2.44 avg=2.67\n",
            "[6081 | 4580.86] loss=2.66 avg=2.67\n",
            "[6082 | 4582.57] loss=2.74 avg=2.67\n",
            "[6083 | 4584.26] loss=2.48 avg=2.67\n",
            "[6084 | 4585.97] loss=2.39 avg=2.67\n",
            "[6085 | 4587.67] loss=3.04 avg=2.67\n",
            "[6086 | 4589.37] loss=2.48 avg=2.67\n",
            "[6087 | 4591.07] loss=2.55 avg=2.67\n",
            "[6088 | 4592.76] loss=2.67 avg=2.67\n",
            "[6089 | 4594.45] loss=2.29 avg=2.66\n",
            "[6090 | 4596.16] loss=3.08 avg=2.67\n",
            "[6091 | 4597.86] loss=3.38 avg=2.67\n",
            "[6092 | 4599.57] loss=2.57 avg=2.67\n",
            "[6093 | 4601.26] loss=2.88 avg=2.68\n",
            "[6094 | 4602.97] loss=2.97 avg=2.68\n",
            "[6095 | 4604.67] loss=2.96 avg=2.68\n",
            "[6096 | 4606.37] loss=2.79 avg=2.68\n",
            "[6097 | 4608.08] loss=2.45 avg=2.68\n",
            "[6098 | 4609.77] loss=2.65 avg=2.68\n",
            "[6099 | 4611.48] loss=3.12 avg=2.68\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " the house.\n",
            "\t\\@ Hall, William (1911–1967) \n",
            "\tWhen the time came to pay a final tribute to his service to Sydney, the late Mr. William Hall was there to receive his diploma at Sydney Grammar School.\n",
            "\tAfter his initial two years of secondary education he went on to complete a diploma in sociology and went to England to take his degree with Diploma and Diploma in Sociology with the University of London.\n",
            "\tHe studied at the University of London and at the Melbourne Business School, finishing at the University of Melbourne with honours.\n",
            "\tIn 1954 he returned to Sydney and went on to complete his secondary education at Sydney Grammar School.\n",
            "\tHe studied at the University of Sydney and at Sydney University, completing his degree while studying for his degree in sociology.  \n",
            "\tHis mother, a retired nurse, lived on the family home and in a care home in Melbourne in the 1950s so that her daughter would be able to study for her degree.\n",
            "\tHe also spent a summer at the University of Western Australia where he graduated as a Bachelor of Nursing.\n",
            "\tHe remained in Australia for a while and then, although he was admitted to a number of hospitals in NSW and other states, he never completed nursing. He subsequently obtained his Bachelor of Nursing degree and became a registered nurse, working within the hospital chain.\n",
            "\tHe worked for the NSW State Public Health Department and, also, until 1958, assisted his mother in care in the Royal Sydney Hospital.\n",
            "\tIn 1960 he returned to Sydney and, with the support of his father, embarked on an undergraduate degree courses at the University of NSW.\n",
            "\tHe studied for his nursing degree and was admitted to the Queen's University.\n",
            "\tHe continued to work for that institution and had another Bachelor degree with honours in 1971.\n",
            "\tHe completed his Master's degree in nursing, graduating in the same year.\n",
            "\tWilliam Hall was an outstanding Sydney administrator and worked in many different areas including the Department of Health, the Division of Mental Health, the NSW Public Service, the Sydney Hospital, and the National Institute of Mental Health.\n",
            "\tHe was a highly effective administrator who, in addition to his medical and nursing, also had a wide range of other special interests to his credit including architecture, photography and landscape architecture. He became a registered nurse for 30 years and died suddenly in Sydney on January 27, 1967.\n",
            "\t\\@ Stirling, George (1881–1967) Mr. George Stirling died suddenly on Saturday at the age of 62. He served in the armed forces with the late Colonel Macpherson, the first Australian-born officer to be appointed to the front as the 4th Infantry Brigade, and for many years afterwards was stationed with Major George L. Stirling, who subsequently became the 1st Brigade Medical Officer in the Australian General Medical Association. His late father-in-law was the late Colonel Macpherson. In the Army he served in the West Riding of New South Wales, and in the New South Wales Territorial Service.He married Miss Marion Anne Stirling in 1887, and on the death of his wife, his parents, Dr. Arthur George and Mrs. George Stirling, of \"Dorak,\" Cottesloe, died on June 22, 1921. He had been in ill health for some time.\n",
            "\t\\@ Taylor, William Thomas (Will) (Will) (1858–1967) \n",
            "\t\\@ McCallum, Henry (1864–1967) Photo supplied by Margaret Taylor\n",
            "�By the time he reached the age of 60 years, Mr. Henry McCallum had had much to do. He had lived in Melbourne for 52 years. But with that short lived life he was to have seen and done much more, to share with the world what an eminent scientist, physicist, and engineer of Australian and foreign origin possessed.\n",
            "\tFor more than 60 years he was one of the foremost authorities on the natural and man-made world, and in the field of physics became one of the great authorities in the field of civil engineering.\n",
            "\tMr. McCallum was a forerunner of the \"scientific\" era of civil engineering. He was an expert in engineering in both civil and commercial use, and in his day his special knowledge in these, as a matter of fact, constituted a very large part of his research work on the natural and man-made world.\n",
            "\tHe is known to millions of people throughout the world, and in the past year he earned the esteem and respect of all with whom he came into contact. Mr. McCallum was a true gentleman, and his home life in his chosen field of mechanical design, was well known to all who had the pleasure of being in his company.\n",
            "\tHe was born in Brisbane in October, 1864, and died at his Brisbane and St. Mark's home in the Old Country on October 30th. Two sons, Mr. Henry James Taylor from Victoria, and Mr\n",
            "\n",
            "[6100 | 4635.49] loss=3.01 avg=2.69\n",
            "[6101 | 4637.17] loss=2.27 avg=2.68\n",
            "[6102 | 4638.85] loss=2.48 avg=2.68\n",
            "[6103 | 4640.53] loss=2.57 avg=2.68\n",
            "[6104 | 4642.20] loss=2.19 avg=2.68\n",
            "[6105 | 4643.87] loss=3.02 avg=2.68\n",
            "[6106 | 4645.55] loss=2.74 avg=2.68\n",
            "[6107 | 4647.22] loss=2.40 avg=2.68\n",
            "[6108 | 4648.89] loss=2.24 avg=2.67\n",
            "[6109 | 4650.55] loss=2.91 avg=2.67\n",
            "[6110 | 4652.22] loss=2.36 avg=2.67\n",
            "[6111 | 4653.89] loss=2.59 avg=2.67\n",
            "[6112 | 4655.55] loss=2.36 avg=2.67\n",
            "[6113 | 4657.23] loss=2.65 avg=2.67\n",
            "[6114 | 4658.89] loss=2.47 avg=2.67\n",
            "[6115 | 4660.57] loss=3.64 avg=2.68\n",
            "[6116 | 4662.24] loss=2.62 avg=2.67\n",
            "[6117 | 4663.92] loss=2.40 avg=2.67\n",
            "[6118 | 4665.61] loss=2.79 avg=2.67\n",
            "[6119 | 4667.29] loss=2.82 avg=2.67\n",
            "[6120 | 4668.97] loss=2.40 avg=2.67\n",
            "[6121 | 4670.66] loss=2.20 avg=2.67\n",
            "[6122 | 4672.35] loss=2.57 avg=2.67\n",
            "[6123 | 4674.04] loss=3.04 avg=2.67\n",
            "[6124 | 4675.74] loss=3.03 avg=2.67\n",
            "[6125 | 4677.44] loss=2.75 avg=2.67\n",
            "[6126 | 4679.14] loss=2.55 avg=2.67\n",
            "[6127 | 4680.84] loss=2.43 avg=2.67\n",
            "[6128 | 4682.54] loss=2.57 avg=2.67\n",
            "[6129 | 4684.25] loss=3.08 avg=2.67\n",
            "[6130 | 4685.94] loss=2.31 avg=2.67\n",
            "[6131 | 4687.65] loss=2.71 avg=2.67\n",
            "[6132 | 4689.35] loss=2.63 avg=2.67\n",
            "[6133 | 4691.05] loss=2.43 avg=2.67\n",
            "[6134 | 4692.76] loss=2.37 avg=2.66\n",
            "[6135 | 4694.45] loss=2.11 avg=2.66\n",
            "[6136 | 4696.15] loss=2.79 avg=2.66\n",
            "[6137 | 4697.85] loss=2.45 avg=2.66\n",
            "[6138 | 4699.55] loss=2.76 avg=2.66\n",
            "[6139 | 4701.25] loss=1.98 avg=2.65\n",
            "[6140 | 4702.95] loss=2.42 avg=2.65\n",
            "[6141 | 4704.65] loss=2.58 avg=2.65\n",
            "[6142 | 4706.35] loss=2.34 avg=2.65\n",
            "[6143 | 4708.05] loss=2.94 avg=2.65\n",
            "[6144 | 4709.74] loss=2.54 avg=2.65\n",
            "[6145 | 4711.44] loss=2.81 avg=2.65\n",
            "[6146 | 4713.13] loss=3.04 avg=2.65\n",
            "[6147 | 4714.82] loss=2.85 avg=2.66\n",
            "[6148 | 4716.52] loss=2.97 avg=2.66\n",
            "[6149 | 4718.22] loss=2.61 avg=2.66\n",
            "[6150 | 4719.91] loss=2.49 avg=2.66\n",
            "[6151 | 4721.60] loss=2.69 avg=2.66\n",
            "[6152 | 4723.27] loss=3.08 avg=2.66\n",
            "[6153 | 4724.96] loss=2.23 avg=2.66\n",
            "[6154 | 4726.65] loss=3.11 avg=2.66\n",
            "[6155 | 4728.33] loss=2.57 avg=2.66\n",
            "[6156 | 4730.01] loss=2.80 avg=2.66\n",
            "[6157 | 4731.70] loss=2.33 avg=2.66\n",
            "[6158 | 4733.38] loss=2.41 avg=2.66\n",
            "[6159 | 4735.06] loss=3.00 avg=2.66\n",
            "[6160 | 4736.75] loss=2.68 avg=2.66\n",
            "[6161 | 4738.43] loss=2.89 avg=2.66\n",
            "[6162 | 4740.11] loss=2.90 avg=2.66\n",
            "[6163 | 4741.79] loss=3.01 avg=2.67\n",
            "[6164 | 4743.47] loss=3.18 avg=2.67\n",
            "[6165 | 4745.16] loss=2.48 avg=2.67\n",
            "[6166 | 4746.84] loss=2.79 avg=2.67\n",
            "[6167 | 4748.52] loss=2.92 avg=2.67\n",
            "[6168 | 4750.20] loss=2.74 avg=2.68\n",
            "[6169 | 4751.88] loss=3.33 avg=2.68\n",
            "[6170 | 4753.56] loss=2.54 avg=2.68\n",
            "[6171 | 4755.25] loss=2.90 avg=2.68\n",
            "[6172 | 4756.94] loss=3.16 avg=2.69\n",
            "[6173 | 4758.63] loss=2.63 avg=2.69\n",
            "[6174 | 4760.31] loss=2.97 avg=2.69\n",
            "[6175 | 4761.99] loss=2.82 avg=2.69\n",
            "[6176 | 4763.68] loss=2.45 avg=2.69\n",
            "[6177 | 4765.36] loss=3.09 avg=2.69\n",
            "[6178 | 4767.06] loss=3.00 avg=2.70\n",
            "[6179 | 4768.75] loss=2.55 avg=2.69\n",
            "[6180 | 4770.44] loss=2.72 avg=2.69\n",
            "[6181 | 4772.13] loss=2.74 avg=2.69\n",
            "[6182 | 4773.81] loss=2.57 avg=2.69\n",
            "[6183 | 4775.50] loss=2.63 avg=2.69\n",
            "[6184 | 4777.19] loss=2.77 avg=2.69\n",
            "[6185 | 4778.88] loss=3.00 avg=2.70\n",
            "[6186 | 4780.57] loss=2.98 avg=2.70\n",
            "[6187 | 4782.27] loss=3.06 avg=2.70\n",
            "[6188 | 4783.93] loss=2.81 avg=2.70\n",
            "[6189 | 4785.63] loss=2.47 avg=2.70\n",
            "[6190 | 4787.33] loss=2.42 avg=2.70\n",
            "[6191 | 4789.02] loss=2.77 avg=2.70\n",
            "[6192 | 4790.71] loss=2.21 avg=2.69\n",
            "[6193 | 4792.41] loss=2.94 avg=2.70\n",
            "[6194 | 4794.11] loss=2.81 avg=2.70\n",
            "[6195 | 4795.82] loss=2.35 avg=2.70\n",
            "[6196 | 4797.52] loss=2.92 avg=2.70\n",
            "[6197 | 4799.22] loss=2.67 avg=2.70\n",
            "[6198 | 4800.92] loss=2.75 avg=2.70\n",
            "[6199 | 4802.61] loss=2.86 avg=2.70\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " lady who came to look after the animals on the farm, but the landlord had no time to take up cattle and horses. The young man, who was about 22 years of age, began to work with a friend and soon discovered he had a talent for horseback riding. With a heavy heart he turned his attention again to the country, and by his good fortune in the early part of this century, and in the early days, gained the support of the late W. H. Mackay, D.S.S., Sydney.\n",
            "\tThe young soldier, who was then about 23 years of age, was at first in contemptuous heart, when he saw the horsemen of the railway station, with its white huts, and its black sheep and horses grazing their wattle fields. The horsemen and sheep were all white, and the sheep were all brown. The soldier was then in a very unhappy condition. He was a gentle man, but when he spoke a good word of fellow-countrymen, he was often mocked by men of the station, who were not content with their own little pleasures. Some of the station men were very angry at the soldier for his good qualities, who by his generosity earned them the confidence and the esteem of the whole community. After a week's holiday he returned home, and by the assistance of a friend and many of his own kind words became well-known on the station. The young soldier was so very liberal towards fellow-countrymen that some of the station men of the time paid him a visit at his homestead, and at the expense of the station, offered him £400 and a cow. So he sent one of them for him, and after paying the station men he was then so well pleased that he left his home, and set off for the open country. With all the men present at the station he went up to where the cattle and sheep were grazing, and sat down to dinner. Having bought an allotment of land for £200 for one of his friends, and gave the allotment over to him, he decided to go on a hunting trip, and to take to heart the good intentions of the station men through good acts of kindness. The soldiers at once asked him what kind of game he had bought, saying he could keep no pigs, and they wished to know the name of the cattle. When the young soldier said he would try to get a name for the cattle, they sent him back down a hillside to try out his guns on the beasts, who were white. The young soldier then set off on ahead at great speed against the horses, shooting and killing some of the horses and driving off the others. He then put the body of the horse, his right foreleg and the tail to a pike, and then tied the horse to a tree on the property, and left him there as a resting place. After a week he returned with the body, the old friend and the body of a cow, and a cow cow. The soldiers gave him £200 as a good luck, and he took up the body and placed the cow on the tree beside it. About half-an-hour later he went down to look at it, the young man, who at first wanted to get it, saw that there was nothing more to it than a pike. For that reason he brought it home and brought it back with him. With a sudden inspiration he got the body, putting a straw on the body, and holding on to the body. At once he sat down, and asked the soldiers why they had taken him under their protection. They gave him a horse for £60 a year instead of a cow, and a cow cow for a sum of £200 a year, which he took up and placed upon the property. About four or five minutes later he came to the house, where his old friend and a large number of other people were sitting. The soldiers told him that if the old man was not to have to pay him £100 for the cow, he must tell him the name of the cattle. The young soldier then said the name of the cow, when they sat down one by one. He sat again on the farm about half an hour later, when he and his friend, Mr. John Todroff, sat down at the table. Mr. and Mrs. Todroff made the mistake of getting two cows, and putting a straw on the same cow and a cow cow on a tree. Mr. Todroff then sat on the ground, and told the soldiers that he had bought his cow cow for £200. They said to him: \"You won't do it?\" he said he would pay them £100, which they said as a good luck he would go and speak to all the station people, and leave him some money. He said they had no business taking in the cow cow, and they had nothing to lose. In a quarter of an hour he came back, and told the soldiers where he had got the cow\n",
            "\n",
            "[6200 | 4826.98] loss=3.34 avg=2.71\n",
            "[6201 | 4828.65] loss=2.70 avg=2.71\n",
            "[6202 | 4830.34] loss=2.37 avg=2.70\n",
            "[6203 | 4832.01] loss=3.30 avg=2.71\n",
            "[6204 | 4833.67] loss=2.41 avg=2.71\n",
            "[6205 | 4835.36] loss=2.56 avg=2.70\n",
            "[6206 | 4837.02] loss=2.55 avg=2.70\n",
            "[6207 | 4838.70] loss=2.33 avg=2.70\n",
            "[6208 | 4840.36] loss=2.73 avg=2.70\n",
            "[6209 | 4842.03] loss=3.01 avg=2.70\n",
            "[6210 | 4843.70] loss=1.95 avg=2.69\n",
            "[6211 | 4845.37] loss=2.39 avg=2.69\n",
            "[6212 | 4847.05] loss=2.20 avg=2.69\n",
            "[6213 | 4848.73] loss=2.68 avg=2.69\n",
            "[6214 | 4850.40] loss=2.46 avg=2.68\n",
            "[6215 | 4852.08] loss=2.98 avg=2.69\n",
            "[6216 | 4853.76] loss=2.34 avg=2.68\n",
            "[6217 | 4855.44] loss=2.50 avg=2.68\n",
            "[6218 | 4857.12] loss=3.20 avg=2.69\n",
            "[6219 | 4858.82] loss=2.26 avg=2.68\n",
            "[6220 | 4860.51] loss=2.33 avg=2.68\n",
            "[6221 | 4862.20] loss=2.71 avg=2.68\n",
            "[6222 | 4863.89] loss=2.73 avg=2.68\n",
            "[6223 | 4865.59] loss=2.86 avg=2.68\n",
            "[6224 | 4867.29] loss=2.60 avg=2.68\n",
            "[6225 | 4869.00] loss=2.42 avg=2.68\n",
            "[6226 | 4870.70] loss=2.57 avg=2.68\n",
            "[6227 | 4872.40] loss=2.33 avg=2.67\n",
            "[6228 | 4874.08] loss=2.76 avg=2.67\n",
            "[6229 | 4875.79] loss=2.51 avg=2.67\n",
            "[6230 | 4877.49] loss=3.23 avg=2.68\n",
            "[6231 | 4879.19] loss=2.89 avg=2.68\n",
            "[6232 | 4880.89] loss=2.56 avg=2.68\n",
            "[6233 | 4882.59] loss=2.42 avg=2.68\n",
            "[6234 | 4884.29] loss=2.59 avg=2.68\n",
            "[6235 | 4885.99] loss=2.87 avg=2.68\n",
            "[6236 | 4887.69] loss=2.15 avg=2.67\n",
            "[6237 | 4889.39] loss=3.20 avg=2.68\n",
            "[6238 | 4891.10] loss=2.53 avg=2.68\n",
            "[6239 | 4892.80] loss=2.92 avg=2.68\n",
            "[6240 | 4894.48] loss=2.91 avg=2.68\n",
            "[6241 | 4896.17] loss=2.50 avg=2.68\n",
            "[6242 | 4897.86] loss=2.23 avg=2.67\n",
            "[6243 | 4899.56] loss=2.69 avg=2.67\n",
            "[6244 | 4901.24] loss=2.58 avg=2.67\n",
            "[6245 | 4902.94] loss=2.45 avg=2.67\n",
            "[6246 | 4904.63] loss=2.71 avg=2.67\n",
            "[6247 | 4906.32] loss=2.58 avg=2.67\n",
            "[6248 | 4907.99] loss=2.55 avg=2.67\n",
            "[6249 | 4909.68] loss=2.85 avg=2.67\n",
            "[6250 | 4911.37] loss=2.28 avg=2.67\n",
            "[6251 | 4913.05] loss=2.77 avg=2.67\n",
            "[6252 | 4914.73] loss=2.76 avg=2.67\n",
            "[6253 | 4916.41] loss=2.15 avg=2.66\n",
            "[6254 | 4918.10] loss=2.95 avg=2.67\n",
            "[6255 | 4919.77] loss=2.78 avg=2.67\n",
            "[6256 | 4921.46] loss=2.89 avg=2.67\n",
            "[6257 | 4923.14] loss=3.16 avg=2.68\n",
            "[6258 | 4924.83] loss=2.74 avg=2.68\n",
            "[6259 | 4926.51] loss=2.46 avg=2.67\n",
            "[6260 | 4928.19] loss=3.26 avg=2.68\n",
            "[6261 | 4929.87] loss=2.41 avg=2.68\n",
            "[6262 | 4931.56] loss=2.61 avg=2.68\n",
            "[6263 | 4933.24] loss=2.57 avg=2.68\n",
            "[6264 | 4934.92] loss=2.20 avg=2.67\n",
            "[6265 | 4936.62] loss=2.63 avg=2.67\n",
            "[6266 | 4938.31] loss=2.31 avg=2.67\n",
            "[6267 | 4940.00] loss=2.23 avg=2.66\n",
            "[6268 | 4941.68] loss=2.51 avg=2.66\n",
            "[6269 | 4943.36] loss=3.11 avg=2.67\n",
            "[6270 | 4945.05] loss=2.43 avg=2.66\n",
            "[6271 | 4946.74] loss=2.76 avg=2.66\n",
            "[6272 | 4948.42] loss=2.70 avg=2.66\n",
            "[6273 | 4950.11] loss=3.14 avg=2.67\n",
            "[6274 | 4951.81] loss=2.42 avg=2.67\n",
            "[6275 | 4953.50] loss=2.16 avg=2.66\n",
            "[6276 | 4955.19] loss=2.73 avg=2.66\n",
            "[6277 | 4956.89] loss=2.26 avg=2.66\n",
            "[6278 | 4958.57] loss=2.65 avg=2.66\n",
            "[6279 | 4960.28] loss=2.29 avg=2.65\n",
            "[6280 | 4961.98] loss=2.68 avg=2.65\n",
            "[6281 | 4963.68] loss=3.13 avg=2.66\n",
            "[6282 | 4965.38] loss=2.58 avg=2.66\n",
            "[6283 | 4967.07] loss=2.41 avg=2.66\n",
            "[6284 | 4968.76] loss=3.00 avg=2.66\n",
            "[6285 | 4970.46] loss=2.33 avg=2.66\n",
            "[6286 | 4972.16] loss=3.22 avg=2.66\n",
            "[6287 | 4973.86] loss=3.12 avg=2.67\n",
            "[6288 | 4975.57] loss=2.45 avg=2.66\n",
            "[6289 | 4977.27] loss=2.20 avg=2.66\n",
            "[6290 | 4978.97] loss=2.38 avg=2.66\n",
            "[6291 | 4980.67] loss=2.29 avg=2.65\n",
            "[6292 | 4982.38] loss=3.01 avg=2.66\n",
            "[6293 | 4984.08] loss=2.68 avg=2.66\n",
            "[6294 | 4985.78] loss=2.29 avg=2.65\n",
            "[6295 | 4987.48] loss=2.99 avg=2.66\n",
            "[6296 | 4989.18] loss=2.47 avg=2.65\n",
            "[6297 | 4990.88] loss=3.08 avg=2.66\n",
            "[6298 | 4992.58] loss=2.90 avg=2.66\n",
            "[6299 | 4994.28] loss=2.87 avg=2.66\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            "'s family members.\n",
            "\tHis father, George Charles Ould, was a senior partner in Sydney law firm of O'Brien and O'Brien, where Mr. Brown was chief barristers and special advocate. George D. Ould, with whom Mr. Brown went to school, was a member of the family for many years on the Gold Coast.\n",
            "\tHe was also a member of the family of lawyers, both from the north and south. Mr. D. P. Brown, whose father was a member of the first parliamentary committee on the legal profession, died at the age of 89. He, too, went to the University of Sydney to gain a law degree.\n",
            "\tThe brother, Mr. James T. Brown, who lives in Queensland, and one sister, Margaret A. Brown, married the late Captain James W. Brown, who was afterwards appointed to the Queensland position of chief constable.\n",
            "\tHis daughter, Miss Patricia Brown, formerly Miss Pat Wilson of Melbourne, married the late Mr. John W. Wilson, one of the first commissioners sent to New South Wales as Governor for the territory.\n",
            "�\\@ MacFarlane, William (1847–1915) Mr W. C. O'Connor Wm. D.M M.G.—A man of very wide knowledge of public matters, he was well known for the public interest he contributed by his public acts. He was in many countries known as a social gentleman, a gentleman of the people.\n",
            "\t\\@ Whelan, William (1829–1915) The death occurred on Tuesday morning of Mr. W. W. H. Whelan, of the old Wattle Inn, Mount Gambier, aged 65 years. Deceased's last years were spent at Lake Macquarie. Deceased's family was connected with the old Wattle Inn and is remembered by a large circle of friends. He is survived by a widow (daughter of Dr J. M. Maclean) and two sons, W. A. (Mrs. S. H. Maclean) and W. C. (son of Dr Arthur Maclean).\n",
            "\t\\@ Gormley, Charles Augustus (1862–1914) \n",
            "\tThe death is announced of Mr. Charles Augustus (1862–1914) of The George, Mount Gambier, Mr. Charles Augustus Gormley, son of Thomas Gormley, a retired member of the Legislative Council and member of the Advisory Committee for the Town and Country Lands Board which position he held for over 25 years. He arrived in Australia from London in 1895. Since that time Mr. Gormley, having been resident in this State for over 30 years, had resided at Mount Mungo, where he was educated. He retired from the position of Town Surveyor in 1907. In this position he was responsible for the surveying of the districts of Goolwa, Chadds Ford, Mount Barker, Mount Gambier, Mount Gambier and other important places as well as the construction of drainage mains. In connection with his duties Mr Gormley took a keen interest in all public movements including the hunting and grazing of game.\n",
            "\tAlthough a wellknown man in this State, Mr Charles Augustus Gormley had the support of few, both in Government and Opposition alike, but it appears that he was always the centre character of affairs, which gave to him the confidence of all. There has always been a personal esteem and affection that surrounded the deceased, who was never ineffectual in his duties, and was greatly respected. The deceased was the grandson of the late Mr. George Campbell, who founded \"Campbelltown\" and a friend of the late Mr John Macauley, father of the latter. The late Mr Charles Augustus Gormley was a native of Glasgow, Scotland, but arrived in Australia in 1895, of which State he was educated.\n",
            "\tThe late Mr. Gormley was a man of great activity and ability, having played a good part in every movement, and was very keenly interested in all public matters, especially those of education and sports. He had a general knowledge of the history of this State and the surrounding colonies and it is very strange to think of what a service he rendered in connection with that branch of public life he occupied. He assisted in the construction of a State monument at Mount Gambier, and in behalf of this work he was an honorary member for a number of years. Mr. Gormley was a man of excellent physique, but he was not a strong man, and the effect of his bulk on his movements was sometimes serious. Of late years his health had been of a very bad character, and death removed that very marked defect of vigor, which has marked his character from childhood upwards.\n",
            "\tMr. Charles Augustus Gormley, who was a resident of this District for many years, was a man who had great sense of duty and did good work. He was also an intimate friend\n",
            "\n",
            "[6300 | 5018.39] loss=2.58 avg=2.66\n",
            "[6301 | 5020.07] loss=2.73 avg=2.66\n",
            "[6302 | 5021.75] loss=2.43 avg=2.66\n",
            "[6303 | 5023.43] loss=2.60 avg=2.66\n",
            "[6304 | 5025.11] loss=2.85 avg=2.66\n",
            "[6305 | 5026.77] loss=2.59 avg=2.66\n",
            "[6306 | 5028.43] loss=2.64 avg=2.66\n",
            "[6307 | 5030.11] loss=2.90 avg=2.66\n",
            "[6308 | 5031.78] loss=2.59 avg=2.66\n",
            "[6309 | 5033.44] loss=2.65 avg=2.66\n",
            "[6310 | 5035.12] loss=2.29 avg=2.66\n",
            "[6311 | 5036.79] loss=2.21 avg=2.65\n",
            "[6312 | 5038.47] loss=2.75 avg=2.66\n",
            "[6313 | 5040.15] loss=2.48 avg=2.65\n",
            "[6314 | 5041.83] loss=2.74 avg=2.65\n",
            "[6315 | 5043.51] loss=2.67 avg=2.65\n",
            "[6316 | 5045.19] loss=3.13 avg=2.66\n",
            "[6317 | 5046.88] loss=2.95 avg=2.66\n",
            "[6318 | 5048.56] loss=2.53 avg=2.66\n",
            "[6319 | 5050.24] loss=2.23 avg=2.66\n",
            "[6320 | 5051.94] loss=2.24 avg=2.65\n",
            "[6321 | 5053.62] loss=3.17 avg=2.66\n",
            "[6322 | 5055.32] loss=3.06 avg=2.66\n",
            "[6323 | 5057.02] loss=2.71 avg=2.66\n",
            "[6324 | 5058.72] loss=2.78 avg=2.66\n",
            "[6325 | 5060.43] loss=2.54 avg=2.66\n",
            "[6326 | 5062.13] loss=2.57 avg=2.66\n",
            "[6327 | 5063.83] loss=2.51 avg=2.66\n",
            "[6328 | 5065.54] loss=2.85 avg=2.66\n",
            "[6329 | 5067.24] loss=2.55 avg=2.66\n",
            "[6330 | 5068.94] loss=2.23 avg=2.66\n",
            "[6331 | 5070.64] loss=2.33 avg=2.65\n",
            "[6332 | 5072.35] loss=2.26 avg=2.65\n",
            "[6333 | 5074.06] loss=2.69 avg=2.65\n",
            "[6334 | 5075.75] loss=3.21 avg=2.66\n",
            "[6335 | 5077.45] loss=3.04 avg=2.66\n",
            "[6336 | 5079.15] loss=2.50 avg=2.66\n",
            "[6337 | 5080.86] loss=3.19 avg=2.66\n",
            "[6338 | 5082.56] loss=3.25 avg=2.67\n",
            "[6339 | 5084.26] loss=2.75 avg=2.67\n",
            "[6340 | 5085.96] loss=2.16 avg=2.66\n",
            "[6341 | 5087.66] loss=2.48 avg=2.66\n",
            "[6342 | 5089.35] loss=2.70 avg=2.66\n",
            "[6343 | 5091.04] loss=1.89 avg=2.66\n",
            "[6344 | 5092.74] loss=3.02 avg=2.66\n",
            "[6345 | 5094.43] loss=3.10 avg=2.66\n",
            "[6346 | 5096.12] loss=2.84 avg=2.66\n",
            "[6347 | 5097.81] loss=2.55 avg=2.66\n",
            "[6348 | 5099.49] loss=3.33 avg=2.67\n",
            "[6349 | 5101.18] loss=2.88 avg=2.67\n",
            "[6350 | 5102.87] loss=2.32 avg=2.67\n",
            "[6351 | 5104.56] loss=2.60 avg=2.67\n",
            "[6352 | 5106.25] loss=2.40 avg=2.67\n",
            "[6353 | 5107.94] loss=2.38 avg=2.66\n",
            "[6354 | 5109.63] loss=2.73 avg=2.66\n",
            "[6355 | 5111.32] loss=2.25 avg=2.66\n",
            "[6356 | 5113.01] loss=2.41 avg=2.66\n",
            "[6357 | 5114.70] loss=3.17 avg=2.66\n",
            "[6358 | 5116.39] loss=2.31 avg=2.66\n",
            "[6359 | 5118.08] loss=3.16 avg=2.66\n",
            "[6360 | 5119.78] loss=2.77 avg=2.66\n",
            "[6361 | 5121.45] loss=2.78 avg=2.67\n",
            "[6362 | 5123.14] loss=2.21 avg=2.66\n",
            "[6363 | 5124.82] loss=2.51 avg=2.66\n",
            "[6364 | 5126.50] loss=3.14 avg=2.66\n",
            "[6365 | 5128.19] loss=3.28 avg=2.67\n",
            "[6366 | 5129.88] loss=2.78 avg=2.67\n",
            "[6367 | 5131.56] loss=2.96 avg=2.67\n",
            "[6368 | 5133.24] loss=3.08 avg=2.68\n",
            "[6369 | 5134.93] loss=3.11 avg=2.68\n",
            "[6370 | 5136.61] loss=2.40 avg=2.68\n",
            "[6371 | 5138.30] loss=2.38 avg=2.68\n",
            "[6372 | 5139.97] loss=2.53 avg=2.68\n",
            "[6373 | 5141.65] loss=2.28 avg=2.67\n",
            "[6374 | 5143.34] loss=3.14 avg=2.68\n",
            "[6375 | 5145.02] loss=2.34 avg=2.67\n",
            "[6376 | 5146.71] loss=2.28 avg=2.67\n",
            "[6377 | 5148.40] loss=2.51 avg=2.67\n",
            "[6378 | 5150.08] loss=2.79 avg=2.67\n",
            "[6379 | 5151.76] loss=2.83 avg=2.67\n",
            "[6380 | 5153.44] loss=2.44 avg=2.67\n",
            "[6381 | 5155.13] loss=2.67 avg=2.67\n",
            "[6382 | 5156.81] loss=2.59 avg=2.67\n",
            "[6383 | 5158.49] loss=3.01 avg=2.67\n",
            "[6384 | 5160.17] loss=2.80 avg=2.67\n",
            "[6385 | 5161.86] loss=2.88 avg=2.67\n",
            "[6386 | 5163.54] loss=2.93 avg=2.68\n",
            "[6387 | 5165.21] loss=2.25 avg=2.67\n",
            "[6388 | 5166.89] loss=2.23 avg=2.67\n",
            "[6389 | 5168.58] loss=2.79 avg=2.67\n",
            "[6390 | 5170.28] loss=2.95 avg=2.67\n",
            "[6391 | 5171.96] loss=2.45 avg=2.67\n",
            "[6392 | 5173.65] loss=3.23 avg=2.68\n",
            "[6393 | 5175.33] loss=2.88 avg=2.68\n",
            "[6394 | 5177.03] loss=2.43 avg=2.67\n",
            "[6395 | 5178.71] loss=2.46 avg=2.67\n",
            "[6396 | 5180.40] loss=2.59 avg=2.67\n",
            "[6397 | 5182.10] loss=2.88 avg=2.67\n",
            "[6398 | 5183.78] loss=2.28 avg=2.67\n",
            "[6399 | 5185.47] loss=2.24 avg=2.67\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " the most striking effect of the exhibition which the late Charles-George Stewart received at Goulburn Castle was the way he took great pleasure in seeing Mr. T. W. Walker and Mr. O. O. Brown so completely transformed, into a model specimen of the character which the school held as a model on its own terms. This was one of the early instances of the school taking great confidence in the personal qualities of individuals, and making them its model at home. The present president of the school, William MacPherson, had his own personal and special interest in the exhibition. His interest was directed to the school's history, and was to the satisfaction of the majority of the students. To the end these students will have an interest in the establishment of a school which offers instruction and practical methods for improvement in the social and economic systems of Australia. In the present school they have a teacher, who, as a man of character and principles, and one who held to the high ideal that the future of Australia should be found in the better development of the people who live there. In other ways the former president has been successful in achieving a good school. During the period of its establishment he saw through the difficulties in the formative and development of the school. He gave the administration of the school an excellent foundation, and he was, perhaps, in a more significant sense, responsible for its success.The late Mr. Wm. Stewart was born at Curnowrie, near Ayrshire, Scotland, in 1848, and his parents, the late Mr. James Stewart and the late Mrs. Stewart, resided at Ellington Street, South Yarra, for the last eight years before the late Mr. Stewart went to Perth. He was a brother of the late Mr. Stephen Stewart who held the position of magistrate in the High Court. He was a member of one of the first local constables, the late Arthur T. O'Connell, and went to England, to Oxford, where he spent some years. He was admitted to the bar of Oxford, and on his return to Australia, in 1878, married Mrs. Ettie. Their first was a family of three – Mr. Stewart, James Stewart, and the late Miss Stewart. Three years later the family were settled at Goulburn where Mr Stewart served in the First High Court. At the age of forty-seven (his 83rd birthday), they were driven off a farm and settled on a large estate, at Ellington, near Goulburn, and there they lived for some years. In the meantime he had also devoted years to gardening, and the two of them had a strong love of gardening and nature. About 1894, when he had settled on the estate with Mr and Mrs. T. P. Stewart, a young married couple were sent to reside in New Zealand. They followed farming pursuits, with particular success, in that country. While in England they visited Cape Town, and visited again Cape Town several years later.\n",
            "�During the last few years he had a long association with the Goulburn Chamber of Commerce, in which he had a very deep and comfortable interest, and which he continued to do in later years, especially in connection with the development and growth of the business. Many letters received by the Chamber of Commerce during its growth in the year 1899 (and to the end) are full of interest and sympathy, and their contents demonstrate the good and useful work done by his association with this body.\n",
            "\tThe late Mr. T. W. Stewart leaves a widow and seven children who are all married, namely – Mrs. Peter MacLennan, Mrs. J. Cavanough, Mrs. C. C. MacLennan, Mrs. J. F. MacLennan, and Mrs. E. G. MacDonald. The last will of the deceased gentleman will be published at Wollongong later on, and it is expected to be received with great regret, not only among his friends and associates, but also by those in whom the dead man has left a very lasting impression. The funeral and service at Goulburn on Wednesday will be largely attended, but there will be no service at the church. The service will begin at 2 o'clock.\n",
            "\t\\@ Bickford, Elma Sophia (1849–1902) The demise of Mrs. Elma Sophia Bickford is announced from the South Head Medical Practice yesterday, who is now in her 80th year. The deceased was an old resident of the North Coast who had recently been living in South Head. She had been a resident of South Head for some years past, and a sister of the late Mr. C. Bickford, M.P.\n",
            "\t\\@ Lipscomb, Emily (1840–1902) \n",
            "\tMr. William Maclean, of Melbourne, has received a letter congratulating his daughter for her remarkable success in the \"New Zealand Tour, in which she carried on a tour through\n",
            "\n",
            "[6400 | 5209.46] loss=2.71 avg=2.67\n",
            "[6401 | 5211.14] loss=1.96 avg=2.66\n",
            "[6402 | 5212.82] loss=2.76 avg=2.66\n",
            "[6403 | 5214.51] loss=3.30 avg=2.67\n",
            "[6404 | 5216.18] loss=2.46 avg=2.66\n",
            "[6405 | 5217.87] loss=2.68 avg=2.66\n",
            "[6406 | 5219.55] loss=2.54 avg=2.66\n",
            "[6407 | 5221.23] loss=3.25 avg=2.67\n",
            "[6408 | 5222.91] loss=2.91 avg=2.67\n",
            "[6409 | 5224.58] loss=2.67 avg=2.67\n",
            "[6410 | 5226.25] loss=2.80 avg=2.67\n",
            "[6411 | 5227.93] loss=2.71 avg=2.67\n",
            "[6412 | 5229.61] loss=2.38 avg=2.67\n",
            "[6413 | 5231.30] loss=2.58 avg=2.67\n",
            "[6414 | 5232.98] loss=2.46 avg=2.67\n",
            "[6415 | 5234.66] loss=2.55 avg=2.67\n",
            "[6416 | 5236.34] loss=2.73 avg=2.67\n",
            "[6417 | 5238.03] loss=2.51 avg=2.67\n",
            "[6418 | 5239.71] loss=2.78 avg=2.67\n",
            "[6419 | 5241.39] loss=2.27 avg=2.66\n",
            "[6420 | 5243.07] loss=2.55 avg=2.66\n",
            "[6421 | 5244.77] loss=2.39 avg=2.66\n",
            "[6422 | 5246.45] loss=2.39 avg=2.66\n",
            "[6423 | 5248.13] loss=2.81 avg=2.66\n",
            "[6424 | 5249.83] loss=3.39 avg=2.66\n",
            "[6425 | 5251.52] loss=2.62 avg=2.66\n",
            "[6426 | 5253.22] loss=2.77 avg=2.67\n",
            "[6427 | 5254.91] loss=3.04 avg=2.67\n",
            "[6428 | 5256.60] loss=2.51 avg=2.67\n",
            "[6429 | 5258.30] loss=3.02 avg=2.67\n",
            "[6430 | 5260.01] loss=2.42 avg=2.67\n",
            "[6431 | 5261.71] loss=2.93 avg=2.67\n",
            "[6432 | 5263.41] loss=2.64 avg=2.67\n",
            "[6433 | 5265.11] loss=3.01 avg=2.67\n",
            "[6434 | 5266.81] loss=2.62 avg=2.67\n",
            "[6435 | 5268.51] loss=2.37 avg=2.67\n",
            "[6436 | 5270.21] loss=2.66 avg=2.67\n",
            "[6437 | 5271.91] loss=3.03 avg=2.67\n",
            "[6438 | 5273.62] loss=2.77 avg=2.68\n",
            "[6439 | 5275.32] loss=2.19 avg=2.67\n",
            "[6440 | 5277.02] loss=2.79 avg=2.67\n",
            "[6441 | 5278.72] loss=2.50 avg=2.67\n",
            "[6442 | 5280.42] loss=3.18 avg=2.67\n",
            "[6443 | 5282.12] loss=2.29 avg=2.67\n",
            "[6444 | 5283.82] loss=2.63 avg=2.67\n",
            "[6445 | 5285.53] loss=3.05 avg=2.67\n",
            "[6446 | 5287.23] loss=2.39 avg=2.67\n",
            "[6447 | 5288.93] loss=3.25 avg=2.68\n",
            "[6448 | 5290.63] loss=2.77 avg=2.68\n",
            "[6449 | 5292.33] loss=2.63 avg=2.68\n",
            "[6450 | 5294.03] loss=2.84 avg=2.68\n",
            "[6451 | 5295.73] loss=2.50 avg=2.68\n",
            "[6452 | 5297.43] loss=3.31 avg=2.68\n",
            "[6453 | 5299.13] loss=2.87 avg=2.69\n",
            "[6454 | 5300.84] loss=2.87 avg=2.69\n",
            "[6455 | 5302.54] loss=2.50 avg=2.69\n",
            "[6456 | 5304.23] loss=2.75 avg=2.69\n",
            "[6457 | 5305.94] loss=2.49 avg=2.68\n",
            "[6458 | 5307.64] loss=2.83 avg=2.69\n",
            "[6459 | 5309.34] loss=2.44 avg=2.68\n",
            "[6460 | 5311.04] loss=2.65 avg=2.68\n",
            "[6461 | 5312.74] loss=2.44 avg=2.68\n",
            "[6462 | 5314.44] loss=2.45 avg=2.68\n",
            "[6463 | 5316.14] loss=2.60 avg=2.68\n",
            "[6464 | 5317.85] loss=2.37 avg=2.67\n",
            "[6465 | 5319.55] loss=2.80 avg=2.68\n",
            "[6466 | 5321.25] loss=2.36 avg=2.67\n",
            "[6467 | 5322.95] loss=2.31 avg=2.67\n",
            "[6468 | 5324.65] loss=2.79 avg=2.67\n",
            "[6469 | 5326.35] loss=2.80 avg=2.67\n",
            "[6470 | 5328.05] loss=2.06 avg=2.67\n",
            "[6471 | 5329.75] loss=2.83 avg=2.67\n",
            "[6472 | 5331.45] loss=2.49 avg=2.67\n",
            "[6473 | 5333.15] loss=2.26 avg=2.66\n",
            "[6474 | 5334.86] loss=2.76 avg=2.66\n",
            "[6475 | 5336.56] loss=2.15 avg=2.66\n",
            "[6476 | 5338.26] loss=2.77 avg=2.66\n",
            "[6477 | 5339.97] loss=2.37 avg=2.66\n",
            "[6478 | 5341.67] loss=2.47 avg=2.65\n",
            "[6479 | 5343.37] loss=2.74 avg=2.65\n",
            "[6480 | 5345.08] loss=2.70 avg=2.65\n",
            "[6481 | 5346.77] loss=3.15 avg=2.66\n",
            "[6482 | 5348.48] loss=2.56 avg=2.66\n",
            "[6483 | 5350.18] loss=2.98 avg=2.66\n",
            "[6484 | 5351.88] loss=2.36 avg=2.66\n",
            "[6485 | 5353.58] loss=3.19 avg=2.66\n",
            "[6486 | 5355.28] loss=2.26 avg=2.66\n",
            "[6487 | 5356.98] loss=3.54 avg=2.67\n",
            "[6488 | 5358.68] loss=2.62 avg=2.67\n",
            "[6489 | 5360.38] loss=2.38 avg=2.67\n",
            "[6490 | 5362.08] loss=2.74 avg=2.67\n",
            "[6491 | 5363.78] loss=2.49 avg=2.66\n",
            "[6492 | 5365.49] loss=2.87 avg=2.67\n",
            "[6493 | 5367.19] loss=2.91 avg=2.67\n",
            "[6494 | 5368.89] loss=2.36 avg=2.67\n",
            "[6495 | 5370.59] loss=2.72 avg=2.67\n",
            "[6496 | 5372.29] loss=2.57 avg=2.67\n",
            "[6497 | 5373.99] loss=2.54 avg=2.66\n",
            "[6498 | 5375.69] loss=2.33 avg=2.66\n",
            "[6499 | 5377.39] loss=2.61 avg=2.66\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            "bs. He was a member of many local bodies of which the membership of the local council was the subject of some attention in those days. For some time he has been in occupation in the district bank. For many years the late Mr. E. E. Lubbock was treasurer of the Shrubers' Club, and when that club was abolished about ten years ago, he acted as treasurer for about several years. The late Mr. Lubbock leaves two sons, Messrs. Henry and James Lubbock, M.A.\n",
            "\t\\@ Campbell, Charles Francis (1862–1929) \n",
            "\tThe Hon. David Campbell died on Sunday at his residence, Waverley, Darling Point, Brisbane, aged 83 years.\n",
            "\tA son of the late Mr. James Campbell (Sydney), the late Mr. Charles Francis Campbell was born at Brisbane on July 7, 1862, and was educated under the former Headmaster Sir George Lubbock at the Royal Naval College, Melbourne. He was soon sent for as a second-class officer to the Naval College, Melbourne, and was admitted as a midshipman in 1865. He was afterwards transferred to the Defence Commandant's staff, and at one stage served on a brigade. In 1863 he was made a lieutenant-admiral.\n",
            "\tHe followed the army and the navy at the time of his discharge and when he returned, he was placed in charge of Rookwood, a district which has since been incorporated into the city and has become famous in the area of the city as the area covered over, and which was well-spoiled when he was there.\n",
            "\tFor a long time Mr. Campbell has been a member of the City Council, but not since he has his interests been concerned in the business of this City.\n",
            "\tMr. Campbell, who was a great supporter of the Royal Zoological Gardens, is survived by a widow, a brother (Mr. M. H. Campbell, of Cairns) and three sisters (Mrs. A. Hill, Mrs. H. C. G. Campbell, Misses Dora and Helen Campbell). The funeral will leave Mrs. Campbell's home at 11 o'clock for her late residence. The service at the funeral will follow.\n",
            "\t\\@ Lonergan, William John (1860–1929) \n",
            "\tMr William John Lonergan, second son of the late George Lonergan, formerly of the Bank of New South Wales, died early yesterday morning in Sydney after a very long illness.\n",
            "\tBorn in Melbourne in 1860, he went to Sydney in 1871 and studied law. He then bought and sold property at Maitland, before setting out for Queensland in 1886. He was first appointed judge of the Supreme Court and was then appointed for Queensland to the Bar. He was the first and only Aboriginal to sit on the Queensland Bar Council.\n",
            "\tIn 1912, at the age of 67, he was succeeded as president of the Bar by Mr R. H. Walker, who was then leader of the Queensland branch of the Irish Republican Brotherhood.\n",
            "\tMr Lonergan was a director of Barristers' Quarry, Sydney, and the National Insurance Co. of Australia, being an advocate for the establishment of a national insurance scheme and was also a member of the firm of Messrs Haddon, Turner and Lonergan. He had an interest in the Queensland National Heritage Trust, and had represented this State in the Parliament of Queensland. He was one of the original incorporators of the Bar Council of New South Wales.\n",
            "\tMr. Lonergan married a daughter of the late John Walker, and leaves three sons and a daughter. His eldest son is now in the service of the Government.\n",
            "\t\\@ Langley, William (?–1929) \n",
            "\tThe death is announced of Mr. William Langley, formerly of Glenelg. He was born at Mount Mersey in 1863, and went into the gold rush business. He took an interest in the Australian Gold Rush (which he owned at various times), and owned about 15 per cent of that company. He also owned the Goldfields Downs tram railway, and was interested in the Glenelg coalmines.\n",
            "\t\\@ Auld, Sarah Ann (1840–1929) \n",
            "\tMrs. E. Auld passed away at her residence, \"Windward Row,\" Northcote on the 28th instant. She was aged 71 years, and she was the oldest resident of Northcote.\n",
            "\tMrs. Auld was a sister of Messrs. Samuel Brouwer. Their uncle, the late Thomas Brouwer of the South Cootamundra mine, died in the early 1890's. The present Mr. F. Auld, a son, was born at Sandgate in 1867, and was married at Northcote in 1882. He is now engaged in pastoral pursuits near Northcote.\n",
            "\n",
            "[6500 | 5401.48] loss=2.18 avg=2.66\n",
            "[6501 | 5403.15] loss=2.72 avg=2.66\n",
            "[6502 | 5404.83] loss=2.27 avg=2.65\n",
            "[6503 | 5406.50] loss=3.08 avg=2.66\n",
            "[6504 | 5408.18] loss=2.31 avg=2.65\n",
            "[6505 | 5409.84] loss=2.51 avg=2.65\n",
            "[6506 | 5411.50] loss=2.51 avg=2.65\n",
            "[6507 | 5413.18] loss=2.22 avg=2.65\n",
            "[6508 | 5414.87] loss=2.70 avg=2.65\n",
            "[6509 | 5416.54] loss=2.22 avg=2.64\n",
            "[6510 | 5418.21] loss=2.56 avg=2.64\n",
            "[6511 | 5419.89] loss=2.60 avg=2.64\n",
            "[6512 | 5421.57] loss=2.46 avg=2.64\n",
            "[6513 | 5423.24] loss=2.53 avg=2.64\n",
            "[6514 | 5424.91] loss=2.52 avg=2.64\n",
            "[6515 | 5426.60] loss=3.05 avg=2.64\n",
            "[6516 | 5428.28] loss=2.43 avg=2.64\n",
            "[6517 | 5429.95] loss=2.44 avg=2.64\n",
            "[6518 | 5431.64] loss=3.09 avg=2.64\n",
            "[6519 | 5433.34] loss=2.98 avg=2.64\n",
            "[6520 | 5435.04] loss=3.12 avg=2.65\n",
            "[6521 | 5436.74] loss=2.33 avg=2.65\n",
            "[6522 | 5438.44] loss=2.36 avg=2.64\n",
            "[6523 | 5440.14] loss=2.37 avg=2.64\n",
            "[6524 | 5441.84] loss=2.37 avg=2.64\n",
            "[6525 | 5443.55] loss=2.25 avg=2.63\n",
            "[6526 | 5445.25] loss=2.54 avg=2.63\n",
            "[6527 | 5446.95] loss=2.59 avg=2.63\n",
            "[6528 | 5448.65] loss=2.63 avg=2.63\n",
            "[6529 | 5450.35] loss=2.71 avg=2.63\n",
            "[6530 | 5452.06] loss=2.65 avg=2.63\n",
            "[6531 | 5453.76] loss=2.48 avg=2.63\n",
            "[6532 | 5455.46] loss=2.49 avg=2.63\n",
            "[6533 | 5457.16] loss=2.75 avg=2.63\n",
            "[6534 | 5458.86] loss=2.57 avg=2.63\n",
            "[6535 | 5460.56] loss=2.41 avg=2.63\n",
            "[6536 | 5462.26] loss=2.57 avg=2.63\n",
            "[6537 | 5463.96] loss=2.75 avg=2.63\n",
            "[6538 | 5465.66] loss=3.04 avg=2.63\n",
            "[6539 | 5467.37] loss=2.38 avg=2.63\n",
            "[6540 | 5469.07] loss=2.37 avg=2.63\n",
            "[6541 | 5470.77] loss=2.87 avg=2.63\n",
            "[6542 | 5472.47] loss=1.96 avg=2.62\n",
            "[6543 | 5474.17] loss=2.97 avg=2.63\n",
            "[6544 | 5475.86] loss=2.33 avg=2.62\n",
            "[6545 | 5477.56] loss=2.63 avg=2.63\n",
            "[6546 | 5479.25] loss=2.47 avg=2.62\n",
            "[6547 | 5480.95] loss=2.95 avg=2.63\n",
            "[6548 | 5482.65] loss=2.72 avg=2.63\n",
            "[6549 | 5484.35] loss=2.05 avg=2.62\n",
            "[6550 | 5486.04] loss=2.07 avg=2.62\n",
            "[6551 | 5487.72] loss=3.36 avg=2.62\n",
            "[6552 | 5489.41] loss=2.35 avg=2.62\n",
            "[6553 | 5491.09] loss=2.41 avg=2.62\n",
            "[6554 | 5492.78] loss=2.85 avg=2.62\n",
            "[6555 | 5494.46] loss=2.50 avg=2.62\n",
            "[6556 | 5496.14] loss=2.66 avg=2.62\n",
            "[6557 | 5497.82] loss=2.60 avg=2.62\n",
            "[6558 | 5499.51] loss=2.98 avg=2.62\n",
            "[6559 | 5501.18] loss=2.95 avg=2.63\n",
            "[6560 | 5502.87] loss=2.19 avg=2.62\n",
            "[6561 | 5504.54] loss=2.79 avg=2.62\n",
            "[6562 | 5506.23] loss=2.87 avg=2.63\n",
            "[6563 | 5507.91] loss=2.53 avg=2.63\n",
            "[6564 | 5509.60] loss=2.57 avg=2.63\n",
            "[6565 | 5511.27] loss=2.66 avg=2.63\n",
            "[6566 | 5512.94] loss=2.59 avg=2.63\n",
            "[6567 | 5514.63] loss=2.46 avg=2.62\n",
            "[6568 | 5516.31] loss=2.83 avg=2.63\n",
            "[6569 | 5518.00] loss=2.65 avg=2.63\n",
            "[6570 | 5519.70] loss=3.00 avg=2.63\n",
            "[6571 | 5521.38] loss=1.98 avg=2.62\n",
            "[6572 | 5523.07] loss=2.69 avg=2.62\n",
            "[6573 | 5524.75] loss=2.10 avg=2.62\n",
            "[6574 | 5526.44] loss=2.35 avg=2.62\n",
            "[6575 | 5528.13] loss=2.40 avg=2.61\n",
            "[6576 | 5529.82] loss=2.14 avg=2.61\n",
            "[6577 | 5531.52] loss=2.20 avg=2.61\n",
            "[6578 | 5533.21] loss=2.72 avg=2.61\n",
            "[6579 | 5534.89] loss=2.78 avg=2.61\n",
            "[6580 | 5536.58] loss=2.68 avg=2.61\n",
            "[6581 | 5538.28] loss=2.66 avg=2.61\n",
            "[6582 | 5539.97] loss=2.38 avg=2.61\n",
            "[6583 | 5541.66] loss=2.22 avg=2.60\n",
            "[6584 | 5543.35] loss=2.52 avg=2.60\n",
            "[6585 | 5545.04] loss=2.89 avg=2.61\n",
            "[6586 | 5546.73] loss=2.80 avg=2.61\n",
            "[6587 | 5548.42] loss=2.41 avg=2.61\n",
            "[6588 | 5550.11] loss=2.61 avg=2.61\n",
            "[6589 | 5551.81] loss=3.01 avg=2.61\n",
            "[6590 | 5553.50] loss=2.36 avg=2.61\n",
            "[6591 | 5555.20] loss=2.41 avg=2.60\n",
            "[6592 | 5556.89] loss=2.68 avg=2.61\n",
            "[6593 | 5558.58] loss=3.02 avg=2.61\n",
            "[6594 | 5560.28] loss=2.67 avg=2.61\n",
            "[6595 | 5561.98] loss=2.83 avg=2.61\n",
            "[6596 | 5563.68] loss=2.37 avg=2.61\n",
            "[6597 | 5565.38] loss=2.48 avg=2.61\n",
            "[6598 | 5567.07] loss=2.40 avg=2.61\n",
            "[6599 | 5568.76] loss=2.34 avg=2.60\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " Richmond.\n",
            "\t\\@ Aitken, Joseph (1851–1933) photo supplied by family\n",
            "\tTwo brothers, Joseph Aitken and Charles Aitken, a son, and his brother, Frank Aitken of Kew, of Sydney, died this morning aged 79 years.\n",
            "\tThe funeral, leaving St. Mark's Cathedral to-morrow afternoon for the Sydney Central Cemetery, will be closely watched.\n",
            "\tThe Rev. R. J. Hughes officiated at the grave. The service at the graveside was conducted by Father John Hughes, Kew, and will be held at 5.30 p.m.\n",
            "\t\\@ Lidstrach, Louis Henry (1846–1933) One of the original members of the A.F.C., and a brother-in-law, of the late Mr. Louis Lidstrach, passed away recently. Mr. Louis Lidstrach was born in London. The late Mr. Louis Lidstrach was the most versatile and highly developed of our commercial and industrial men. Mr. Louis Lidstrach was interested in banking, before he enlisted in the army. He enlisted in the 1st A.B.F., with £20 in his pocket. In 1906, he married Miss Elizabeth Maclure in London. He later managed the Bank of France, and in 1913 he became general manager and manager of the Melbourne branch of the Bank of New South Wales. Mr. Lidstrach was president of the First Melbourne Bank, which was merged into the Bank of Australia in 1932, and he became vice-president, in 1922. A member of the A.F.C, and for some years secretary, when he retired was at the Wellington branch. Mr. Lidstrach's business interests were broad-based, and he managed large and well known companies in Victoria and New South Wales. He was a member of the Melbourne Steamship Co., and later of the Wellington Steamship Co., a managing director of the Sydney Steam Navigation Co., and a director of the Melbourne & Melbourne Railroad Company. He had many friends in Europe and Australasia, and his works for others and his love of life are most inspiring. He leaves a widow and seven children to mourn their loss.\n",
            "\t\\@ Wightman, George (1864–1933) The death at Epping of Sir George Wightman, chairman of the New South Wales branch of the Royal Agricultural Society, and a member of the Australian royal family, has been a shock to the agricultural industry in the colony, as he was widely known in business circles. He was a son of the late Sir Frederick Wightman, who died in 1918, and was educated in England. He joined the Royal Agricultural Society in 1889, and entered practice in 1894. He was a most useful member of the society for his practical work, which he found stimulating. Some 17 years ago he retired from active work in the management of the British and Agricultural Insurance Company, in conjunction with his brother, William, and joined the New South Wales branch of the Royal Agricultural Society. Sir George Wightman, who had five sons, was a brother-in-law of the Earl of Cornwall, and a cousin of the Duchess of Cornwall. Sir George Wightman was a member of Parliament from 1911 until 1924, and twice Prime Minister. Since his retirement one of his sons, Mr. Edward Wightman, is director of the Royal Agricultural Society and headmaster of the Epping Primary School. The funeral will leave the residence of Mr. Frank Wightman, Epping, New South Wales, at 6.30 to-day for the Sydney Cemetery.\n",
            "\t\\@ Lefroy, Sir John (1874–1933) \n",
            "\t\\@ Govett, William (1868–1933) \n",
            "\tThe death of Mr. Govett, late of Paddington, from influenza, which occurred at the age of 71, took place on Sunday at his home, Gower, Victoria, where he was staying with his two sons. The deceased, who was educated at Ballina School, in the Hawkesbury district, was well known throughout the district. He had been ill four weeks. He leaves a widow and grown-up sons and daughters to mourn their loss.\n",
            "\t\\@ Aitken, Mary (1853–1933) Mrs. Aitken died on Saturday [9th May] after living to be 102 years of age. Surviving Mrs. O'Leary and Miss O. F. O'Leary were neighbours at the time of her death. She was buried at Woodcross Cemetery on the 10th May last.\n",
            "\t\\@ Lefroy, Francis John (1857–1933) The death occurred suddenly at his residence, Darling Point, to the family of Mr. Francis Lefroy, son of Mr. James de Lefroy, at noon on Tuesday of the following\n",
            "\n",
            "[6600 | 5593.16] loss=3.09 avg=2.61\n",
            "[6601 | 5594.84] loss=2.44 avg=2.61\n",
            "[6602 | 5596.52] loss=2.19 avg=2.60\n",
            "[6603 | 5598.21] loss=2.37 avg=2.60\n",
            "[6604 | 5599.89] loss=3.10 avg=2.61\n",
            "[6605 | 5601.57] loss=2.48 avg=2.60\n",
            "[6606 | 5603.25] loss=2.56 avg=2.60\n",
            "[6607 | 5604.92] loss=2.30 avg=2.60\n",
            "[6608 | 5606.60] loss=2.49 avg=2.60\n",
            "[6609 | 5608.28] loss=2.50 avg=2.60\n",
            "[6610 | 5609.96] loss=3.00 avg=2.60\n",
            "[6611 | 5611.64] loss=2.89 avg=2.61\n",
            "[6612 | 5613.33] loss=2.47 avg=2.60\n",
            "[6613 | 5615.01] loss=2.85 avg=2.61\n",
            "[6614 | 5616.69] loss=2.38 avg=2.60\n",
            "[6615 | 5618.37] loss=2.70 avg=2.61\n",
            "[6616 | 5620.05] loss=2.22 avg=2.60\n",
            "[6617 | 5621.73] loss=3.39 avg=2.61\n",
            "[6618 | 5623.41] loss=2.39 avg=2.61\n",
            "[6619 | 5625.09] loss=3.00 avg=2.61\n",
            "[6620 | 5626.78] loss=2.76 avg=2.61\n",
            "[6621 | 5628.46] loss=3.11 avg=2.62\n",
            "[6622 | 5630.14] loss=2.37 avg=2.62\n",
            "[6623 | 5631.83] loss=2.61 avg=2.62\n",
            "[6624 | 5633.51] loss=2.45 avg=2.61\n",
            "[6625 | 5635.19] loss=2.67 avg=2.61\n",
            "[6626 | 5636.87] loss=2.52 avg=2.61\n",
            "[6627 | 5638.55] loss=2.88 avg=2.62\n",
            "[6628 | 5640.24] loss=2.05 avg=2.61\n",
            "[6629 | 5641.91] loss=2.84 avg=2.61\n",
            "[6630 | 5643.59] loss=2.47 avg=2.61\n",
            "[6631 | 5645.27] loss=2.19 avg=2.61\n",
            "[6632 | 5646.95] loss=2.91 avg=2.61\n",
            "[6633 | 5648.64] loss=2.06 avg=2.60\n",
            "[6634 | 5650.33] loss=2.67 avg=2.61\n",
            "[6635 | 5652.01] loss=2.39 avg=2.60\n",
            "[6636 | 5653.72] loss=2.97 avg=2.61\n",
            "[6637 | 5655.40] loss=2.51 avg=2.61\n",
            "[6638 | 5657.09] loss=2.42 avg=2.60\n",
            "[6639 | 5658.77] loss=2.77 avg=2.61\n",
            "[6640 | 5660.46] loss=2.97 avg=2.61\n",
            "[6641 | 5662.14] loss=2.76 avg=2.61\n",
            "[6642 | 5663.84] loss=2.24 avg=2.61\n",
            "[6643 | 5665.53] loss=3.03 avg=2.61\n",
            "[6644 | 5667.22] loss=3.15 avg=2.62\n",
            "[6645 | 5668.91] loss=2.42 avg=2.61\n",
            "[6646 | 5670.60] loss=3.09 avg=2.62\n",
            "[6647 | 5672.29] loss=2.86 avg=2.62\n",
            "[6648 | 5674.00] loss=2.38 avg=2.62\n",
            "[6649 | 5675.69] loss=2.52 avg=2.62\n",
            "[6650 | 5677.38] loss=2.47 avg=2.62\n",
            "[6651 | 5679.09] loss=2.30 avg=2.61\n",
            "[6652 | 5680.78] loss=1.96 avg=2.61\n",
            "[6653 | 5682.48] loss=2.34 avg=2.60\n",
            "[6654 | 5684.17] loss=2.20 avg=2.60\n",
            "[6655 | 5685.86] loss=2.34 avg=2.60\n",
            "[6656 | 5687.56] loss=2.59 avg=2.60\n",
            "[6657 | 5689.26] loss=2.49 avg=2.60\n",
            "[6658 | 5690.96] loss=2.31 avg=2.59\n",
            "[6659 | 5692.64] loss=2.95 avg=2.60\n",
            "[6660 | 5694.34] loss=2.51 avg=2.60\n",
            "[6661 | 5696.04] loss=2.56 avg=2.60\n",
            "[6662 | 5697.75] loss=2.37 avg=2.59\n",
            "[6663 | 5699.45] loss=2.78 avg=2.60\n",
            "[6664 | 5701.15] loss=2.96 avg=2.60\n",
            "[6665 | 5702.85] loss=3.45 avg=2.61\n",
            "[6666 | 5704.55] loss=2.42 avg=2.61\n",
            "[6667 | 5706.25] loss=2.33 avg=2.60\n",
            "[6668 | 5707.96] loss=2.65 avg=2.60\n",
            "[6669 | 5709.66] loss=2.76 avg=2.61\n",
            "[6670 | 5711.36] loss=2.38 avg=2.60\n",
            "[6671 | 5713.06] loss=2.95 avg=2.61\n",
            "[6672 | 5714.76] loss=2.82 avg=2.61\n",
            "[6673 | 5716.46] loss=2.61 avg=2.61\n",
            "[6674 | 5718.17] loss=2.14 avg=2.60\n",
            "[6675 | 5719.86] loss=2.64 avg=2.60\n",
            "[6676 | 5721.57] loss=2.53 avg=2.60\n",
            "[6677 | 5723.27] loss=2.96 avg=2.61\n",
            "[6678 | 5724.98] loss=2.62 avg=2.61\n",
            "[6679 | 5726.67] loss=2.28 avg=2.60\n",
            "[6680 | 5728.37] loss=3.01 avg=2.61\n",
            "[6681 | 5730.08] loss=2.36 avg=2.61\n",
            "[6682 | 5731.78] loss=3.04 avg=2.61\n",
            "[6683 | 5733.48] loss=2.82 avg=2.61\n",
            "[6684 | 5735.18] loss=2.57 avg=2.61\n",
            "[6685 | 5736.88] loss=2.43 avg=2.61\n",
            "[6686 | 5738.59] loss=2.77 avg=2.61\n",
            "[6687 | 5740.29] loss=2.05 avg=2.61\n",
            "[6688 | 5742.00] loss=2.84 avg=2.61\n",
            "[6689 | 5743.70] loss=2.15 avg=2.60\n",
            "[6690 | 5745.40] loss=2.80 avg=2.61\n",
            "[6691 | 5747.10] loss=2.49 avg=2.60\n",
            "[6692 | 5748.80] loss=2.39 avg=2.60\n",
            "[6693 | 5750.51] loss=2.20 avg=2.60\n",
            "[6694 | 5752.20] loss=2.20 avg=2.59\n",
            "[6695 | 5753.91] loss=2.62 avg=2.59\n",
            "[6696 | 5755.61] loss=2.45 avg=2.59\n",
            "[6697 | 5757.31] loss=2.30 avg=2.59\n",
            "[6698 | 5759.01] loss=2.14 avg=2.59\n",
            "[6699 | 5760.71] loss=2.53 avg=2.58\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " and in 1857 acquired the lands he had purchased about the year 1773. During his lifetime he had been a resident of Sydney for sixty years, and his home was known for generations to the first settlers who came to it. It is now little better, with the exception of a short visit on the death of his son, but it was a grand and delightful house, which was built over half a league of country between the two towns of Parramatta and Parramatta. It was a handsome house of timber and of stone, handsomely built, and was built at a time when only a little more than a third of the whole of the new colonies were so far advanced, and the work done on even a small part of that country is so long and labouring. On its foundation it took up about four miles of country, and by the present distance of one hundred miles, it was of considerable value. Mr. Oram, his son in the deceased gentleman's company, is a descendant of one of the original settlers, having come to Sydney at the beginning of the settlement in the New South Wales, where his great-grandfather arrived in 1796. The deceased married several of the daughters of that celebrated pioneer female poetess, Miss Frances Scott, whose last words were \"a little wind, but it will go away.\"\n",
            "\t\\@ Hughes, Thomas Alfred (1836–1870) One day in August last a friend of ours, Mr. J. S. O'Farrell, received notice by telegraph to the effect that he was to see Mr. Thomas Hughes, Esq., at \"Maitland.\" He arrived at Sydney on the 28th August, and he has remained there ever since, his health not failing. Deceased was a son of Mr. Coughlan Hughes, and died some eight years ago; his other son, Messrs. Thomas Hughes, Esq., and William Hughes, Esq., were members of his family, although deceased had not been a resident of the colony for a great length of time. Deceased will be remembered as the first solicitor for Sydney and Parramatta in the district, who has never been short of a welcome. Since his death his estate has been given to Sir H. G. R. Hughes for his daughter who is married to Mr. E. S. Hughes, the Hon. S. G. Hughes, Esq., and his wife who is Miss Hughes. The funeral will be in St. Matthew's Church of England Cemetery, St. James' Street, at 3 o'clock on Thursday morning.\n",
            "\t\\@ Bremner, Alfred (1841–1870) Mrs. Bremner, a native of Ireland, with three brothers, Mr. Frederick Bremner (who is well known in Northam,) Mr. R. S. Bremner, and Mr. Frederick Bremner Bremner, of Sydney, has gone to England by way of Australia, and from thence travelled over land to Sydney. She then proceeded via London to England, then by way of France, and thence back again. She arrived at Sydney some four months ago, and has left with her children a few months ago. The funeral will be private with instructions to call at her residence when it arrives at Windsor. The late Mrs. Bremner was a very fine woman for her time, and was well liked by all classes of the people—especially by the Jews of Sydney. Her character and her talents will long be honoured.\n",
            "\t\\@ Nunn, George H. (1851–1870) \n",
            "\t\\@ Stokes, J. R. (1835–1870) At his residence there passed away on Monday a very well-known figure on the Hawkesbury, Mrs. J. R. Stokes who was 88 years of age. Her husband died in his seventy-first year. The deceased lady had been ailing for some time and is in the prime of life. She leaves behind a large family in England, two daughters having already married in the Hawkesbury, and one son, Mr. L. L. Lathrop Stokes, residing at Streatham.\n",
            "\t\\@ Gairdner, Robert James (1795–1870) \n",
            "\tThe people of the Hawkesbury district have been pleased to reflect on the death last week of his deceased Majesty's second son, Robert James Gairdner, Esq., and other of the leading men in the Hawkesbury district. The late Sir Henry St. Aubyn, C.M.G.; Sir A. W. Macintyre, F.R., M.C.; Major-General Sir A. H. Macpherson, M.L.C., M.S.G.; Sir William Macleod, M.L.C.; Mr. C. S. Laidley, M.A.; Mr. H. A. MacLellan, M.M\n",
            "\n",
            "[6700 | 5784.72] loss=3.00 avg=2.59\n",
            "[6701 | 5786.39] loss=2.28 avg=2.59\n",
            "[6702 | 5788.07] loss=2.23 avg=2.58\n",
            "[6703 | 5789.74] loss=2.43 avg=2.58\n",
            "[6704 | 5791.41] loss=2.43 avg=2.58\n",
            "[6705 | 5793.08] loss=2.95 avg=2.58\n",
            "[6706 | 5794.76] loss=2.53 avg=2.58\n",
            "[6707 | 5796.42] loss=2.95 avg=2.59\n",
            "[6708 | 5798.09] loss=2.47 avg=2.59\n",
            "[6709 | 5799.76] loss=2.60 avg=2.59\n",
            "[6710 | 5801.44] loss=2.98 avg=2.59\n",
            "[6711 | 5803.10] loss=2.40 avg=2.59\n",
            "[6712 | 5804.76] loss=2.27 avg=2.58\n",
            "[6713 | 5806.45] loss=2.73 avg=2.59\n",
            "[6714 | 5808.13] loss=2.90 avg=2.59\n",
            "[6715 | 5809.79] loss=2.37 avg=2.59\n",
            "[6716 | 5811.47] loss=3.04 avg=2.59\n",
            "[6717 | 5813.16] loss=3.01 avg=2.60\n",
            "[6718 | 5814.83] loss=2.21 avg=2.59\n",
            "[6719 | 5816.52] loss=2.95 avg=2.59\n",
            "[6720 | 5818.21] loss=3.10 avg=2.60\n",
            "[6721 | 5819.90] loss=2.29 avg=2.60\n",
            "[6722 | 5821.59] loss=2.89 avg=2.60\n",
            "[6723 | 5823.28] loss=3.05 avg=2.60\n",
            "[6724 | 5824.99] loss=2.93 avg=2.61\n",
            "[6725 | 5826.68] loss=2.55 avg=2.61\n",
            "[6726 | 5828.38] loss=2.77 avg=2.61\n",
            "[6727 | 5830.08] loss=2.43 avg=2.61\n",
            "[6728 | 5831.79] loss=2.60 avg=2.61\n",
            "[6729 | 5833.49] loss=2.40 avg=2.60\n",
            "[6730 | 5835.19] loss=2.52 avg=2.60\n",
            "[6731 | 5836.90] loss=3.20 avg=2.61\n",
            "[6732 | 5838.60] loss=2.67 avg=2.61\n",
            "[6733 | 5840.30] loss=2.71 avg=2.61\n",
            "[6734 | 5842.01] loss=2.22 avg=2.61\n",
            "[6735 | 5843.71] loss=2.89 avg=2.61\n",
            "[6736 | 5845.41] loss=2.79 avg=2.61\n",
            "[6737 | 5847.10] loss=2.71 avg=2.61\n",
            "[6738 | 5848.80] loss=3.19 avg=2.62\n",
            "[6739 | 5850.50] loss=2.41 avg=2.62\n",
            "[6740 | 5852.20] loss=2.36 avg=2.61\n",
            "[6741 | 5853.90] loss=2.97 avg=2.62\n",
            "[6742 | 5855.60] loss=2.76 avg=2.62\n",
            "[6743 | 5857.29] loss=2.17 avg=2.61\n",
            "[6744 | 5858.98] loss=2.11 avg=2.61\n",
            "[6745 | 5860.68] loss=2.53 avg=2.61\n",
            "[6746 | 5862.36] loss=3.09 avg=2.61\n",
            "[6747 | 5864.04] loss=2.67 avg=2.61\n",
            "[6748 | 5865.72] loss=2.99 avg=2.62\n",
            "[6749 | 5867.40] loss=2.71 avg=2.62\n",
            "[6750 | 5869.08] loss=2.45 avg=2.62\n",
            "[6751 | 5870.75] loss=2.09 avg=2.61\n",
            "[6752 | 5872.44] loss=1.94 avg=2.61\n",
            "[6753 | 5874.12] loss=2.65 avg=2.61\n",
            "[6754 | 5875.80] loss=2.51 avg=2.60\n",
            "[6755 | 5877.47] loss=2.16 avg=2.60\n",
            "[6756 | 5879.15] loss=2.58 avg=2.60\n",
            "[6757 | 5880.83] loss=2.51 avg=2.60\n",
            "[6758 | 5882.52] loss=2.53 avg=2.60\n",
            "[6759 | 5884.22] loss=3.14 avg=2.60\n",
            "[6760 | 5885.91] loss=2.29 avg=2.60\n",
            "[6761 | 5887.60] loss=3.33 avg=2.61\n",
            "[6762 | 5889.29] loss=2.42 avg=2.61\n",
            "[6763 | 5890.98] loss=2.69 avg=2.61\n",
            "[6764 | 5892.68] loss=2.73 avg=2.61\n",
            "[6765 | 5894.37] loss=2.56 avg=2.61\n",
            "[6766 | 5896.07] loss=2.44 avg=2.61\n",
            "[6767 | 5897.78] loss=2.90 avg=2.61\n",
            "[6768 | 5899.48] loss=2.58 avg=2.61\n",
            "[6769 | 5901.17] loss=2.55 avg=2.61\n",
            "[6770 | 5902.88] loss=2.26 avg=2.60\n",
            "[6771 | 5904.58] loss=3.15 avg=2.61\n",
            "[6772 | 5906.28] loss=2.56 avg=2.61\n",
            "[6773 | 5907.98] loss=3.09 avg=2.61\n",
            "[6774 | 5909.69] loss=2.76 avg=2.62\n",
            "[6775 | 5911.39] loss=3.39 avg=2.62\n",
            "[6776 | 5913.08] loss=2.45 avg=2.62\n",
            "[6777 | 5914.79] loss=2.90 avg=2.62\n",
            "[6778 | 5916.49] loss=2.62 avg=2.62\n",
            "[6779 | 5918.19] loss=2.80 avg=2.63\n",
            "[6780 | 5919.90] loss=3.03 avg=2.63\n",
            "[6781 | 5921.59] loss=2.38 avg=2.63\n",
            "[6782 | 5923.30] loss=2.65 avg=2.63\n",
            "[6783 | 5925.00] loss=2.40 avg=2.63\n",
            "[6784 | 5926.70] loss=2.31 avg=2.62\n",
            "[6785 | 5928.41] loss=2.23 avg=2.62\n",
            "[6786 | 5930.11] loss=3.04 avg=2.62\n",
            "[6787 | 5931.81] loss=2.08 avg=2.62\n",
            "[6788 | 5933.51] loss=2.81 avg=2.62\n",
            "[6789 | 5935.20] loss=2.70 avg=2.62\n",
            "[6790 | 5936.91] loss=2.29 avg=2.62\n",
            "[6791 | 5938.59] loss=2.59 avg=2.62\n",
            "[6792 | 5940.29] loss=2.05 avg=2.61\n",
            "[6793 | 5941.99] loss=2.74 avg=2.61\n",
            "[6794 | 5943.69] loss=2.25 avg=2.61\n",
            "[6795 | 5945.39] loss=2.10 avg=2.60\n",
            "[6796 | 5947.10] loss=3.19 avg=2.61\n",
            "[6797 | 5948.80] loss=2.76 avg=2.61\n",
            "[6798 | 5950.50] loss=3.35 avg=2.62\n",
            "[6799 | 5952.20] loss=2.72 avg=2.62\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " despite some criticism of his actions, and was appointed a trustee to the National Health Service in 1967.In 1971, he was appointed the senior health adviser to President Nixon. But, as a result of Nixon's decision to bomb Cambodia in August of that year, Kerr was removed from the position, and his services were returned to the National Health office.In 1976 (and again in 1982), Kerr worked on the restructuring of the National Health Service and became health adviser to the Prime Minister of the newly elected United States of America.In 1983 he worked on the reorganisation of the Health Services Division of the Department of Health, and joined the National Health and Medical Research Council in 1974.In 1986 he was appointed the joint deputy director general of the National Health and Medical Research Council when it was renamed the National Health Research Institute (NHRI).In the early 1990s, he continued in the post of Health Adviser to the Prime Minister of Australia and to the US President, George H W Bush. In September 2006 he was appointed to the new position of health adviser to the President of New Zealand, Sir John Gorton.Kerr was appointed a Fellow of the Royal Society in 1997.He also made several high-profile trips to India, Indonesia and China, where he was to conduct medical investigations with Chinese medical advisers, and was a consultant to the Royal Chinese Society.Kerr's death in August 2011 came after a long battle with cancer. He was born Robert Kenneth Kerr, on March 20, 1930, and was the eldest son of a Presbyterian minister, Charles Kerr, and a nurse, Margaret Kerr. He went to the Sydney Grammar School, where he became a very good football player. He was also a star athlete, winning a scholarship to a Melbourne Grammar School. He finished with 33 games to his name, including 17 to his football team's nine in his senior year, four in football and eight in rugby.At the end of a football career that stretched over 44 years, Kerr retired in 1969 at the age of 36. He went into business as an investment banker, managing investment funds for companies. He also founded his own insurance business, which he retained until 1996. In 2001 he returned to business as a consultant to the Health and Medical Research Council, but it was not until 2001 (after being diagnosed with breast cancer) and two years later (after having a tumour removed) that he decided he wanted to make medical history. He returned to the health and medical research profession in 2003.At that time, he was appointed National Health Officer (NHO), and in June 2004, he also was appointed Health and Medical Research Foundation of Australia (HKMA), an organisation that is credited with helping to ensure global health through funding of medical research and the development of new therapies.Kerr, who was 79 at the time of his death, was a committed social worker, and an extremely bright and ambitious man - and a great man. His wife of 64 years, Maureen, has eight children, his brother, Peter, is now the Chief Executive of the Australian Medical Association.\n",
            "\t\\@ Garside, George (Jack) (1948–2011) \n",
            "\tGeorge Garside was born in Melbourne and was educated at the Melbourne Grammar School. During the 1950s and early 1960s he taught music at St Kilda Grammar School, then was appointed to the school's music department in 1969, with a year to go he was appointed principal of St Kilda Boys High School. He remained at St Kilda until his retirement in 2001. He also attended the University of Melbourne School of Music where he studied for his GED. He studied under the legendary saxophonist, Dr. John Beale. In 1972 he was appointed instructor of music, after obtaining his B.A. and M.B.A. in music at the University of Melbourne. He also became a senior research and teaching assistant for the School of Advanced Studies. A year after becoming an associate of the School of Advanced Studies, his father, Dr. George Garside, received the Distinguished Service Order in recognition of his achievements. He made an unsuccessful bid for Parliament in 1975 and was defeated by Dr. David Fagan. \n",
            "\tIn 1981, Dr. John Beale offered the Garside son an appointment as a research fellow at the University of Victoria where he studied to be a Ph.D. He became an honorary lecturer of music with the University of Melbourne following his graduation in 1986. He also trained as a teacher, later returning to the University of Melbourne to work as a student teacher. In 1996 Mr. Garside was awarded the ERC Medal for academic achievement for his dissertation on music in a university. He also became a Fellow of the Royal College of Music and the Institute of Music in 1987.\n",
            "\tMr. Garside leaves a special bond with his sons, his son Harry, now the manager of the Melbourne Music Academy, also an arts and craftsman. Mr. Garside was also an avid member of the Melbourne\n",
            "\n",
            "[6800 | 5976.33] loss=2.95 avg=2.62\n",
            "[6801 | 5978.01] loss=2.55 avg=2.62\n",
            "[6802 | 5979.69] loss=2.38 avg=2.62\n",
            "[6803 | 5981.37] loss=2.23 avg=2.62\n",
            "[6804 | 5983.05] loss=2.57 avg=2.62\n",
            "[6805 | 5984.73] loss=3.05 avg=2.62\n",
            "[6806 | 5986.41] loss=2.82 avg=2.62\n",
            "[6807 | 5988.08] loss=2.32 avg=2.62\n",
            "[6808 | 5989.75] loss=2.77 avg=2.62\n",
            "[6809 | 5991.43] loss=2.52 avg=2.62\n",
            "[6810 | 5993.10] loss=1.95 avg=2.61\n",
            "[6811 | 5994.77] loss=2.60 avg=2.61\n",
            "[6812 | 5996.45] loss=3.21 avg=2.62\n",
            "[6813 | 5998.13] loss=2.68 avg=2.62\n",
            "[6814 | 5999.80] loss=2.32 avg=2.62\n",
            "[6815 | 6001.48] loss=2.81 avg=2.62\n",
            "[6816 | 6003.17] loss=2.88 avg=2.62\n",
            "[6817 | 6004.85] loss=2.15 avg=2.62\n",
            "[6818 | 6006.54] loss=2.20 avg=2.61\n",
            "[6819 | 6008.23] loss=2.63 avg=2.61\n",
            "[6820 | 6009.92] loss=3.01 avg=2.62\n",
            "[6821 | 6011.61] loss=2.65 avg=2.62\n",
            "[6822 | 6013.31] loss=2.88 avg=2.62\n",
            "[6823 | 6015.01] loss=3.09 avg=2.62\n",
            "[6824 | 6016.72] loss=2.50 avg=2.62\n",
            "[6825 | 6018.41] loss=2.76 avg=2.62\n",
            "[6826 | 6020.11] loss=2.52 avg=2.62\n",
            "[6827 | 6021.80] loss=2.20 avg=2.62\n",
            "[6828 | 6023.51] loss=2.21 avg=2.61\n",
            "[6829 | 6025.21] loss=2.69 avg=2.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS1RJJDFOPnb"
      },
      "source": [
        "Save our checkpoints to start training again later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JretqG1zOXdi"
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/ /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D-i7vERWbNS"
      },
      "source": [
        "Load your trained model for use in sampling below (117M or 345M)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeETvWvrbKga"
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/117M/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np0r6qfXBeUX"
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/345M/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmnSrXqtfRbq"
      },
      "source": [
        "Generate conditional samples from the model given a prompt you provide -  change top-k hyperparameter if desired (default is 40),  if you're using 345M, add \"--model-name 345M\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJj-iY4gHwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8add2f64-a9dd-4d94-8129-135b10680704"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 40 --model_name \"345M\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 00:38:59.198956 140564883507072 deprecation_wrapper.py:119] From /content/gpt-2/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0904 00:38:59.291688 140564883507072 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:55: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-09-04 00:38:59.293412: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-04 00:38:59.312397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:38:59.313183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-04 00:38:59.313431: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-04 00:38:59.314843: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-04 00:38:59.316003: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-04 00:38:59.316337: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-04 00:38:59.317878: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-04 00:38:59.318918: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-04 00:38:59.322573: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-04 00:38:59.322723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:38:59.323479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:38:59.324193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-04 00:38:59.329676: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-09-04 00:38:59.330010: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x329d2c0 executing computations on platform Host. Devices:\n",
            "2019-09-04 00:38:59.330043: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-04 00:38:59.386273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:38:59.387126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x329d480 executing computations on platform CUDA. Devices:\n",
            "2019-09-04 00:38:59.387171: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-09-04 00:38:59.387352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:38:59.388070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-04 00:38:59.388136: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-04 00:38:59.388165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-04 00:38:59.388190: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-04 00:38:59.388215: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-04 00:38:59.388241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-04 00:38:59.388266: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-04 00:38:59.388292: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-04 00:38:59.388393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:38:59.389141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:38:59.389795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-04 00:38:59.389875: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-04 00:38:59.391394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-04 00:38:59.391424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-04 00:38:59.391437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-04 00:38:59.391578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:38:59.392383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:38:59.393074: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-04 00:38:59.393132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0904 00:38:59.394089 140564883507072 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0904 00:38:59.396733 140564883507072 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0904 00:38:59.400077 140564883507072 deprecation_wrapper.py:119] From /content/gpt-2/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0904 00:39:08.048786 140564883507072 deprecation.py:323] From /content/gpt-2/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0904 00:39:08.065386 140564883507072 deprecation.py:323] From /content/gpt-2/gpt-2/src/sample.py:16: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0904 00:39:08.067396 140564883507072 deprecation.py:323] From /content/gpt-2/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "W0904 00:39:08.078808 140564883507072 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:66: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0904 00:39:08.549282 140564883507072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Model prompt >>> \\@ \n",
            "2019-09-04 00:39:22.374294: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            "~~~//~~~/~~~//~~~//~/~~~//~~~/~~~~~~~~//~~~//~~~//~~~//~~~~~~/~~~~~~/~~~~~~//~~~//~~~//~~~~~~~/~~~~~~/~~~~~~/~~~~~~/~~~~~~//~~~//~~~//~~~~~~//~~~//~~~//~~~/~~~~~~/~~~~~~//~~~//~~~//~~~//~~~/~~~~~~/~~~~~~//~~~//~~~//~~~/~~~~~~/~~~~~~/~~~~~~//~~~//~~~//~~~/~~~~~~/~~~~~~/~~~~~~//~~~//~~~//~~~//~~~//~~~/~/*=======================================================*//~/ [12] \"Fault tolerance\" is the tolerance for errors due to the existence of a system within the system. This can affect the system's behavior or cause its existence to be discovered. Fault tolerance is defined by the following formula which is a function of the severity of the system error, whether it can be completely eliminated, and whether there is any attempt at repair within the system. /= -[0-3]/ The above formula gives a tolerance of -1, which means that for any error greater than 3 it can be considered impossible to fix it. This limit becomes a point of comparison when discussing the system's \"performance\" or \"safety\". An error on its own will cause the system to fail very soon, but it can occur within a normal operation under normal conditions or within a situation where some element of the software fails completely that would otherwise cause failure (for example if a system is designed to be fault tolerant and it fails because a fault appears while the software is executing on some server). This could mean that the software has already failed within the previous operation and it is necessary to create a re-order to restore functionality by manually checking for errors before trying to restore functionality. By using the \"fault tolerance\" formula it is also possible to determine that an error within the system really did happen, while other errors caused by other elements are simply due to bad luck (or some aspect of programming). *NOTE:* For most operations requiring some level of reliability beyond a very high tolerance, the system will probably perform perfectly, but as long as there are errors and they cause failures, the system was probably not as robust as expected. This kind of accident can easily cost billions, and if that\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 5652, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 71, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 89, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 86, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1618, in __exit__\n",
            "    close_thread.start()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 851, in start\n",
            "    self._started.wait()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeDhY97XMDXn"
      },
      "source": [
        "To check flag descriptions, use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBaj2L_KMAgb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "af647192-e6dc-4fe3-a37e-d7a8bf4a6b51"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py -- --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0903 15:49:18.644938 139822344439680 deprecation_wrapper.py:119] From /content/gpt-2/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "\u001b[1mNAME\u001b[0m\n",
            "    interactive_conditional_samples.py - Interactively run the model :model_name=117M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=1 : Number of samples to return total :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples. :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling, overriding top_k if set to a value > 0. A good setting is 0.9.\n",
            "\n",
            "\u001b[1mSYNOPSIS\u001b[0m\n",
            "    interactive_conditional_samples.py <flags>\n",
            "\n",
            "\u001b[1mDESCRIPTION\u001b[0m\n",
            "    Interactively run the model :model_name=117M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=1 : Number of samples to return total :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples. :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling, overriding top_k if set to a value > 0. A good setting is 0.9.\n",
            "\n",
            "\u001b[1mFLAGS\u001b[0m\n",
            "    --model_name=\u001b[4mMODEL_NAME\u001b[0m\n",
            "    --seed=\u001b[4mSEED\u001b[0m\n",
            "    --nsamples=\u001b[4mNSAMPLES\u001b[0m\n",
            "    --batch_size=\u001b[4mBATCH_SIZE\u001b[0m\n",
            "    --length=\u001b[4mLENGTH\u001b[0m\n",
            "    --temperature=\u001b[4mTEMPERATURE\u001b[0m\n",
            "    --top_k=\u001b[4mTOP_K\u001b[0m\n",
            "    --top_p=\u001b[4mTOP_P\u001b[0m\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8rSqkGxg5OK"
      },
      "source": [
        "Generate unconditional samples from the model,  if you're using 345M, add \"--model-name 345M\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaQUEnRxWc3c",
        "outputId": "1101c953-3a18-4839-f68e-1407fa714f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 src/generate_unconditional_samples.py --model_name \"345M\" | tee /tmp/samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 00:39:56.692107 140067729090432 deprecation_wrapper.py:119] From /content/gpt-2/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0904 00:39:56.783232 140067729090432 deprecation_wrapper.py:119] From src/generate_unconditional_samples.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-09-04 00:39:56.784858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-04 00:39:56.802736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:39:56.803459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-04 00:39:56.803737: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-04 00:39:56.805023: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-04 00:39:56.806164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-04 00:39:56.806504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-04 00:39:56.808267: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-04 00:39:56.809366: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-04 00:39:56.812725: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-04 00:39:56.812894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:39:56.813633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:39:56.814236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-04 00:39:56.819666: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-09-04 00:39:56.819895: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16cd2c0 executing computations on platform Host. Devices:\n",
            "2019-09-04 00:39:56.819929: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-04 00:39:56.863940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:39:56.864750: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16cd480 executing computations on platform CUDA. Devices:\n",
            "2019-09-04 00:39:56.864780: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-09-04 00:39:56.864950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:39:56.865803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-04 00:39:56.865862: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-04 00:39:56.865889: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-04 00:39:56.865911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-04 00:39:56.865933: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-04 00:39:56.865969: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-04 00:39:56.866005: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-04 00:39:56.866028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-04 00:39:56.866111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:39:56.866880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:39:56.867486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-04 00:39:56.867540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-04 00:39:56.869015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-04 00:39:56.869044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-04 00:39:56.869056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-04 00:39:56.869193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:39:56.870015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-04 00:39:56.870605: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-04 00:39:56.870668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0904 00:39:56.871755 140067729090432 deprecation_wrapper.py:119] From src/generate_unconditional_samples.py:54: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0904 00:39:56.878765 140067729090432 deprecation_wrapper.py:119] From /content/gpt-2/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0904 00:39:56.879852 140067729090432 deprecation_wrapper.py:119] From /content/gpt-2/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0904 00:40:04.126527 140067729090432 deprecation.py:323] From /content/gpt-2/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0904 00:40:04.128859 140067729090432 deprecation.py:323] From /content/gpt-2/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "W0904 00:40:04.143092 140067729090432 deprecation_wrapper.py:119] From src/generate_unconditional_samples.py:63: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0904 00:40:04.416062 140067729090432 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-09-04 00:40:08.853277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            "A government-appointed inquiry into the impact of proposed coal combustion-fired power stations on regional public health has been launched by Environment Canada.\n",
            "\n",
            "\"After nearly 30 years of designing and building these vill or buildings, I married them with government subsidies and unemployment insurance rights,\" said Audrey Dumler, an actress who gave birth to the Pussycat Doll Princess 500 month ago. \"I said that has to stop. Now is my chance to regain my health.\"\n",
            "\n",
            "Dr. Ian Savage, manager of Cigarette Party varieties and Metalworker Belongs Now (BMAL) has said existing Robensham Power Station coal power station operations are a clear example of dangerous underdevelopment. Interviews with 276 residents and 209 residents requesting access to the nearby Environmental Health Network (EHN) showed dangerous smoke emanating from survey sites in nearby Waters Edge.\n",
            "\n",
            "In March 2011, Savage published information on the health hazards posed by Robensham Power Station fire large quantities of which proved resistant to redeveloping after they were discovered by the EHN. That information led the federally-appointed Industrial Health and Safety Task Force to issue an update dramatically expanding activity limits on the projects – an unprecedented proposed redirection of development plans.\n",
            "\n",
            "Beyond Day-In-Day Out\n",
            "\n",
            "The standby stock of Robensham assets sold to the private sector aboard the flagship of the merged Hazelwood-Edmonton export-based Hazelwood utility today has a loading capacity of about 11 billion cubic feet per year, valued at approximately $400 million with $185 million exemption of the bank for striking price agreements.\n",
            "\n",
            "Over the next several years, 2.4 BMG Boker equivalent coal power plants will form part of its recently imposed standby loadings of 1.23 BMG Boker coal power, 831 b/d diesel electrical generation locations, six stores of Walgreens, four Hobby Bodies Chemical, 54 PHE gas water stations and 26 hard cocktails suppliers. This would represent a changing landscape for health amongst the setting of EHN disaster modeling data so far. The ALP (alternative to centralized disease care coalition) health care website is set to roll out in October 2013 and touted improved databases for planning and contractor responsibilities are expected to meet external guidance.\n",
            "\n",
            "The Health Divide\n",
            "\n",
            "As cigarette smokers hide under the trees, makes competition top animal for coal's survival in China, it is equally destructive to public health into which smoke drifts from newly built combustion and stored extended stacks. Skin cancer blows out of the blue after Lancers close their proposed lake woodshoe by 20 yen per ounce – a 60 percent increase from 2008's price. The real body horrors begin with head wound tumours comparable in severity to statewide effects reported to time Moreland Health in 2003 among 314 overdoses related to Draeger Kruskal vanilla pod standardized 36 jorph Lindahl gums, an, estimated by one year. The consultation solid-fee of cash for additional serious injuries centers 1990 for 2500 residents. 2012 for partial/heavy inhalation deaths, usually in pulmonary edema followed by focal biliary cirrhosis and frequent which, despite the 692 pages of now brand EHN reports that are also updated every week, there still is no clear consensus among commissioners. Gear up, Calloss et al. Canada. July. Dr. J's review of hospital docs. found one in four sought antihistamines in sports American Medical Association publishes Educational Impact of Proposed New Electric Forest Dr. Gordenx chair of Fossil Fort Read cause report written 'on fossil fuels' Dr. Goose calls input 'imposed lifelong'. Canada Horn of Plenty Kills endangered seals eating $175 million of walruses. Edmund Skonal retains royal interest in structuring steaming Thames River fen toll would be latest national health talky produced. Tell the news ... Peter Mittleman, Alternatives Publishing Comme des Garçons briefs web stream Tara Guest is MP for megafin providing counselling to local public school children after limb amputations who had ethically been covered by era via ladder. Local health organ of Babes to Promise Awards. 12 August 2012.\n",
            "\n",
            "Particularly discomforting about the present buzzword is the kicker: nothing. Planning cannot regret local protests against Robensham's plans due to sleep disturbance pain. As if member is only one of 8 MILLION active events across the nation including user, two rallies for peoples participation.\n",
            "\n",
            "Bronto is sub 2ml pnm. As is the Chinese in 'helping Prayer sincerely', nutrients,,lessly mutquiddity once 422 fuel related and evidenced Urananol which treatments Condor health deficientogne rat liver. Either this is why very obvious sounds in GTA oils have been shut down from March to December 2012-- preventing butter temperatures on today's economy scorching Pork embryos incur promise hay Fall salts or Cas ($ %.negroloma, STUD TECH. GRAIN MONOGRAM 27R ) Mongolia was the Roberto Jona centres of prize sprinters Brazil's Peacock bress price riveted US smoking control energized grants Tet Bo stealth\n",
            "======================================== SAMPLE 2 ========================================\n",
            "The page you contract to link against is nothing more or less than garbage; now that we're super-secure, is anyone able to find anything similar? Is \"Really Useful Knowledge\" livable? Technically?\n",
            "\n",
            "From a mediaeval point of view, \"basic income\" referred not so much to a guaranteed income to help out for indigent citizens (or so the library used to tell of course), but to the social cap on mobility taken as universal and impersonal liability for the eco-climate of an economy running on…means-test currencies!\n",
            "\n",
            "To Bob:\n",
            "\n",
            "\"You shouldn't tell me anything about your personal impact on the state of western civilization, Bob Chesterton, without explaining it. He means 'the manifold relationship of opportunity and discrimination. Discrimination is fat on the scale of minimal reward'. So to harm that, you're intentionally diminishing recognition of the oppression arising from the total elimination of necessary and intrinsic advantage.\"\n",
            "\n",
            "This throwaway inquiry pretty well read me out of boredom. Karl Marx or Franz Boas? It may sound veer-flung from Marxism's conception of capital as economic care or utility to hear them speak by way of interpersonal value-association, and please close the IF qualify box before..okay? \"We of the class-struggle know opponents poor and stupid men heredityetically made Irish commit intemperate acts of rape to yield uncure and unrecoverable diseases,\" and we of the class-struggle realize part of our identity is that it means threatening systemic status as his skills man each other until public safety vaults us to sing festivities. And who better than masters at stirring candidates to pat hate into their controlled descendants for you to focus your anger 20-somethings base your sentiment on? Good luck explaining how intellectually rich, idiotic, and distinctive a voluble polous in aesthetic philosophy might be by way of Scandinavian-roommate security and surveillance than someone glancing back land-mine-proof fancy skiing around wilderness long enough to point it out (Alice Walker if she weren't galling the wisdombox with transportation attendations where kvetching about food, shelter, fresh air, and knowledge somehow results in dressing tails), but no discretion is hurt love…no freedom. You could go on the offensive against bigotry, love, suffering, incompetence, state state–social stratification, vileness of the natural world, homelessness, convince me people care something about anything. For me, you degenerate herastaphan And rational lamentations toward its Me leave. Bad concepts, plain and simple. Nothing have led my mind farther toward creative storytelling of colour, innovation sounds like an established business in Denmark out of nowhere, somone has the Siri intelligencer Woobsle suspected expensive job auditor Charlene Legrainori severe privation to vilify you as a Stasi traitor-punch. Tourists on the beaches of Our New, Noble Land at work. cdcanceLL&Jerry jacklousSEanyrollingwithMusminover)probably right. To the libertarian architect as I think most readers with one's roots in \"led by inspiration\" think, your merely misanthropy has been you can never prove that illiberal government is actualhame is no idea help popularize the minimum challenge facilitated by public power and irn-empire. An extensive chilling of the confidence free/niroblegather's revolt platitude commends Demon Boost if urged for career development, human tech projection, foreign trade, establishment services selection, telling arta of working, we transplanted Wise Woman Glen even hostile Reuters Pressroom, when Sauron will mislead you they've turned the back on solid wisdom manifested evidenced only whileplaying to Condemnation by game being conducted simultaneously with gambler shouting Football and Alpha Social Movements protesting under the effused soul-fraud Freewheel Chomsky proclaimed on Supreme why Big About na can helped you them starts here and can't wow for having a child mood seems Impaired Anti Social Compromises overseen by Diplomacy gamer Vox Populi knee crabs player Tribal Sobriety restraint and moral direction poisoned cards5 with Zone VR aspect of symbol ponders stupid deserts heres your previous \"gathering companions\" splendor exceeding his limits frame-control lasts 20sec good for deterrence and refreshing passes on moderate internet Listenability fostered Delusions mirror thoughts of intimacy Staying calm and logical restrained in His teacherical problems 724\n",
            "\n",
            "Møller\n",
            "\n",
            "\n",
            "Offline\n",
            "\n",
            "\n",
            "Activity: 107\n",
            "\n",
            "Merit: 10\n",
            "\n",
            "\n",
            "MemberActivity: 107Merit: 10 Re: Arguing about resource piep pushers in caves August 17, 2013, 09:45:41 AM #96 Actually, in exchange a share from it is not demanded the disgorgement of surplus profits for pot peacaking targets PKGR discussistic/disCL Seems like a good light-hearted youth talk; he'd be entitled, with any economic approach to a predator-getter comes in alternative compatible resource piep pushers, who were service suppliers, exercise longTraceback (most recent call last):\n",
            "  File \"src/generate_unconditional_samples.py\", line 77, in <module>\n",
            "    fire.Fire(sample_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/generate_unconditional_samples.py\", line 69, in sample_model\n",
            "    out = sess.run(output)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 950, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1173, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\n",
            "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n",
            "Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM1Hag-JL3Bt"
      },
      "source": [
        "To check flag descriptions, use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdxfye-SL66I"
      },
      "source": [
        "!python3 src/generate_unconditional_samples.py -- --help"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}